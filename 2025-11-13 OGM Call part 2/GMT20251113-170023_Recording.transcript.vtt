WEBVTT

1
00:00:00.000 --> 00:00:04.639
Jerry Michalski: You often want a choctaw to run their business.

2
00:00:04.640 --> 00:00:07.570
Kevin Jones: Much more transactional commercial folks.

3
00:00:07.860 --> 00:00:12.820
Jerry Michalski: It's like having a Shabbos goi turned on and off, turn your switches on and off on Shabbat.

4
00:00:12.820 --> 00:00:24.029
Kevin Jones: Or something like that. It's, it's, yeah, they don't think transactionally well. The Choctaw have always done that, and I could go further into the Choctaw, but yeah.

5
00:00:25.220 --> 00:00:27.859
Jerry Michalski: Thank you so much for that story. Gil, please.

6
00:00:27.860 --> 00:00:37.719
Gil Friend • Sustainability OG • CxO Coach: It's a wonderful story, Kevin. Thank you. And the… the what does this decision make us is a question that's going to be resonating with me for a while, so thank you for that.

7
00:00:38.020 --> 00:00:53.839
Gil Friend • Sustainability OG • CxO Coach: Well, it's a… it's a great example of how… how contextual this whole conversation is, because, you know, I would… I might assume something about Native American culture, but no, Cherokee different than Choctaw. No, actually, within Cherokee, differences within… you know, so all of that situational.

8
00:00:53.840 --> 00:00:58.749
Kevin Jones: Yeah, and Cherokee Nation is much more transactional than Eastern Bend and Coutua.

9
00:00:59.460 --> 00:01:13.840
Gil Friend • Sustainability OG • CxO Coach: And you say, but even within Cherokee Nation, there's going to be differences in the different formations that people have, and I'm struck that if I were in conversation with that tribe, talking, you know, if I were you in that situation, and asked.

10
00:01:14.660 --> 00:01:22.989
Gil Friend • Sustainability OG • CxO Coach: Hey guys, what's going on? Haven't heard from you for a while, being curious about the process of the transaction. That would have been very unwelcome, and not helpful.

11
00:01:23.920 --> 00:01:28.100
Gil Friend • Sustainability OG • CxO Coach: Whereas in another setting, I'm at a SOCAP conference, you might ask that question to somebody.

12
00:01:28.500 --> 00:01:33.350
Kevin Jones: Yep. Yeah, the fastest way to go slower with a tribe is to probe.

13
00:01:35.320 --> 00:01:36.820
Gil Friend • Sustainability OG • CxO Coach: Probe how? What does that mean?

14
00:01:37.070 --> 00:01:40.260
Kevin Jones: Is to probe, you know, to say, hey, what's up?

15
00:01:40.510 --> 00:01:54.240
Kevin Jones: You know, it's like, they've said they're going off to think about it. Oh, okay, so you're saying, yeah, that will slow things down. I gotcha. Right, like, you don't get welcome to the camp if you come into the camp. You get visible.

16
00:01:54.380 --> 00:01:59.570
Kevin Jones: And then you wait, and you get invited when it's time to invite you. I mean, it's that kind of…

17
00:01:59.730 --> 00:02:03.950
Kevin Jones: You know, drives me fucking crazy, but, you know, that's what you have to do.

18
00:02:04.150 --> 00:02:07.570
Gil Friend • Sustainability OG • CxO Coach: I had a friend years ago who, lived in…

19
00:02:08.389 --> 00:02:12.419
Gil Friend • Sustainability OG • CxO Coach: I guess northwestern Maryland, very rural northwestern Maryland.

20
00:02:12.610 --> 00:02:23.999
Gil Friend • Sustainability OG • CxO Coach: And their family had been there for 20 years before they had a conversation with somebody, not on their front porch, but in their house. 20 years before they were invited in from the porch into the house.

21
00:02:25.340 --> 00:02:29.879
Gil Friend • Sustainability OG • CxO Coach: Completely friendly, you know, friendly conversations on the porch, but that's where it was.

22
00:02:30.510 --> 00:02:31.250
Gil Friend • Sustainability OG • CxO Coach: Until…

23
00:02:31.250 --> 00:02:33.390
Jerry Michalski: It's a whole new perspective on slow to warm up.

24
00:02:36.660 --> 00:02:42.550
Kevin Jones: I'll just toss this quickly in, and my friends in Barcelona say they get invited to cafes, but not to the houses.

25
00:02:42.720 --> 00:02:44.259
Gil Friend • Sustainability OG • CxO Coach: There you go.

26
00:02:44.260 --> 00:02:58.929
Jerry Michalski: Yeah, thanks. Our senses of what is… our intimacy gradient is a way of expressing this. Like, who would you invite into your bedroom, to your living room, onto your porch, to your block party? There's a series of concentric rings.

27
00:02:58.930 --> 00:03:00.219
Judith Benham: And…

28
00:03:00.220 --> 00:03:07.910
Jerry Michalski: Each culture, and then within each person probably has different settings for, like, who gets to be where, and how… and what you…

29
00:03:08.010 --> 00:03:23.179
Jerry Michalski: what the framing is for that particular ring. Like, oh, in this ring, it's okay to talk about this kind of stuff, but not okay, you know, further out. All those kinds of things. And then there are people who just, like, live their lives fully in public and have no rings, apparently. Alex?

30
00:03:27.310 --> 00:03:42.979
Alex Kladitis: Thank you, very, very interesting. I wanted to… I was very, sort of… I resonated with a lot of what Louise said, not about the teaching side, but about what things are. Like, I'm… no insult intended.

31
00:03:43.050 --> 00:03:48.459
Alex Kladitis: The chances are, if I see you in another Zoom group, I will not recognize any of you.

32
00:03:48.750 --> 00:04:08.369
Alex Kladitis: Literally, you're different entities, and in my mind, it's a different set. I cannot recognize people. It's always a joke when going to the station, I go past neighbors and friends or whatever, because I can't… they're out of context to where they're supposed to be. So… so the reason… so, it's a different mentality brain.

33
00:04:08.630 --> 00:04:14.509
Alex Kladitis: But what, on the other side is, and a number of you have said it, is… I don't know how many of you have this feeling.

34
00:04:14.810 --> 00:04:22.700
Alex Kladitis: I will not use anything, or do anything, or travel in anything, where I don't understand how it works.

35
00:04:23.500 --> 00:04:25.050
Alex Kladitis: I know how cars work.

36
00:04:25.270 --> 00:04:27.039
Alex Kladitis: I know how jets work.

37
00:04:27.300 --> 00:04:32.039
Alex Kladitis: I have looked through the manual of a 747 jet engine when I was 15.

38
00:04:32.280 --> 00:04:34.390
Alex Kladitis: Because I feel the need to know.

39
00:04:34.960 --> 00:04:43.139
Alex Kladitis: I wouldn't get on a plane without no notice. I wonder how many other people feel like that, because… and that is the inner curiosity that some people have.

40
00:04:43.410 --> 00:04:51.149
Alex Kladitis: And, maybe I'm… like some people said, I talk to everyone. I talk to everyone so much.

41
00:04:51.440 --> 00:04:52.989
Alex Kladitis: I have no…

42
00:04:53.840 --> 00:05:00.520
Alex Kladitis: no barrier. I will ask them anything. And some people, especially in Britain, the British people, a lot of them are very reserved.

43
00:05:00.890 --> 00:05:07.710
Alex Kladitis: And, you know, not difficult to cross the barrier. You can ask about the weather, you can ask about…

44
00:05:07.820 --> 00:05:13.409
Alex Kladitis: anything, not important. But as soon as you ask anything remotely personal, it's just like…

45
00:05:13.880 --> 00:05:19.250
Alex Kladitis: goes out of the window, and I kind of upset a lot of people, strangers, so that's okay.

46
00:05:19.710 --> 00:05:24.420
Alex Kladitis: One of the things I found interesting in talking to young people.

47
00:05:25.060 --> 00:05:32.020
Alex Kladitis: And… but it's not just, you know, it just… just happened to be young people in one company I was working in. When we were doing Brexit in Britain.

48
00:05:33.300 --> 00:05:37.090
Alex Kladitis: It was a big thing. Everybody was talking about it, took years to resolve.

49
00:05:37.740 --> 00:05:42.609
Alex Kladitis: And I was sitting at lunch with some young people, they're all, like, 22, 23, 24.

50
00:05:43.210 --> 00:05:48.989
Alex Kladitis: And I started talking about Brexit, you know, political, you know, being mean, sensitive, you know, I'll go in.

51
00:05:49.510 --> 00:05:55.329
Alex Kladitis: And, to my surprise, they all turned around, the three of them, and said, we don't watch the news.

52
00:05:56.410 --> 00:05:58.579
Alex Kladitis: I said, but it's a big thing, don't you care?

53
00:05:59.150 --> 00:06:03.509
Alex Kladitis: No, I said, did you vote? No, we just don't care.

54
00:06:04.140 --> 00:06:08.279
Alex Kladitis: You know, so, like, they didn't say, don't care, we're just not interested.

55
00:06:08.440 --> 00:06:12.010
Alex Kladitis: And that really profoundly shocked me, that there are people in this world

56
00:06:12.420 --> 00:06:15.479
Alex Kladitis: that are like that. So incurious.

57
00:06:17.950 --> 00:06:28.069
Alex Kladitis: On the one point about Louise and the AIs, what I want to say was, I'm one of those people, because of the faces and everything else, I never understand. You can tell me something.

58
00:06:28.260 --> 00:06:39.590
Alex Kladitis: you know, the teacher would tell me something, I could never understand it because my comprehension's not quite right, etc. And, I was too embarrassed to ask clarifying questions, because eventually it got really annoying to the teacher.

59
00:06:39.750 --> 00:06:43.779
Alex Kladitis: She'd answer the same question 3 times at different angles, and I still didn't get it.

60
00:06:44.100 --> 00:06:45.460
Alex Kladitis: But do you know what?

61
00:06:45.560 --> 00:06:48.870
Alex Kladitis: Since ChatGPT came along, Oh.

62
00:06:49.620 --> 00:06:55.620
Alex Kladitis: Fantastic. I ask the same question in different ways, and eventually I understand it.

63
00:06:55.780 --> 00:07:07.650
Alex Kladitis: And that is brilliant, and I wonder whether kids may actually benefit from that. So, because you don't… you don't feel like being… you're not going to be dumb asking the same question to an AI 50 different times.

64
00:07:07.890 --> 00:07:16.469
Alex Kladitis: But I just thought… I wonder whether that would improve things if you… if you have the teacher and the AI to support the teaching.

65
00:07:17.270 --> 00:07:20.580
Alex Kladitis: And… That's it, thank you.

66
00:07:21.680 --> 00:07:34.340
Jerry Michalski: Thanks, Alex, very much. You reminded me of a little historical nugget. A friend of Kevin and mine, Joe Gouldy, who's a digital historian, wrote a book about… called Roads to Power, which was about the first turnpikes in England.

67
00:07:34.380 --> 00:07:51.789
Jerry Michalski: And before they started putting in turnpikes in England, nobody knew the whole country. There was no map of the whole country. You only knew the road to the next town. And when you start getting roads, you start getting carriage rides. And when you have carriage rides, it's the first time you have strangers contained in a small space.

68
00:07:51.790 --> 00:07:55.680
Jerry Michalski: So you have to invent things like, oh, lovely weather outside.

69
00:07:55.890 --> 00:08:05.780
Jerry Michalski: That small talk is invented, apparently, in that culture, for the close confines of long travel in a carriage.

70
00:08:06.200 --> 00:08:07.150
Jerry Michalski: And…

71
00:08:08.130 --> 00:08:12.679
Jerry Michalski: It pervades cultures in all sorts of different ways, and probably showed up in other ways in other places, but it's cool.

72
00:08:12.960 --> 00:08:14.440
Jerry Michalski: Clause, please.

73
00:08:15.320 --> 00:08:16.899
Klaus Mager: Yeah, we have been…

74
00:08:17.020 --> 00:08:31.559
Klaus Mager: reviewing individual curiosity, but there's also a commons persona, you know, as people… so Brexit is a great example. How was Brexit possible? It's because there was…

75
00:08:31.650 --> 00:08:44.910
Klaus Mager: a curiosity of the comments about what does this all imply, and what does it mean, and where should we be drifting, and where should we be going. So the…

76
00:08:45.110 --> 00:09:04.080
Klaus Mager: looking at this not just from an individual perspective, but from a commons perspective, you know, from… from where the majority is moving, moving around, and maybe having groups within the commons who have divergent opinions. I mean, that's…

77
00:09:04.360 --> 00:09:09.870
Klaus Mager: also, I mean, it's heavily cultural, but it's also,

78
00:09:09.930 --> 00:09:20.860
Klaus Mager: a way to define curiosity, you know, to… because the… the… and I'm not quite sure how to… how to really frame this, but…

79
00:09:20.860 --> 00:09:30.289
Klaus Mager: The… the common mind is curious about and interested in information, and of course it's being manipulated and

80
00:09:30.290 --> 00:09:41.070
Klaus Mager: and messed around with. And the reason why I'm so, so, maybe more aware of it is because, you know, I've been working on climate change, I've been working on…

81
00:09:41.070 --> 00:09:50.480
Klaus Mager: Getting people to understand food within the context of climate and environment. And there is a shift in public perception.

82
00:09:50.560 --> 00:10:05.099
Klaus Mager: You know, you can see that opinion bending towards an understanding of health and of nutrition and so on, and the impact on environment.

83
00:10:05.270 --> 00:10:11.050
Klaus Mager: But it's, it's, and… and I think that the curiosity is there.

84
00:10:11.220 --> 00:10:25.159
Klaus Mager: But you are fighting these information streams that are contradicting each other, you know, and that are manipulated. So how does that all play a role here? How does that…

85
00:10:25.160 --> 00:10:38.029
Klaus Mager: you know, enter the idea of what is curiosity. You know, if you can't distinguish between what's right and wrong, and not wanting to be misled, you know, having to have the trust

86
00:10:38.320 --> 00:10:56.849
Klaus Mager: towards an information source, and then… and then, commit yourself to that information source versus, you know, dismissing others. So I think there's a… there's a… there are a lot of nuances here that are a little bit more difficult to define.

87
00:10:57.360 --> 00:11:00.489
Jerry Michalski: Absolutely, Klaus. You just opened up in my brain

88
00:11:01.770 --> 00:11:09.450
Jerry Michalski: sort of the QAnon and other conspiracy theorist comment of, I did… well, I did the research, or do your own research.

89
00:11:09.610 --> 00:11:26.280
Jerry Michalski: And people going off onto the intertubes and discovering God knows what. And this is sort of at that boundary between curiosity and critical thinking, but also misinformation, disinformation, etc, etc. And, strangely enough, collective sense-making, which is an incredibly OGM-y topic.

90
00:11:27.630 --> 00:11:31.689
Jerry Michalski: Part of the reason we're here is how do we make sense of our world together?

91
00:11:32.110 --> 00:11:33.590
Jerry Michalski: Scott, please.

92
00:11:37.310 --> 00:11:43.269
Scott Moehring: as I am… want to do, I… Have an idea about…

93
00:11:43.750 --> 00:11:46.729
Scott Moehring: A way to define curiosity, or one definition.

94
00:11:46.730 --> 00:11:52.060
Jerry Michalski: And Scott, your volume seems to be really low, if you can lean toward your mic or turn up the gain or something, but keep going.

95
00:11:52.060 --> 00:11:56.480
Scott Moehring: Alright, well, we'll just talk a little louder for a minute.

96
00:11:56.690 --> 00:12:00.160
Scott Moehring: Curiosity.

97
00:12:00.300 --> 00:12:04.320
Scott Moehring: Noticing things you don't… didn't have to notice.

98
00:12:05.040 --> 00:12:09.820
Scott Moehring: I'm gonna put that in the chat. I just wanna see if that resonates with anyone.

99
00:12:10.050 --> 00:12:14.379
Scott Moehring: I've been thinking about noticing, and that seems to fit.

100
00:12:14.860 --> 00:12:15.850
Scott Moehring: What?

101
00:12:16.740 --> 00:12:21.060
Scott Moehring: Well, curiosity. Noticing things you didn't have to notice.

102
00:12:24.410 --> 00:12:25.180
Jerry Michalski: Thank you.

103
00:12:25.980 --> 00:12:26.909
Jerry Michalski: Pete, please.

104
00:12:29.670 --> 00:12:33.300
Pete Kaminski: I, I wanted to… to echo Alex's…

105
00:12:33.910 --> 00:12:42.640
Pete Kaminski: discussion of not going in things that you don't know how they work. I'm not quite that… that extreme, but I certainly

106
00:12:42.860 --> 00:12:49.749
Pete Kaminski: in a building, or in a city, or in a vehicle, or whatever, wherever I'm at.

107
00:12:49.940 --> 00:12:55.140
Pete Kaminski: I usually know a lot about the infrastructure of it, and…

108
00:12:55.810 --> 00:12:59.919
Pete Kaminski: And I feel a lot better about it because of that.

109
00:13:00.130 --> 00:13:14.429
Pete Kaminski: And it's… it's just a way I live. It's not, you know, it's… I don't feel like I'm super curious about things, or that I've got to find out stuff. Although, demonstrably, kind of, I am, compared to other people.

110
00:13:14.800 --> 00:13:17.500
Pete Kaminski: And…

111
00:13:17.660 --> 00:13:29.139
Pete Kaminski: I… I, I'm gonna put a link to a Washington Post article, and I'm not gonna archive, .ph it, you'll have to do that yourself, but, it's…

112
00:13:29.140 --> 00:13:42.710
Pete Kaminski: Washington Post found 47,000 conversations, with ChatGPT, that kind of spilled out onto the internet, and they collected them up and kind of went through them. So, what do people talk with ChatGPT about?

113
00:13:42.710 --> 00:13:50.369
Pete Kaminski: And some of the… some of the things were just, like, heart-stoppingly heartbreaking for me to read, because

114
00:13:51.000 --> 00:14:04.149
Pete Kaminski: when I'm using a chat system, a ChatGP or cloud or whatever, I know how it works, I know why it does what it does, how, you know, I can predict, you know, not entirely accurately, but I can kind of predict

115
00:14:04.470 --> 00:14:18.410
Pete Kaminski: it's going to be good at these things, it's going to be bad at these things, it's going to pretend to be good at these things, and it's going to be wrong, and that doesn't freak me out, you know? It's like riding in a jet airplane, and knowing

116
00:14:18.620 --> 00:14:27.849
Pete Kaminski: What kinds of things would break and are no big deal, and what kinds of things might seem like not a big deal, but they're huge, and, like, everything is a disaster, right?

117
00:14:28.000 --> 00:14:38.730
Pete Kaminski: I know that kind of thing about jet airplanes, or cars, or buses, or, you know, tall buildings, or whatever. And so it…

118
00:14:39.200 --> 00:14:40.010
Pete Kaminski: it…

119
00:14:40.960 --> 00:14:58.779
Pete Kaminski: kind of terrifies me, thinking that people are using these things that are able to ape human emotions effectively, with absolutely no intent or care about what they're doing, because they cannot have care, not because they don't, you know, they don't

120
00:14:59.130 --> 00:15:15.290
Pete Kaminski: give a hoot. They can't. But they pretend that they do, or they act like they do, in a way that confuses people, and there's a bunch of people who don't know how, you know, AI works, and they get fooled by it, and they do all kinds of crazy things with it.

121
00:15:15.490 --> 00:15:24.039
Pete Kaminski: This… it reminds me also, in a strange way, this… I'm going to say something that I feel like is embarrassing to say in public.

122
00:15:24.290 --> 00:15:27.259
Pete Kaminski: I am pretty successful at using

123
00:15:27.290 --> 00:15:48.500
Pete Kaminski: don't do this at home, folks. I'm pretty successful at using ChatGPT as health advice. And I was thinking about that. I had a… I had a kind of a health scare. I ended up in the hospital for a few days. I spent a lot of time with ChatGPT, asking stupid questions of it, rather than a nurse, because nurses are busy doing other

124
00:15:48.500 --> 00:15:57.669
Pete Kaminski: more important things, apparently. No offense to nurses or even the medical system, but ChatGPT was a huge help to me, and I'm like.

125
00:15:57.670 --> 00:16:04.130
Pete Kaminski: Okay, how can I tell people that I did this, and I did it in a safe way?

126
00:16:04.130 --> 00:16:23.119
Pete Kaminski: Because, just like jet airplanes and, you know, excavators and tall buildings, I know a lot about health systems, too. Health systems and my health, and how medicine works, and I can understand an explanation from ChatGPT and ask penetrating questions about

127
00:16:23.120 --> 00:16:27.600
Pete Kaminski: Are you… are you sure that you thought about this or that, you know, in a way that I feel…

128
00:16:27.740 --> 00:16:30.400
Pete Kaminski: safe to navigate with ChatGPT,

129
00:16:30.530 --> 00:16:51.439
Pete Kaminski: giving me health advice. I wouldn't recommend that to most people, and again, don't do it at home. But it's… it was shocking reading the Washington Post thing, going, oh my god, people are using these technologies, and they have no clue how it works, and they're getting tricked by it. Not because the thing is trying to trick it, but because they've…

130
00:16:51.610 --> 00:16:54.670
Pete Kaminski: They're in a context where they don't have enough information about it.

131
00:16:56.890 --> 00:16:58.770
Jerry Michalski: Thanks, Pete. Louise.

132
00:16:59.600 --> 00:17:09.560
LP1: Well, that's an interesting one for me to lead on to, because I do reflect on the use of AI, in an education environment.

133
00:17:09.640 --> 00:17:28.100
LP1: I can see there would be so many benefits. I mean, I'm fortunate to have small classes of, say, 24 students, but you can imagine trying to give those 24 students individual focused attention is very challenging. But if they have an AI bot that can respond to them.

134
00:17:28.099 --> 00:17:37.629
LP1: which can lead them, which can assess them and move them on. We have individual students moving at an individual pace.

135
00:17:37.630 --> 00:17:53.529
LP1: And I can see a huge benefit in that, but you've, it's Pete, has given me then a lot of that concern, you know, we've got to have some confidence that that, AI is capable of doing that. Maybe in a focused,

136
00:17:53.530 --> 00:18:09.149
LP1: on a focused topic or subject, you can have an AI that could lead students through a learning experience, and let them, at their own pace, but also at their own level of curiosity, explore a subject.

137
00:18:09.360 --> 00:18:26.100
LP1: Something the conversation has really highlighted for me, which is going to be beneficial when I'm teaching, is that this curiosity is so multifaceted that I may not recognize curiosity from a student about this particular maths lesson.

138
00:18:26.120 --> 00:18:46.040
LP1: But they probably do have the curiosity in some area that's, engrossing for them, and I may just not be aware of that. I mustn't judge them just in their… in the environment of curiosity in my classroom and maths. So that's been very helpful, today.

139
00:18:46.040 --> 00:19:05.019
LP1: One thing I might mention is if you are interested in Brexit, I don't know if you've seen the film, which I found very, enlightening, although I do appreciate it's sort of a docudrama, where, Benedict Cumberbatch plays Dominic Cummings, and, it explores the ways that,

140
00:19:05.020 --> 00:19:14.339
LP1: they managed to influence and convince the public that, to exit was the vote. So that's quite interesting to watch.

141
00:19:16.650 --> 00:19:18.910
Jerry Michalski: Thank you so much, Louise. Excuse me.

142
00:19:21.020 --> 00:19:22.210
Jerry Michalski: Oops, John.

143
00:19:23.280 --> 00:19:23.810
* John Kelly: Yup.

144
00:19:26.020 --> 00:19:34.269
* John Kelly: Okay, so… One of the ideas of my curiosity was noticing things that you don't absolutely have to notice.

145
00:19:34.460 --> 00:19:40.209
* John Kelly: You may notice that I'm in a different context than I was earlier in the call, and

146
00:19:40.890 --> 00:19:47.359
* John Kelly: If you're curious, I'm actually in a hyperbaric chamber, and we're just under 2 atmospheres

147
00:19:47.580 --> 00:19:51.490
* John Kelly: And about 46% oxygen, which is,

148
00:19:52.560 --> 00:19:59.360
* John Kelly: As nominally therapeutic benefits for both Certainly.

149
00:19:59.860 --> 00:20:09.199
* John Kelly: conditions, certain disease conditions, but also, you know, as both a longevity or a cognitive enhancement tool, and that's how I'm using it.

150
00:20:10.300 --> 00:20:15.409
* John Kelly: And also to build on the comments about teaching.

151
00:20:17.200 --> 00:20:19.459
* John Kelly: I taught different levels, you know.

152
00:20:19.840 --> 00:20:24.090
* John Kelly: young kids, High school, college, and adults.

153
00:20:24.330 --> 00:20:25.909
* John Kelly: And,

154
00:20:26.630 --> 00:20:35.699
* John Kelly: there are techniques which, if you thought this was curiosity, you would be oversimplifying on the one hand. On the other hand.

155
00:20:36.680 --> 00:20:41.479
* John Kelly: They're quite powerful, particularly if You can,

156
00:20:41.670 --> 00:20:54.540
* John Kelly: alter the social meaning of it. So, a classic one that all of us who have done any consulting, or even just people who are here, I mean, you've heard of the five whys things, where you just keep asking why, why.

157
00:20:54.940 --> 00:20:58.630
* John Kelly: You basically take apart each answer.

158
00:20:59.180 --> 00:21:06.159
* John Kelly: you don't accept it as, oh, that's not the… that's not the ultimate why. The other whys are underneath.

159
00:21:07.800 --> 00:21:13.970
* John Kelly: That's just an example of one kind of question. I actually Noticed in teaching that

160
00:21:15.380 --> 00:21:18.160
* John Kelly: It's possible to over-focus on why.

161
00:21:18.690 --> 00:21:32.950
* John Kelly: when you haven't done the previous work about what and how. And how is a more neutral version of why. Why assumes, you know, why… we tend to look for a motivation. We tend to look for a human actor and a motivation. And

162
00:21:33.180 --> 00:21:39.370
* John Kelly: It's a good place to look, you know, if you're… if you're in a mystery story, or if you're in a, you know…

163
00:21:40.360 --> 00:21:48.460
* John Kelly: Murder mystery, or other kind of mysteries. But there's other kinds of… kinds of collaborative coherence of,

164
00:21:48.580 --> 00:21:57.100
* John Kelly: causes, and you might not notice those unless you said how instead of why, and also if you said what first. And…

165
00:21:57.580 --> 00:22:00.889
* John Kelly: What about the fact that students, and I had, I had plenty of…

166
00:22:01.300 --> 00:22:09.400
* John Kelly: militantly uncurious students. First gen… first generation college, In a mill town, you know.

167
00:22:09.510 --> 00:22:14.610
* John Kelly: Their ideal, their career goal was to become a shop teacher.

168
00:22:15.460 --> 00:22:20.629
* John Kelly: you know, they were… they were there. When I started talking about communication, they said, well.

169
00:22:20.820 --> 00:22:22.269
* John Kelly: When are we gonna laminate?

170
00:22:23.150 --> 00:22:28.350
* John Kelly: And they had pictures of motorcycles and things like this that they wanted to land. This is college. This is college.

171
00:22:28.450 --> 00:22:35.790
* John Kelly: But it was… it was a shock to me. But I found that if you created a context in which there's a social reason

172
00:22:36.160 --> 00:22:51.650
* John Kelly: for participating and pursuing a question like the five whys. They'll participate for the social reason, and then down the road, they'll get the benefit in terms of the enrichment of the conversation and the possibility of, say, oh.

173
00:22:52.040 --> 00:23:05.679
* John Kelly: We actually, discovered something that we weren't looking for, and we weren't particularly… if you told us to look for it, we would not have necessarily done it, but we did it in the context of playing this little game, and as a result of playing the little game.

174
00:23:06.220 --> 00:23:08.279
* John Kelly: We now have a different perspective.

175
00:23:08.400 --> 00:23:11.260
* John Kelly: So… That's it.

176
00:23:11.930 --> 00:23:13.099
* John Kelly: Thank you, John.

177
00:23:13.890 --> 00:23:14.660
Jerry Michalski: Determined.

178
00:23:15.270 --> 00:23:34.720
Kevin Jones: Yeah, you know, this is going from, don't try this at home, and sort of part of my approach to life or something. About 25 years ago, I was in Rajasthan at a Mughal fort, and there was a fakir who does, you know, a random pattern to keep a cobra.

179
00:23:35.820 --> 00:23:45.840
Kevin Jones: From going at it. And I've been told just a few weeks before by a woman that I was hard to follow in dance, so I wanted to see how it would be with the cobra.

180
00:23:45.950 --> 00:23:47.830
Kevin Jones: So I bought a…

181
00:23:48.030 --> 00:24:03.479
Kevin Jones: little pipe thing, little tube, whatever those things are, and got a little closer, and so the Cobra focused on me, and it turned… I did my little funky thing, and within less than 30 seconds, the cobra had me figured out better than Sean McConnell's wife had.

182
00:24:03.610 --> 00:24:13.179
Kevin Jones: But I planned my exit well. I knew what to do with my right hand and with my left leg, and to spin behind, and so that he was in the line of fire, and my kids are watching me, and it's like.

183
00:24:13.760 --> 00:24:18.729
* John Kelly: I didn't have to tell them, don't try this, because they'd seen me, you know, do something.

184
00:24:19.270 --> 00:24:25.809
Kevin Jones: But it was a great time. The moment of being eye-to-eye with a cobra is something I would do

185
00:24:26.210 --> 00:24:34.869
Kevin Jones: And I don't regret doing, but I'm glad they didn't think they needed to do it. So I'm really glad that my kids have not seen me as a role model.

186
00:24:36.430 --> 00:24:39.529
Jerry Michalski: This is a good, non-replicable parenting moment.

187
00:24:40.550 --> 00:24:42.930
Jerry Michalski: Thanks, Kevin.

188
00:24:43.270 --> 00:24:44.410
Jerry Michalski: Stacy.

189
00:24:44.680 --> 00:24:51.240
Jerry Michalski: Stacy, you're ending up in the queue after people saying incredible things, so… good luck. Go ahead.

190
00:24:51.700 --> 00:25:08.520
Stacey Druss: Thank you. Yeah, I just… I just wanted to say that, I think we're… there's a little bit of a blurry line between the noticing and the curious, and I… I just want to remind everybody, we are all curious, so just saying that.

191
00:25:09.010 --> 00:25:15.779
Stacey Druss: With the noticing, I do believe there are people that they just don't notice.

192
00:25:16.030 --> 00:25:16.830
Stacey Druss: And…

193
00:25:17.260 --> 00:25:23.680
Stacey Druss: Like, they may not have the ability to notice, and so if you don't notice in the first place, you can't be curious.

194
00:25:23.920 --> 00:25:32.389
Stacey Druss: Then there are people that notice, and they're not curious, and there's a difference there. So I just wanted to point that out.

195
00:25:34.120 --> 00:25:35.959
Jerry Michalski: Thanks, Stacey. And, and, and…

196
00:25:36.590 --> 00:25:44.539
Jerry Michalski: So much of all of this is about how we direct our attention, or how we mind our attention, or what we pay attention to, however you want to phrase that.

197
00:25:45.800 --> 00:25:51.019
Jerry Michalski: Because only that will direct us to be curious and give us the avenue, as you just described.

198
00:25:51.930 --> 00:25:58.760
Jerry Michalski: We are very close to the end of our time together today, so I'm wondering if anybody has,

199
00:25:58.870 --> 00:26:08.809
Jerry Michalski: Victoria, did we miss things? Would you rather us have a more solid framework? I haven't been able to track the Excalibro on board very well. The Excalidraw has been growing.

200
00:26:09.220 --> 00:26:18.109
Victoria (Spain): And it can be opened Longer, so anybody who wants to continue the conversation there, that would be great.

201
00:26:18.430 --> 00:26:22.069
Victoria (Spain): It's always great to have the conversation going on.

202
00:26:22.500 --> 00:26:32.899
Victoria (Spain): I will say that… I asked here in the chat if anyone knew about the question formulation technique.

203
00:26:33.400 --> 00:26:40.250
Victoria (Spain): That is a methodology that the Right Question Institute launched some years ago.

204
00:26:41.040 --> 00:26:44.050
Victoria (Spain): I think we need to do something like that.

205
00:26:44.810 --> 00:26:51.410
Victoria (Spain): With a good focus question, And start asking the questions first.

206
00:26:52.030 --> 00:27:00.309
Victoria (Spain): And then, like, playing with… These questions, prioritize, and then decide what to do.

207
00:27:00.850 --> 00:27:04.789
Victoria (Spain): Because I love the conversation, I've learned a lot.

208
00:27:05.890 --> 00:27:09.029
Victoria (Spain): But I don't think we have really

209
00:27:10.810 --> 00:27:15.890
Victoria (Spain): start to uncover half of what curiosity is about.

210
00:27:16.370 --> 00:27:21.959
Victoria (Spain): Because we were explaining our hypotheses instead of asking questions.

211
00:27:22.390 --> 00:27:34.229
Jerry Michalski: Hmm, okay. So the four rules for producing questions from the question formulation technique, I'll just read them into the room so that we're aware, because I think you're suggesting we use this?

212
00:27:35.430 --> 00:27:45.339
Victoria (Spain): So, if you are, if you want some combat, some of the meeting could go like this, so, just to practice.

213
00:27:45.750 --> 00:27:51.319
Jerry Michalski: So the four rules for producing questions are ask as many questions as you can.

214
00:27:51.760 --> 00:27:54.610
Jerry Michalski: Do not stop to answer, judge, or discuss.

215
00:27:55.290 --> 00:28:01.469
Jerry Michalski: Write down every question exactly as stated, and then change any statements into questions.

216
00:28:02.390 --> 00:28:03.800
Jerry Michalski: That's the process.

217
00:28:04.160 --> 00:28:12.030
Jerry Michalski: And it would be fun to experiment with that. And Victoria, have you run any meetings or sessions where you've used this?

218
00:28:12.680 --> 00:28:15.729
Victoria (Spain): I was attending a seminar.

219
00:28:16.040 --> 00:28:19.099
Victoria (Spain): More or less, very informal, just like this.

220
00:28:19.490 --> 00:28:24.170
Victoria (Spain): among people who were interested in learning about Greek mythology.

221
00:28:25.090 --> 00:28:35.850
Victoria (Spain): And the idea was that we raised the theme, and one person was preparing the theme for the next session, and people would come with questions.

222
00:28:36.400 --> 00:28:39.520
Victoria (Spain): Nobody did, nobody asked, of course.

223
00:28:39.750 --> 00:28:43.490
Victoria (Spain): Until I suggested this, And then…

224
00:28:44.580 --> 00:28:50.549
Victoria (Spain): We had so many questions, and we were able, like, to really…

225
00:28:51.000 --> 00:28:54.870
Victoria (Spain): Go in the direction we wanted, because…

226
00:28:55.070 --> 00:29:02.490
Victoria (Spain): We end it with those lists of, questions, prioritize them, decide what to do with them.

227
00:29:02.740 --> 00:29:11.709
Victoria (Spain): Some people were like, for example, I want to invest to go further, research the…

228
00:29:12.890 --> 00:29:22.580
Victoria (Spain): The hero, heroine, difference, I want to go through this other path, so each one decided

229
00:29:23.010 --> 00:29:27.229
Victoria (Spain): The next session, instead of having this, like.

230
00:29:27.400 --> 00:29:33.340
Victoria (Spain): Standardized sessions, because they were the topics everybody talks about.

231
00:29:34.230 --> 00:29:39.770
Victoria (Spain): And it was really enriched… enriched for everybody.

232
00:29:40.600 --> 00:29:45.740
Victoria (Spain): So… Maybe we can use it at least once?

233
00:29:46.760 --> 00:29:58.840
Victoria (Spain): to uncover anything we can about curiosity or about anything else. That's not the… the issue is not the theme, it's that we practice with this.

234
00:29:58.940 --> 00:30:03.790
Victoria (Spain): That maybe can bring something new to this… conversations.

235
00:30:04.760 --> 00:30:08.440
Jerry Michalski: I like it, and I'm tempted to…

236
00:30:08.970 --> 00:30:27.549
Jerry Michalski: go back to the topic of curiosity, or just shift around? I don't know. I'm open to whatever anybody wants to suggest, but I think using this would be great. I think the immediate question that comes to mind is, at the end of this process, you have apparently a really long, great list of questions, then what do you do?

237
00:30:28.690 --> 00:30:35.539
Victoria (Spain): No, the next steps, the question formulation technique does not end in the list of questions.

238
00:30:35.710 --> 00:30:36.450
Jerry Michalski: Right?

239
00:30:36.450 --> 00:30:45.449
Victoria (Spain): It ends when you decide to prioritize the questions, and what to do with the first three questions that are in your list.

240
00:30:46.220 --> 00:30:46.890
Jerry Michalski: Awesome.

241
00:30:47.620 --> 00:30:48.540
Victoria (Spain): Thank you.

242
00:30:49.230 --> 00:30:50.650
Jerry Michalski: Beautiful.

243
00:30:51.500 --> 00:30:58.700
Jerry Michalski: So I… let's you and I talk about that some more, so we can sort of set this up. Anybody else who's interested, let us know on the OGM list.

244
00:30:59.420 --> 00:31:00.840
Jerry Michalski: And,

245
00:31:01.750 --> 00:31:06.850
Jerry Michalski: We don't have Ken for a while, he's stepped away from conversations like this for a bit, so we don't have a poem.

246
00:31:07.300 --> 00:31:12.740
Jerry Michalski: From him at the end of the call, which is… Sad for me. But,

247
00:31:13.850 --> 00:31:20.609
Jerry Michalski: We'll be back in a week. So, thank you very much for a great call. That was… this was… this was a perfect exploration. Really appreciate it.

248
00:31:21.320 --> 00:31:22.299
Jerry Michalski: Thank you all.

249
00:31:23.590 --> 00:31:25.780
Jerry Michalski: Gabriele, welcome, thanks, nice to see you.

250
00:31:25.780 --> 00:31:26.930
Gabriele G: Thanks. Thanks.

251
00:31:26.930 --> 00:31:28.340
Jerry Michalski: And Luis as well.

252
00:31:28.490 --> 00:31:30.279
Gabriele G: Yeah, yeah, thank you, Jerry.

253
00:31:30.740 --> 00:31:33.500
Gabriele G: I had some good, insights from that.

254
00:31:35.660 --> 00:31:38.440
Gabriele G: Yeah, I'm really intrigued about this,

255
00:31:38.720 --> 00:31:47.710
Gabriele G: asking questions things, so I'm… I'm going to read and found something online, or… how can I,

256
00:31:49.150 --> 00:32:00.950
Gabriele G: you said that if… if I am interested, how can I, manifest those interest… interests if you're going to do something about this… the question formulating, or…

257
00:32:02.320 --> 00:32:03.920
Gabriele G: In the future.

258
00:32:04.320 --> 00:32:09.589
Jerry Michalski: Yeah, you are not yet on the OGM Google group, the mailing list that we use, so… No.

259
00:32:09.590 --> 00:32:10.020
Gabriele G: I eat.

260
00:32:10.020 --> 00:32:14.080
Jerry Michalski: Victoria gave me your email address. Is it okay if I add you to the list?

261
00:32:14.450 --> 00:32:15.970
Gabriele G: Yeah, definitely, definitely.

262
00:32:15.970 --> 00:32:21.639
Jerry Michalski: Sounds great. And then, so on that list is where we talk. That's our conversational space, so…

263
00:32:21.750 --> 00:32:22.770
Jerry Michalski: That would be the place.

264
00:32:22.770 --> 00:32:24.499
Gabriele G: Nice. Perfect. Jerry?

265
00:32:24.720 --> 00:32:33.050
Stacey Druss: Can you, can you put, can you put Victoria's, thing on the email? The, I don't know what it's called, the cat…

266
00:32:33.050 --> 00:32:33.850
Jerry Michalski: Calendar.

267
00:32:34.290 --> 00:32:44.560
Jerry Michalski: I will add a link to the Excaladraw map to the email that I post when I posted this session online. That's a great idea.

268
00:32:44.560 --> 00:32:45.190
Stacey Druss: Okay.

269
00:32:45.190 --> 00:32:46.299
Jerry Michalski: Stacey, thank you.

270
00:32:46.300 --> 00:32:52.470
Stacey Druss: Gabrielle, if you do… if you do write and post something, post it also to the OGM mailing list so we can see it.

271
00:32:53.100 --> 00:32:54.660
Gabriele G: I'm sorry, I don't…

272
00:32:54.660 --> 00:33:02.140
Gil Friend • Sustainability OG • CxO Coach: I think you said you were going to write or post something about your exploration. I invite you to share it with us on the OGM mailing list.

273
00:33:02.390 --> 00:33:03.909
Jerry Michalski: Once I put you on the list.

274
00:33:05.010 --> 00:33:07.439
Jerry Michalski: Cool. Thank you. Thanks. Thanks, everybody.

275
00:33:07.490 --> 00:33:08.969
Gil Friend • Sustainability OG • CxO Coach: Thanks, everybody. Bye, all.

276
00:33:08.970 --> 00:33:09.650
Gabriele G: Bye.

