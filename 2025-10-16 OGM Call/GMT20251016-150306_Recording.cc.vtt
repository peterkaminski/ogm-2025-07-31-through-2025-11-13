WEBVTT

00:00:00.000 --> 00:00:00.000
Okay.

00:00:00.000 --> 00:00:01.000
Awesome. Um…

00:00:01.000 --> 00:00:03.000
This is the Open Global Mind

00:00:03.000 --> 00:00:06.000
I think there were a few women on there, too, which surprised me.

00:00:06.000 --> 00:00:07.000
Uh, in… in the group chat. Oh, good. This is the Open Global Mind, uh, weekly call

00:00:07.000 --> 00:00:12.000
not surprising to me.

00:00:12.000 --> 00:00:15.000
for October 16th.

00:00:15.000 --> 00:00:19.000
2025. We were just bantering a little bit.

00:00:19.000 --> 00:00:26.000
Dave and I have been in, uh, for the week, and Dave, I have to apologize, I haven't been able to make your sessions, because…

00:00:26.000 --> 00:00:28.000
they've overlapped with stuff. We've been part of a…

00:00:28.000 --> 00:00:35.000
Sketch Your Mind virtual workshop all week that a Hungarian friend, Jolt Vichyan,

00:00:35.000 --> 00:00:40.000
decided to throw, and it's been great. It's been really, like…

00:00:40.000 --> 00:00:43.000
Um, I found it super useful, like, I got to

00:00:43.000 --> 00:00:46.000
do a brain demo session on Tuesday morning.

00:00:46.000 --> 00:00:50.000
Dave, I don't know if you have any thoughts about it, but…

00:00:50.000 --> 00:00:53.000
I thought it was great, and it was well received, I think.

00:00:53.000 --> 00:01:00.000
And it's… what's nice is he's attracted a good who's who of people who care about visualization and graphic facilitation,

00:01:00.000 --> 00:01:05.000
And thinking with pictures, and uh… aces like Dave, who've been, uh,

00:01:05.000 --> 00:01:09.000
putting concepts into visuals for years and years and years and years and years.

00:01:09.000 --> 00:01:12.000
And it's collaborative, it's… it's…

00:01:12.000 --> 00:01:15.000
there's a very nice… there's a very nice feel to it, where, you know,

00:01:15.000 --> 00:01:19.000
kind of attending one another's sessions and on from there.

00:01:19.000 --> 00:01:22.000
I will put a link to the…

00:01:22.000 --> 00:01:24.000
Uh, the conference in…

00:01:24.000 --> 00:01:27.000
the chat. Sketch Your Mind is the name of it.

00:01:27.000 --> 00:01:30.000
And, uh, I'll put a link to it in the chat.

00:01:30.000 --> 00:01:33.000
And then…

00:01:33.000 --> 00:01:40.000
Off we go. And then, Stacy, I wanted to mention to you that I just recorded… I just recorded a podcast, uh…

00:01:40.000 --> 00:01:43.000
about masculinity, with Mo Carrick.

00:01:43.000 --> 00:01:47.000
I'll put a link to her, uh…

00:01:47.000 --> 00:01:49.000
her bio… her LinkedIn, uh…

00:01:49.000 --> 00:01:57.000
in the chat as well. I met her when I was in Berkeley at the Responsive Conference, and we had a really delightful conversation about

00:01:57.000 --> 00:02:02.000
all aspects about masculinity, so I'm gonna do… I have to do some very, very light editing on it.

00:02:02.000 --> 00:02:05.000
And then post that.

00:02:05.000 --> 00:02:06.000
Thank you. Look forward to that.

00:02:06.000 --> 00:02:11.000
And… and maybe, I mean, a good idea might be to… I'll post that, and then we can have a…

00:02:11.000 --> 00:02:14.000
That is a topic for an OGM call.

00:02:14.000 --> 00:02:17.000
See what happens. See how that goes.

00:02:17.000 --> 00:02:18.000
groovy. Nice to see everybody here.

00:02:18.000 --> 00:02:20.000
I like that.

00:02:20.000 --> 00:02:23.000
I, uh, sent… I was inspired, uh,

00:02:23.000 --> 00:02:27.000
for this topic just by recent news, and…

00:02:27.000 --> 00:02:35.000
And by, uh, kind of an awareness that generally, but not exclusively or entirely, this is a left-leaning group.

00:02:35.000 --> 00:02:38.000
We sort of have attracted like minds,

00:02:38.000 --> 00:02:44.000
Uh, and some of us are more toward the middle, but very few of us are out on the right wing of political opinion these days.

00:02:44.000 --> 00:02:49.000
And when things happen, uh, we tend to have a similar response, and uh…

00:02:49.000 --> 00:02:51.000
I was struck recently that, uh,

00:02:51.000 --> 00:02:59.000
through bluster and force, and I don't know what else, other kinds of things, uh, Donald Trump seems to have cracked some

00:02:59.000 --> 00:03:02.000
on the Gaza situation.

00:03:02.000 --> 00:03:07.000
And achieved a ceasefire and an exchange of hostages, which ends the hostage problem

00:03:07.000 --> 00:03:12.000
for the moment. Uh, there are no remaining October 7 hostages that we know of.

00:03:12.000 --> 00:03:16.000
alive or dead. I guess maybe some of the bodies have yet to be recovered and returned, but…

00:03:16.000 --> 00:03:19.000
In general, that thing is resolved.

00:03:19.000 --> 00:03:25.000
how Gaza plays out, we don't know. Uh, if Trump has his way, it'll turn into a resort city with, you know, large Trump

00:03:25.000 --> 00:03:28.000
towers on it, a thought that chills my blood, but hey, there we are.

00:03:28.000 --> 00:03:31.000
He seems to have dropped… he seems to have dropped that.

00:03:31.000 --> 00:03:33.000
Uh, I… maybe.

00:03:33.000 --> 00:03:34.000
He's also apparently got…

00:03:34.000 --> 00:03:36.000
never know anything with him, yeah.

00:03:36.000 --> 00:03:41.000
Yeah, he's apparently also got plans on his, uh, in the Oval Office, he's got mock-ups of…

00:03:41.000 --> 00:03:45.000
A new arc of triumph kind of thing, opposite, uh…

00:03:45.000 --> 00:03:52.000
Opposite Arlington National Cemetery, across the river, and he's adding stuff like the ballroom and other sorts of things to the…

00:03:52.000 --> 00:03:58.000
the White House, gilding it all in gold, etc. He's leaving his mark. He's absolutely leaving his mark.

00:03:58.000 --> 00:03:59.000
But I'm straying from our topic.

00:03:59.000 --> 00:04:00.000
Mm-hmm.

00:04:00.000 --> 00:04:04.000
Uh, in a way that I don't particularly want to, because I kind of want to… I'll come back to it.

00:04:04.000 --> 00:04:08.000
Then, then I heard the news that I didn't realize,

00:04:08.000 --> 00:04:11.000
but that the recent, um, the, uh…

00:04:11.000 --> 00:04:14.000
the Nobel… the Nobel Peace Prize winner.

00:04:14.000 --> 00:04:18.000
Maria Corina Machado.

00:04:18.000 --> 00:04:23.000
dedicated her Nobel Prize to the people of Venezuela and Donald Trump.

00:04:23.000 --> 00:04:32.000
And I sort of googled that, and I saw… well, I googled that, and I saw an article from The Nation that was like, oh my god, what a sellout, this is terrible, blah blah blah.

00:04:32.000 --> 00:04:34.000
And then I heard some backstory.

00:04:34.000 --> 00:04:41.000
And the backstory I heard, which I'll share here, which is Googleable also, if you're looking for it,

00:04:41.000 --> 00:04:47.000
was that Trump is the only president who has actually sent, like, Navy offshore.

00:04:47.000 --> 00:04:52.000
And started to actively do stuff that is helpful to…

00:04:52.000 --> 00:05:01.000
people against Maduro. He's put a $40 million bounty on Maduro's head. Whether that's even legal in the world, I don't know.

00:05:01.000 --> 00:05:03.000
likely that it's not.

00:05:03.000 --> 00:05:08.000
But somehow or other, through, uh… and the reason that Machado…

00:05:08.000 --> 00:05:14.000
dedicates their award to him is he has actually done something, and moved the needle, and, and…

00:05:14.000 --> 00:05:17.000
Sometimes you move the needle by scratching the record.

00:05:17.000 --> 00:05:20.000
I don't know, I'm stretching the metaphor.

00:05:20.000 --> 00:05:24.000
But I'm left-leaning, and I was like, ah!

00:05:24.000 --> 00:05:30.000
How do I process this? How do I handle this? And I'd like us not to talk about…

00:05:30.000 --> 00:05:33.000
Trump and Machado and this particular incident, but rather…

00:05:33.000 --> 00:05:38.000
Other instances of hearing stuff that conflicts with our worldview,

00:05:38.000 --> 00:05:45.000
And figuring out, do we shift our worldview some? What do we do? How do we do that? I'd rather focus there…

00:05:45.000 --> 00:05:53.000
Then on the incident, although I will understand if we need to spend some time decompressing the incident right now. Uh, so Gil.

00:05:53.000 --> 00:05:57.000
Yeah, so the topic for today is shifting one's worldview?

00:05:57.000 --> 00:06:00.000
Um, no, the topic is just, uh, dealing with uncomfortable news.

00:06:00.000 --> 00:06:01.000
Ah, okay.

00:06:01.000 --> 00:06:06.000
Uh, which taps into shifting one's worldview, but it's just like, how do we handle news that doesn't fit our world?

00:06:06.000 --> 00:06:08.000
view, is maybe the generalization of the topic.

00:06:08.000 --> 00:06:13.000
Yeah. Got it. Good topic, and plenty of opportunity for that these days.

00:06:13.000 --> 00:06:19.000
Um, just on the immediate one, and maybe this is a good cutting… jumping-off point, I don't…

00:06:19.000 --> 00:06:26.000
I'm not of the mind that someone should get the Nobel Peace Prize for putting warships off somebody's coast.

00:06:26.000 --> 00:06:30.000
kind of doesn't fit my picture of a Nobel Peace Prize. On the other hand, um…

00:06:30.000 --> 00:06:32.000
Um, I'm… I'm…

00:06:32.000 --> 00:06:35.000
cautiously impressed with what Trump has done.

00:06:35.000 --> 00:06:41.000
in the Middle East, but I also don't think that somebody should get the Nobel Peace Prize for starting an initiative. I don't think

00:06:41.000 --> 00:06:43.000
Obama should have gotten it when he did.

00:06:43.000 --> 00:06:48.000
Obama, the Peace Prize he got seems completely ridiculous.

00:06:48.000 --> 00:06:49.000
Yeah.

00:06:49.000 --> 00:06:52.000
No, it was… it was performative, and I don't think Trump should deserve it now, but he might well deserve it in a year, if this thing holds.

00:06:52.000 --> 00:07:01.000
Yeah, and that's… and that challenges my pictures of a bumbling, narcissistic, um, you know, uh, baby guy.

00:07:01.000 --> 00:07:06.000
Kimmel's been reaming him beautifully every night, and really brilliant work going on there.

00:07:06.000 --> 00:07:11.000
But that doesn't mean that he can't do some things successfully and well.

00:07:11.000 --> 00:07:16.000
And it may be that just the character that he brings to it was very different than Biden's.

00:07:16.000 --> 00:07:17.000
Yeah.

00:07:17.000 --> 00:07:22.000
could generate movement in the Middle East that nobody else could. So, cautiously optimistic there.

00:07:22.000 --> 00:07:28.000
Big change in my worldview, because I have him on the neg list for everything, except now.

00:07:28.000 --> 00:07:30.000
one thing's moved over. Maybe.

00:07:30.000 --> 00:07:31.000
Maybe.

00:07:31.000 --> 00:07:41.000
Maybe, maybe, maybe. Okay, good. So, so I, I want to loosen up that part of the topic. My buddy Al Chang, who always says wise things and always thinks differently than I do, but we can talk really, really well.

00:07:41.000 --> 00:07:46.000
Um, said a while ago that it's as if there's this set of facts on the ground,

00:07:46.000 --> 00:07:48.000
And the left and the right are seeing…

00:07:48.000 --> 00:07:50.000
Roughly the same fact, roughly. Not always.

00:07:50.000 --> 00:07:51.000
Mmm…

00:07:51.000 --> 00:07:57.000
But roughly the same facts, but have a completely different movie script around them, a totally different narrative.

00:07:57.000 --> 00:07:59.000
But the narratives are relatively consistent.

00:07:59.000 --> 00:08:07.000
and work. And the two sides can't see or read each other's narratives. They're incapable, and this is…

00:08:07.000 --> 00:08:13.000
This is… I'm paraphrasing Al badly, but he really kind of made me slow down a little bit, and think, how do I steal man

00:08:13.000 --> 00:08:16.000
the opposing narrative. How do I actually…

00:08:16.000 --> 00:08:22.000
He put my brain into it, and listened for those different parts. So when Trump was like, I've stopped eight wars,

00:08:22.000 --> 00:08:29.000
I used Claude and ChatGBT to say, hey, what has… and Trump has actually… he has sent his people…

00:08:29.000 --> 00:08:34.000
all over the place to do stuff, and he claimed credit for India, Pakistan, which infuriated Modi,

00:08:34.000 --> 00:08:44.000
and is stupid, but the other things that he claims to have done, he's actually been, like, on the ground, not him on the ground, his people have been doing stuff that hasn't been done before.

00:08:44.000 --> 00:08:50.000
And that's very interesting to me, because he gives a damn about, like, you know, making a mark in foreign policy,

00:08:50.000 --> 00:08:53.000
with his particular imprimatur. Anyway…

00:08:53.000 --> 00:08:56.000
Um, Mike.

00:08:56.000 --> 00:09:05.000
I don't know where to go exactly, but let me start by just saying that the commentary about the Nobel.

00:09:05.000 --> 00:09:10.000
Peace Prize was… she said it's dedicated.

00:09:10.000 --> 00:09:14.000
to the people of Venezuela, and that she thanks.

00:09:14.000 --> 00:09:15.000
Trump. I don't think… I don't think she used the word dedicated it.

00:09:15.000 --> 00:09:17.000
I've got the…

00:09:17.000 --> 00:09:21.000
I've got the quote, um, it's dedicated. Uh, it's, um…

00:09:21.000 --> 00:09:25.000
Oops, let me see where I've… how did I… I'll find it, but um…

00:09:25.000 --> 00:09:29.000
Well, most of the quotations have been. sort of two-phase. But anyway.

00:09:29.000 --> 00:09:30.000
So here, let me read it.

00:09:30.000 --> 00:09:37.000
Um, the fact is, is that she's in a bind. She has to be as obsequious as possible.

00:09:37.000 --> 00:09:38.000
That's a way of reading it, but listen to this. I dedicate that last sentence of a long post on X.

00:09:38.000 --> 00:09:43.000
That's…

00:09:43.000 --> 00:09:47.000
I dedicate this prize to the suffering people of Venezuela,

00:09:47.000 --> 00:09:53.000
and to President Trump for his decisive support of our cause, exclamation point.

00:09:53.000 --> 00:09:54.000
That's the quote.

00:09:54.000 --> 00:09:58.000
Well, the first round, I mean, she actually… I think she actually called him up.

00:09:58.000 --> 00:09:59.000
Yes. They had a call.

00:09:59.000 --> 00:10:06.000
And said, you know. Yeah, but again, it's… if you're in her position.

00:10:06.000 --> 00:10:11.000
And you've got somebody who's angry he doesn't have the Peace Prize, and you need his help.

00:10:11.000 --> 00:10:16.000
I mean, whether those words reflect what she really believes is what I'm saying.

00:10:16.000 --> 00:10:17.000
Which I agree with.

00:10:17.000 --> 00:10:21.000
But the other thing I wanted to say is that, um.

00:10:21.000 --> 00:10:28.000
I've been using the phrase cosplay. diplomacy, over and over again.

00:10:28.000 --> 00:10:37.000
Because that's what we're seeing. I mean, these claims that he somehow reconciled or stopped a fight between Armenia and Azerbaijan.

00:10:37.000 --> 00:10:45.000
I mean… it's… these are temporary things that are happening, but.

00:10:45.000 --> 00:10:52.000
let's wait 5 years and look back, and particularly with Gaza. I mean, Gaza, he says he has a deal.

00:10:52.000 --> 00:10:56.000
And maybe in the New York City real estate.

00:10:56.000 --> 00:11:00.000
sense of the word deal. He has a deal where, okay.

00:11:00.000 --> 00:11:04.000
We've got a common goal, and now let's figure out the details.

00:11:04.000 --> 00:11:13.000
But no diplomat. would claim that what… Hamas said they would half agree to.

00:11:13.000 --> 00:11:17.000
is a final deal. I mean, it's already falling apart.

00:11:17.000 --> 00:11:22.000
So, in many ways, this is like the way that Trump ended the.

00:11:22.000 --> 00:11:29.000
U.S. Involvement in Afghanistan. He didn't talk to the Afghan government, he talked to the Taliban, and they got a deal.

00:11:29.000 --> 00:11:41.000
Which was completely vague, and didn't have any. Any checks, any way of making sure both parties did their… did their, um, fulfilled their piece of the deal.

00:11:41.000 --> 00:11:46.000
And for his convenience. he set it up so that.

00:11:46.000 --> 00:11:48.000
the withdrawal happened after he was out of office.

00:11:48.000 --> 00:11:49.000
Great.

00:11:49.000 --> 00:11:54.000
And Biden got to have all this egg on his face because of an incompetent deal.

00:11:54.000 --> 00:11:58.000
That, uh. Trump and his team had agreed to.

00:11:58.000 --> 00:12:08.000
And I really worry that if you've got a deal with Hamas that says they will disarm, but they explicitly said, we didn't agree to that part of the deal.

00:12:08.000 --> 00:12:11.000
But he still thinks he deserves a peace prize.

00:12:11.000 --> 00:12:30.000
But let me get… let me… let me change topics to a third thing that… is very personal, and that is… Two days ago, I got some incredibly… unforeseen, incredible… outrageous, very upsetting news.

00:12:30.000 --> 00:12:36.000
about one of my favorite colleagues here at Carnegie, and some of you may have seen this story.

00:12:36.000 --> 00:12:40.000
We have one of the very top analysts who studies.

00:12:40.000 --> 00:12:50.000
Indian military and geopolitics. And his house was raided recently by the FBI, and they found.

00:12:50.000 --> 00:12:55.000
more than a thousand top secret and confidential documents.

00:12:55.000 --> 00:13:02.000
And, you know, he's been an advisor to the State Department, he knows full well how to handle classified documents.

00:13:02.000 --> 00:13:17.000
But it's, you know, it's leading to all sorts of stories about, is he a spy for the Chinese? He hasn't been accused of that, but… It's… it's just astonishing that someone… if this is true, how could someone so smart and so…

00:13:17.000 --> 00:13:23.000
experienced be so stupid. It's a little bit like Sandy Berger.

00:13:23.000 --> 00:13:33.000
Clinton's National Security Advisor. who went to the archives and decided to take a couple documents and stuff them in his pants and walk out the door.

00:13:33.000 --> 00:13:40.000
But on a much larger scale. And so, again, I mean, this was just… it's a complete disconnect.

00:13:40.000 --> 00:13:48.000
From everything I know about this scholar, and it makes no sense, and… I'm having a very hard time dealing with it. I don't know how I will.

00:13:48.000 --> 00:13:54.000
Yeah, Mike. Thank you very much for offering up a completely different example of this thing going on, because that's…

00:13:54.000 --> 00:13:56.000
That's what I'd love to focus on, is how to…

00:13:56.000 --> 00:13:59.000
How do we handle unwelcome, un…

00:13:59.000 --> 00:14:01.000
ill-fitting news in our worldview.

00:14:01.000 --> 00:14:08.000
And do we allow our worldviews to be permeable to things like that, or not? Or how? Or, like, what's that…

00:14:08.000 --> 00:14:10.000
What's that juncture? Um, thank you.

00:14:10.000 --> 00:14:15.000
All right, Kevin, please.

00:14:15.000 --> 00:14:18.000
Uh, you took your hand down, but you… oh, there you go, there you go, you did unmute.

00:14:18.000 --> 00:14:28.000
Yeah, um, you know, so this is actually the opposite of that. I've got some surprisingly great news. I don't know how to put together.

00:14:28.000 --> 00:14:37.000
Um, some people know, you know, our house was rendered uninhabitable, and one in six houses in our low-status neighborhood.

00:14:37.000 --> 00:14:43.000
of Swan and Oak were rendered either, uh. destroyed or uninhabited, about 400 houses.

00:14:43.000 --> 00:15:06.000
And we've been asked to do a housing plan for the folks, most of the Latino folks moved there because it was the cheapest place in the county.

00:15:06.000 --> 00:15:07.000
Wow.

00:15:07.000 --> 00:15:09.000
And, uh, starting to work with the community on it, and they're really a lot of credibility. And we got an outreach this week through my son, and we're gonna have 25 old order Mennonite carpenters working… living on our farm, and they're self-contained, you know.

00:15:09.000 --> 00:15:16.000
trucks and whatever they do. They're gonna, um, build houses for free from May.

00:15:16.000 --> 00:15:22.000
Through, uh, November through May, and want to do it again, uh, next year.

00:15:22.000 --> 00:15:29.000
And, um… They're also going to leave behind a 30 by 40 foot, uh, what is going to be their, uh.

00:15:29.000 --> 00:15:46.000
mess hall, eating room, whatever, and we'll have this building, and they're gonna rehab our house for free, you know, do the… at least the sheetrock and the, uh… the, uh, installation and stuff, we have to decide, you know, if it's a…

00:15:46.000 --> 00:16:01.000
becomes an Airbnb, you don't need the large mudroom that we had for 5 people, so you have to do some other things. But it's just amazingly, surprisingly good. You know, they're gonna clean it up, and they're gonna fix the house for free, and they're gonna build.

00:16:01.000 --> 00:16:07.000
About 20 houses for free, so that, you know, our… are ready for our fund.

00:16:07.000 --> 00:16:16.000
It went down by, you know, the labor on 20 houses is not… no longer in our math, really, for the first year, so it's like.

00:16:16.000 --> 00:16:20.000
Well, you know, sometimes things happen like that, too. I just need to, you know.

00:16:20.000 --> 00:16:29.000
Sometimes there are days like that, where everything… I do a brief thing, I was taking my son on a college trip, he's 407 of them, so whatever.

00:16:29.000 --> 00:16:43.000
But we, uh… We're flying upstate New York to Bart, I think it was, and uh… We got upgraded to first class, and we got, you know, champagne or whatever in the morning, and then we got to the hotel.

00:16:43.000 --> 00:16:54.000
And it was apparently closed, but there was this massive Samoan guy working on the phones, and he said, just grab a key, and nobody ever came, so we sampled single mouse.

00:16:54.000 --> 00:16:59.000
from the deck that, you know, that's my first sampling of single moths.

00:16:59.000 --> 00:17:03.000
We went to the movie Smoke, and they said, oh, we're through taking tickets, just go inside.

00:17:03.000 --> 00:17:05.000
So I told him, I said, Lord, you know.

00:17:05.000 --> 00:17:21.000
Sometimes there are days like this, you know? And so, you know, suddenly, you know, 25 to 30 older… and they wear straw hats, and they get driven around, and… They'll bring some porcher on things, but they have, you know, they have people drive their.

00:17:21.000 --> 00:17:28.000
They're semi-trailer with all their tools. They use power tools, but it's just like, you know, sometimes things happen like that. I just need to say.

00:17:28.000 --> 00:17:46.000
That's brilliant. I'm happy to hear happy news around, so I don't know, thank you.

00:17:46.000 --> 00:17:47.000
Love that. Um, Gil, please.

00:17:47.000 --> 00:17:49.000
Yeah, stitching together all these new resources is going to be really complicated. I need people who are…

00:17:49.000 --> 00:17:50.000
Yeah. Kevin, why… why is that a challenge to your worldview?

00:17:50.000 --> 00:17:55.000
much better at figuring out how to handle that than I am, and there are people around, so…

00:17:55.000 --> 00:17:56.000
Why is all that good stuff that's happened a challenge to your worldview, given that that's the theme here?

00:17:56.000 --> 00:18:00.000
Why is what?

00:18:00.000 --> 00:18:11.000
Oh, it doesn't show… no, sometimes things happen like that, it just… then you have to deal with this… this, you know, surprising abundance requires lots of coordination, you know? That's… I mean, you know.

00:18:11.000 --> 00:18:20.000
It would require lots of coordination. It doesn't challenge… no, it challenges the worldview in here, saying, let's think about bad things. I was saying, no, let's think about good things, too.

00:18:20.000 --> 00:18:22.000
Good deal. I love it.

00:18:22.000 --> 00:18:27.000
Jerry, by the way, could you raise the gain on your mic? You're much softer than everybody else.

00:18:27.000 --> 00:18:28.000
Yeah, with your fam- with your…

00:18:28.000 --> 00:18:30.000
Oh, interesting. Um, I've actually switched over to this mic, is it…

00:18:30.000 --> 00:18:32.000
You can fancy… with your fancy new mic.

00:18:32.000 --> 00:18:33.000
Yeah, no. Thank you.

00:18:33.000 --> 00:18:44.000
Um, couple of things. Back on the Machado thing, it seems that obsequiousness is one of the required things with this president, and if you've watched a cabinet meeting, you know, you can see that in full cringe.

00:18:44.000 --> 00:18:47.000
Um, seems to be a necessary part of any conversation.

00:18:47.000 --> 00:18:56.000
Back to what you're saying, Jerry, about left and right seeing the same facts and developing different interpretations. You know that I'm… I'm… excuse me.

00:18:56.000 --> 00:19:02.000
I'm big on interpretations, I'm not big on facts these days. I think we live in interpretations, and that's

00:19:02.000 --> 00:19:05.000
part of the currency of human affairs and where it gets really interesting.

00:19:05.000 --> 00:19:10.000
But part of the challenge right now is that left and right are not seeing the same facts.

00:19:10.000 --> 00:19:12.000
Folks are in deep, deep bubbles.

00:19:12.000 --> 00:19:19.000
Uh, not even being exposed to the same information, things that we think are obvious, uh, you know, folks who are living on Fox never see.

00:19:19.000 --> 00:19:24.000
And vice versa. So it's a whole other layer of challenge.

00:19:24.000 --> 00:19:29.000
to how we have reasonable conversations when we're just looking at, you know, utterly same detail.

00:19:29.000 --> 00:19:40.000
In personal terms, I've found that happening with me around the whole Gaza situation over the last 3 or 4 months, where I've come to the conclusion that I have no fucking clue.

00:19:40.000 --> 00:19:42.000
of what was going on there.

00:19:42.000 --> 00:19:50.000
I don't trust Hamas and the Gaza Health Ministry or news services or anything like that. I don't trust the Israeli government's information.

00:19:50.000 --> 00:19:58.000
But don't trust the UN. Um, and I try to piece together stories from anomalous reports that contradict each other.

00:19:58.000 --> 00:20:01.000
from people who aren't there. And I'm not there.

00:20:01.000 --> 00:20:06.000
And I've… it's very strange for me to come to the conclusion that I really don't know what happened.

00:20:06.000 --> 00:20:11.000
And I'm happy to go into detail about that. I've done some numerical analysis.

00:20:11.000 --> 00:20:14.000
Excuse me of some of the data that's been reported, and things just don't…

00:20:14.000 --> 00:20:20.000
cohere. From what I can see. And it's forced the kind of humility on me

00:20:20.000 --> 00:20:23.000
that's really unfamiliar.

00:20:23.000 --> 00:20:28.000
I'm used to being able to, you know, look at a bunch of complex information and draw a conclusion that I have some confidence in.

00:20:28.000 --> 00:20:35.000
And… can't, in that case. So, double layer, not seeing the same facts, and

00:20:35.000 --> 00:20:39.000
you know, mix-up facts that don't fit together.

00:20:39.000 --> 00:20:42.000
makes this even more challenging.

00:20:42.000 --> 00:20:45.000
Um, thanks, y'all. Is my voice a little louder? I found the gain and turned it up.

00:20:45.000 --> 00:20:47.000
It's better now, thanks.

00:20:47.000 --> 00:20:49.000
Is it loud enough? Should I turn it up more?

00:20:49.000 --> 00:20:52.000
Somebody else say something.

00:20:52.000 --> 00:20:53.000
We're good? Uh…

00:20:53.000 --> 00:20:55.000
No, let's have somebody else say something, compare levels.

00:20:55.000 --> 00:20:59.000
Oh, somebody else to compare levels.

00:20:59.000 --> 00:21:00.000
Yeah, sounds fine, Jerry.

00:21:00.000 --> 00:21:01.000
Okay, good. Thank you for… uh, Gil, thank you very much for pointing that out.

00:21:01.000 --> 00:21:04.000
No, it sounds good to me, Jerry.

00:21:04.000 --> 00:21:11.000
Um, on the point of not seeing the same facts, I want to complexify that a little bit, if I can borrow Adam Grant's term.

00:21:11.000 --> 00:21:16.000
There's a book out called Progressive Myths. I'll put a link to it in the chat.

00:21:16.000 --> 00:21:20.000
And I only know about it because my buddy Sammy McElhanan,

00:21:20.000 --> 00:21:23.000
Uh, Finn, who lives in Melbourne,

00:21:23.000 --> 00:21:25.000
wrote a review about it,

00:21:25.000 --> 00:21:34.000
And, uh, he said, this… and I'm just realizing this moment that this is a reason for the topic that we're on right now, is that this was in the back of my head.

00:21:34.000 --> 00:21:39.000
And I hadn't realized that, uh, you know, I didn't connect it to the Gaza news.

00:21:39.000 --> 00:21:43.000
And apparently in this book,

00:21:43.000 --> 00:21:47.000
a lot of what happened, which I've not read, a lot of what happens is

00:21:47.000 --> 00:21:54.000
Uh, the taking apart of, of, uh, situations where left and right disagree, and seeing that

00:21:54.000 --> 00:21:57.000
Uh, the situations are more complicated than you thought they were.

00:21:57.000 --> 00:22:03.000
that it isn't black and white, that it isn't this or that. And from my conversation with Al,

00:22:03.000 --> 00:22:10.000
I think… I think the left sees… I think a lot of the left believes that the right isn't even seeing things that happened.

00:22:10.000 --> 00:22:13.000
When what's happening sometimes, sometimes on the right,

00:22:13.000 --> 00:22:20.000
is they're seeing the incident, but they're gathering different information about it and seeing it with a different lens or a different…

00:22:20.000 --> 00:22:23.000
disaggregation of components. I don't know exactly how to say it.

00:22:23.000 --> 00:22:26.000
Um, and since I haven't read the book, I don't know the details in it.

00:22:26.000 --> 00:22:29.000
But that's a piece of what I'm aiming for, is…

00:22:29.000 --> 00:22:32.000
hey, how do we…

00:22:32.000 --> 00:22:38.000
Might we be able to have more interesting conversations about things that have happened if we allowed

00:22:38.000 --> 00:22:43.000
the complexity to show up in this space, and the possibility that

00:22:43.000 --> 00:22:47.000
The other side isn't completely stupid and evil.

00:22:47.000 --> 00:22:50.000
Which, which I hear a lot.

00:22:50.000 --> 00:22:54.000
like, really. Years ago, in 2015…

00:22:54.000 --> 00:22:57.000
Dean, I think this was before the 2016 election,

00:22:57.000 --> 00:23:03.000
April and I visited some deer family friends who live in Boulder, and we had a friendly political conversation in which I said,

00:23:03.000 --> 00:23:15.000
Trump is actually sort of smarter than people think he is. And there was no synonym for smart that I could use that would make them go, oh, okay, we sort of agree. So we had a little bet going, and it was… it turned into a funny thing.

00:23:15.000 --> 00:23:24.000
But, you know, smart like a mafia Don, maybe? I don't know, but it's some sort of intelligent, because nobody survives 91 federal indict… 91 indictments.

00:23:24.000 --> 00:23:31.000
Um, and winds up running the world, and, you know, closing a deal in Gaza, who isn't… who is an idiot.

00:23:31.000 --> 00:23:35.000
Like, I don't see how you can just be lucky enough to do that.

00:23:35.000 --> 00:23:41.000
Um, and… and I'll put a link to my… in fact, I created some videos

00:23:41.000 --> 00:23:47.000
Uh, during the pandemic about Trump. I created a field manual around Donald Trump. It's 6 videos.

00:23:47.000 --> 00:23:52.000
I'll just put a link to the playlist, and the very first one is, Trump is smarter than people think.

00:23:52.000 --> 00:23:58.000
Right? And it's hard to say. Uh, and so I'm trying to figure out,

00:23:58.000 --> 00:24:05.000
How do we not make the situations black and white, and like, oh my god, when they do hateful things,

00:24:05.000 --> 00:24:12.000
Like, boast that they… that they have to be given a Nobel Peace Prize. What person in their right mind does that?

00:24:12.000 --> 00:24:16.000
Like, nobody goes and says, you must give me this award, I deserve… like, that's…

00:24:16.000 --> 00:24:21.000
Well, okay, maybe that's just that this guy's style. And…

00:24:21.000 --> 00:24:27.000
And there are things that Trump and his minions have done which are horrifying and are hurting… are harming people.

00:24:27.000 --> 00:24:30.000
And I am, like, dramatically opposed to those.

00:24:30.000 --> 00:24:32.000
But I… I'm… I'm…

00:24:32.000 --> 00:24:34.000
Trying to find words to say.

00:24:34.000 --> 00:24:42.000
How do we not look at all of this and say, there's nothing in here that we can talk about, or that we can agree on, or that whatever else?

00:24:42.000 --> 00:24:46.000
So, uh, Gil, please.

00:24:46.000 --> 00:24:52.000
Somebody can be both smart and not in their right mind.

00:24:52.000 --> 00:24:59.000
somebody can be smart about certain things and stupid about other things. Somebody can be, you know, can be effective in certain ways, and…

00:24:59.000 --> 00:25:03.000
Um, uh, you know, ineffective in other ways. And this guy is complicated.

00:25:03.000 --> 00:25:12.000
Uh, and that's part of the challenge here. Um, you know, again, I don't think we're seeing the same facts. I sometimes hop between MSNBC and Fox News.

00:25:12.000 --> 00:25:17.000
In the evening. And you'd think they're on different planets.

00:25:17.000 --> 00:25:27.000
stories just, you know, covered on one, not covered at all on the other, not just covered differently, but just not covered at all. Things that we might think totally important.

00:25:27.000 --> 00:25:29.000
Not there all week on Fox.

00:25:29.000 --> 00:25:33.000
So, there's that as kind of one of the bases of it.

00:25:33.000 --> 00:25:35.000
Um, um…

00:25:35.000 --> 00:25:42.000
But I hear… I hear and really resonate, Jerry, with what you're saying, um, because we're… there's a tendency

00:25:42.000 --> 00:25:48.000
And I don't think this is left or right, maybe it's modern capitalist culture of really

00:25:48.000 --> 00:25:55.000
polarizing and calling things black and white that are complex, and, you know, washing out nuance.

00:25:55.000 --> 00:26:01.000
Um, and, um, yeah, and it's part of the mess that we're in.

00:26:01.000 --> 00:26:06.000
I've shared before, uh, you know, a friend I've made on the Magarite.

00:26:06.000 --> 00:26:10.000
introduced by a mutual friend who we both love and trust, and uh…

00:26:10.000 --> 00:26:13.000
We had a fascinating first conversation.

00:26:13.000 --> 00:26:19.000
Uh, ostensibly, it was going to be about climate, and I was going to change his mind about things, and uh…

00:26:19.000 --> 00:26:25.000
discovered him changing my mind about things around supply-side economics and other stuff.

00:26:25.000 --> 00:26:27.000
We came out of that conversation loving each other.

00:26:27.000 --> 00:26:30.000
We're still friends, we still disagree.

00:26:30.000 --> 00:26:36.000
We have changed these as… you know, we sometimes… we occasionally agree in surprising ways, and often don't.

00:26:36.000 --> 00:26:40.000
But we found a way to have that different kind of conversation that you're talking about.

00:26:40.000 --> 00:26:47.000
Um, I'm just back from the Sustainable Brands Conference in San Diego, and one of the presentations on

00:26:47.000 --> 00:26:55.000
Monday was from a guy named Bill Shireman. He's a longtime friend of mine, who's probably my favorite Republican environmentalist.

00:26:55.000 --> 00:26:57.000
Um, yeah, and um…

00:26:57.000 --> 00:27:02.000
used to, uh, used to organize with Nader, um, around, uh, uh,

00:27:02.000 --> 00:27:04.000
the California Bottle Bill.

00:27:04.000 --> 00:27:11.000
Um, and parted ways on other political issues. Bill did a presentation about how to talk to MAGA.

00:27:11.000 --> 00:27:19.000
And one of the things you did, one of the… one of the pieces that stood out was he set up a pair of slides of four MAGA people and four progressive people.

00:27:19.000 --> 00:27:24.000
And said, look, you know, these sides are not at all the same.

00:27:24.000 --> 00:27:31.000
you know, on the Republican side, you got, you know, you've got Bannon and you've got Pence, and you've got Alex Jones, and you've got, uh, whoever, Mike Johnson.

00:27:31.000 --> 00:27:37.000
Not all the same people, not all the same thinking, analyses, political positions, and so forth, but we lump them.

00:27:37.000 --> 00:27:39.000
And you can do the same thing on the left.

00:27:39.000 --> 00:27:44.000
Uh, and it's very easy to, you know, to…

00:27:44.000 --> 00:27:49.000
Humans seem to love to categorize.

00:27:49.000 --> 00:27:50.000
We do.

00:27:50.000 --> 00:27:58.000
Uh, we love… we love to take shades of gray, as Dave might talk about, and try to, you know, try to delineate them and put them into boxes, and say, this is this and not that.

00:27:58.000 --> 00:28:05.000
Uh, and real often in the physical world, it's not that way. Even around things like shades of Ray and colors. You know, we've talked about the

00:28:05.000 --> 00:28:09.000
The color maps that are red… red and named differently.

00:28:09.000 --> 00:28:15.000
In different cultures. You know, what I will call blue someone in Japan will call green.

00:28:15.000 --> 00:28:17.000
So how do we have a conversation that doesn't acknowledge that?

00:28:17.000 --> 00:28:21.000
and Russian apparently has 4 different words for blue, yeah.

00:28:21.000 --> 00:28:28.000
So, um… so this is… this is really important territory, and it's very challenging, and we're in a culture that doesn't support

00:28:28.000 --> 00:28:36.000
the kind of conversation that you're proposing that we have.

00:28:36.000 --> 00:28:37.000
Thanks, Gil.

00:28:37.000 --> 00:28:38.000
Yeah.

00:28:38.000 --> 00:28:44.000
Any thoughts on this? Where do we go with this? What, um… Kalia, you mentioned in the chat,

00:28:44.000 --> 00:28:53.000
that the left is, like, throwing itself on the spike of very narrow issues that are truly controversial.

00:28:53.000 --> 00:29:00.000
Any other thoughts on what you wish would happen here?

00:29:00.000 --> 00:29:04.000
I mean… hmm…

00:29:04.000 --> 00:29:10.000
Yeah, I have…

00:29:10.000 --> 00:29:11.000
Can't hear you, Julia.

00:29:11.000 --> 00:29:12.000
Um, Kalia, why don't you turn your video off, because the audio is clipping a lot.

00:29:12.000 --> 00:29:16.000
I'm assuming we operate in here under Chatham House Renewals, because I have opinions.

00:29:16.000 --> 00:29:20.000
And if you have the video off, we'll probably hear you better, because we're…

00:29:20.000 --> 00:29:21.000
I'd love to hear you.

00:29:21.000 --> 00:29:22.000
Um, sir.

00:29:22.000 --> 00:29:30.000
Are we… okay. I mean, I assume we operate here under Chatham House rules, because I have opinions in this space that…

00:29:30.000 --> 00:29:32.000
have already gotten me canceled.

00:29:32.000 --> 00:29:39.000
Wait, hang… I'm sorry to interrupt, but Jerry, you post these videos publicly, don't you?

00:29:39.000 --> 00:29:40.000
Yeah, so just be aware of that, Khalil.

00:29:40.000 --> 00:29:45.000
I do. Um, so Kalia… so, Kalia, these videos go straight to YouTube, and we don't operate under Chatham House.

00:29:45.000 --> 00:29:50.000
And I've never made that declaration up front, so if you want to not say what you're going to say,

00:29:50.000 --> 00:29:51.000
We will totally understand.

00:29:51.000 --> 00:30:04.000
I… then you can't even bring up what I said, and I should never have said anything in chat, so I'm sorry. That's how intense this issue is, and I'd ask you to take this out of the video before you post it.

00:30:04.000 --> 00:30:05.000
Okay.

00:30:05.000 --> 00:30:08.000
Sorry, I can't even talk.

00:30:08.000 --> 00:30:09.000
Oh, wow. Can you tell me what… I'm sorry.

00:30:09.000 --> 00:30:11.000
Thanks, Kalia.

00:30:11.000 --> 00:30:12.000
Adam House rules it. You tell me what…

00:30:12.000 --> 00:30:19.000
Sure. Chatham House is an organization in England, and when you say something is under Chatham House rules, it means

00:30:19.000 --> 00:30:23.000
You, uh, everything that's said under this… in this meeting,

00:30:23.000 --> 00:30:32.000
Which cannot be identified with the speaker. You can't say, so-and-so said this. You can, my understanding under Chatham House is, you can write about what got said,

00:30:32.000 --> 00:30:36.000
You just can't attribute it to anybody without their agreement. So if you need to quote

00:30:36.000 --> 00:30:41.000
If Kevin said something that you want to write about in an article, you'd have to contact Kevin, get his approval.

00:30:41.000 --> 00:30:46.000
to say Kevin said it, but I believe you can still say someone said X.

00:30:46.000 --> 00:30:47.000
Yes.

00:30:47.000 --> 00:30:48.000
Right.

00:30:48.000 --> 00:30:49.000
But you can't reveal who was there, because sometimes.

00:30:49.000 --> 00:30:50.000
Right. Yeah.

00:30:50.000 --> 00:30:51.000
Correct.

00:30:51.000 --> 00:30:53.000
Thank you.

00:30:53.000 --> 00:30:58.000
saying that this was said. will be immediately linked to the one person in the room who would have said it.

00:30:58.000 --> 00:30:59.000
Yep. Yep.

00:30:59.000 --> 00:31:08.000
Yep, yep. And I… Jerry, I was not clear about this for a long time. I was very surprised when I first discovered that OGM was being posted to YouTube, because I had talked about very personal things.

00:31:08.000 --> 00:31:12.000
In these meetings that I assumed were just among us. So, the ground rules

00:31:12.000 --> 00:31:19.000
should be made more clear, especially if there's new people coming in.

00:31:19.000 --> 00:31:23.000
I have a question, because I think in the posting to YouTube.

00:31:23.000 --> 00:31:27.000
The chat is not shared, it's just the video, correct?

00:31:27.000 --> 00:31:32.000
I don't post the chat on YouTube, but I do make the chat very available.

00:31:32.000 --> 00:31:37.000
Right. But I mean, in terms of this particular session and CALIA.

00:31:37.000 --> 00:31:42.000
what you raised in the chat. It wasn't voiced in the video.

00:31:42.000 --> 00:31:44.000
So, I think you're okay.

00:31:44.000 --> 00:31:51.000
Oh, I… yeah, that's fine, and I… but I will, I will, um, I don't usually edit these. I will edit, uh, Kalia's drop-in,

00:31:51.000 --> 00:31:57.000
And now it's much more complicated because we're talking about it, so I'm gonna have to edit twice.

00:31:57.000 --> 00:32:01.000
But I will also clip what, uh, Kalia wrote in the chat.

00:32:01.000 --> 00:32:04.000
Uh, as well.

00:32:04.000 --> 00:32:08.000
Before I share the chat back up.

00:32:08.000 --> 00:32:12.000
Cool, then that… that didn't work so well, my apologies.

00:32:12.000 --> 00:32:21.000
And I should mention more often that these videos I do post directly, I'm a big believer in sort of open conversations, and these videos do go

00:32:21.000 --> 00:32:26.000
to YouTube, and that will have an effect on, uh,

00:32:26.000 --> 00:32:27.000
what we decide to talk about, and I'm…

00:32:27.000 --> 00:32:30.000
quite aware of that. Um…

00:32:30.000 --> 00:32:32.000
So, my apologies for not…

00:32:32.000 --> 00:32:38.000
repeating that more often, because we actually all should be quite aware of that.

00:32:38.000 --> 00:32:40.000
Doug.

00:32:40.000 --> 00:32:49.000
So, yeah, I… I, um… I was really… it… I was really intrigued by your… your intro to this session.

00:32:49.000 --> 00:32:56.000
And had… had… an experience in the last 24 hours with a post.

00:32:56.000 --> 00:33:15.000
that, um… sort of… the combination of the two, I think, is… is… is worth sharing. So there was… there was a post that… did, like, a serious drill down on… our current…

00:33:15.000 --> 00:33:26.000
Um, Supreme Court… head, um, and his relationship and history with the Voting Rights Act.

00:33:26.000 --> 00:33:31.000
which is long and deep and anti. with a capital A.

00:33:31.000 --> 00:33:44.000
And I read this piece, which was… very grounded, very credible, and… Um, shed him for me in a completely different light.

00:33:44.000 --> 00:33:48.000
Like, I've experienced his position as sort of an.

00:33:48.000 --> 00:33:56.000
an unknown quasi-neutral? in terms of the personae that I think he's publicly attempted to achieve.

00:33:56.000 --> 00:34:05.000
for himself, Roberts. Um, but what this post made clear was, um, no, he's hardcore.

00:34:05.000 --> 00:34:10.000
ideologue about certain things related to presidential power and related to.

00:34:10.000 --> 00:34:22.000
killing the Voting Rights Act. And… there was the theater and Illusion, the public persona, and then there was the Oh.

00:34:22.000 --> 00:34:31.000
that. And then connecting that to… So we know which way this whole redistricting thing is going to come out.

00:34:31.000 --> 00:34:39.000
Um, and it's not going to be good. And, um…

00:34:39.000 --> 00:34:48.000
And my… orientation to receiving that recalibration. Like, it was exactly what you described in the.

00:34:48.000 --> 00:34:55.000
Intro to this session of receiving something that's just like, oh.

00:34:55.000 --> 00:35:04.000
was… I can be reactive to that, or… I can just sort of recalibrate.

00:35:04.000 --> 00:35:12.000
my understanding of the world. Like, that's the way that piece of the existing puzzle.

00:35:12.000 --> 00:35:20.000
is, in fact… And, um… It gives me a better sense of.

00:35:20.000 --> 00:35:27.000
the degree to which. Effectively, the… The court system has been zeroed out as well.

00:35:27.000 --> 00:35:39.000
Well, while the, sort of. wishful thinking, underlying sense impression up to that moment was, maybe there's some salvation to be had out of the court system, but no, it's been done, like, taken care of.

00:35:39.000 --> 00:35:40.000
Mm-mm.

00:35:40.000 --> 00:35:46.000
Going back to… going back to when this guy was a law clerk for Rehnquist.

00:35:46.000 --> 00:35:53.000
And, um, and it was sort of like… Um.

00:35:53.000 --> 00:36:02.000
there are all those knock-on recalibration, reconfiguration of. the way of seeing what is.

00:36:02.000 --> 00:36:13.000
as sort of a ripple effect. It's sort of an update of the vision of the map, of the picture.

00:36:13.000 --> 00:36:16.000
Can you describe that a little bit more?

00:36:16.000 --> 00:36:22.000
Yeah, so… you know, if I'm carrying this mosaic of.

00:36:22.000 --> 00:36:29.000
you know, the state of… our government, and it's… it's decimation.

00:36:29.000 --> 00:36:36.000
Um, and I'm looking for pockets of integrity being held. I'm looking for.

00:36:36.000 --> 00:36:42.000
pockets of structural, you know, persistence against. the destruction and collapse.

00:36:42.000 --> 00:36:49.000
Uh, and I believe there are still some features of that landscape effective functioning and operating.

00:36:49.000 --> 00:36:55.000
And all of a sudden. like, the one sort of remaining pillar.

00:36:55.000 --> 00:37:01.000
Uh, that… that held some promise is neutralized… is zeroed out.

00:37:01.000 --> 00:37:10.000
So, effectively, it's all gone. And how bad… Will they make it? How bad does it get?

00:37:10.000 --> 00:37:15.000
how much will that…

00:37:15.000 --> 00:37:29.000
manifest, you know, in consequences. And I'm, you know, picking up… data bits about… failure sectors in the economy.

00:37:29.000 --> 00:37:34.000
That are not public, you know, that haven't been, like, highlighted.

00:37:34.000 --> 00:37:43.000
you know, the number of. farmer, uh, bankruptcy filings under, under, under 12.

00:37:43.000 --> 00:37:51.000
is going through the roof. And, uh, and they're not… they don't have the labor to harvest crops.

00:37:51.000 --> 00:37:56.000
So, like, that, you know, how soon do the supermarket shelves start going there?

00:37:56.000 --> 00:38:02.000
you know, this is, like, now. This isn't some objective future, this is now.

00:38:02.000 --> 00:38:08.000
And, um… you know.

00:38:08.000 --> 00:38:15.000
since the… the current course doesn't suggest.

00:38:15.000 --> 00:38:21.000
actions within agencies. are being governed by any sense of rule of law anymore.

00:38:21.000 --> 00:38:26.000
So, you know, when does Social Security check stop?

00:38:26.000 --> 00:38:31.000
For me, because of whatever category I fall into.

00:38:31.000 --> 00:38:43.000
or whatever office gets decimated through layoffs. So, it's… it's, um… It's very much, uh, trying to… find clarity.

00:38:43.000 --> 00:38:51.000
personal clarity, sense of balance. what is reality, you know, what is my reality?

00:38:51.000 --> 00:39:01.000
Now… I don't… I really endeavor… to not react.

00:39:01.000 --> 00:39:04.000
But to figure out, you know, how to relate.

00:39:04.000 --> 00:39:08.000
It's not even rising to the level of how to respond.

00:39:08.000 --> 00:39:16.000
Or how to act, or do, or whatever. Like, that's a whole secondary thing. It's like.

00:39:16.000 --> 00:39:29.000
how to… how to relate. to the scale and scope of… of… changing reality, uh, and find my ground first.

00:39:29.000 --> 00:39:36.000
before going to the okay. So, is there a way I want to respond or directly engage?

00:39:36.000 --> 00:39:48.000
in… in some kind of collaborative way, or… communication or… or… you know, engagement way, like… going on Saturday to the local.

00:39:48.000 --> 00:39:52.000
You know, no kings. demonstration.

00:39:52.000 --> 00:40:01.000
So, just slowing it down. Oh! Um, and checking in.

00:40:01.000 --> 00:40:02.000
Um, thanks, Doug.

00:40:02.000 --> 00:40:03.000
So I just, yeah, I'm complete.

00:40:03.000 --> 00:40:06.000
You've brought a bunch of things into my…

00:40:06.000 --> 00:40:08.000
brain that I want to share out.

00:40:08.000 --> 00:40:11.000
Um, first,

00:40:11.000 --> 00:40:20.000
I'm among probably a large group of Americans who are pretty convinced that, um, ICE tracking down immigrants, a lot of whom are agricultural farm workers,

00:40:20.000 --> 00:40:25.000
And, uh, the tariffs and all that kind of stuff would lead to, by now, buy now,

00:40:25.000 --> 00:40:30.000
pretty miserable inflation and food shortages and other kinds of things.

00:40:30.000 --> 00:40:33.000
Um, there are… there are some price bumps, but…

00:40:33.000 --> 00:40:39.000
I don't… I don't think that… I don't think that dreadful future has materialized. The system has adapted

00:40:39.000 --> 00:40:42.000
And this… the ball… the shoe may drop later, I don't know.

00:40:42.000 --> 00:40:49.000
But, uh, but it didn't materialize the way the catastrophizers said immediately. It was going to. And that happens

00:40:49.000 --> 00:40:51.000
all the time on all sides, right?

00:40:51.000 --> 00:40:54.000
So, that reminded me of the book Super Forecasting,

00:40:54.000 --> 00:40:59.000
Uh… by Philip Tetlock.

00:40:59.000 --> 00:41:08.000
And he talks… he talks in the book about what makes a good forecast, and the problem is that most futurists and forecasters and all that make crappy forecasts, where…

00:41:08.000 --> 00:41:11.000
You really can't tell whether they were right or wrong.

00:41:11.000 --> 00:41:17.000
And that's the sign of a good weasel forecast, is you say something that gets you some news,

00:41:17.000 --> 00:41:24.000
And that can't be pinned down later on. It's like, ah, I was just off on the date, it happened but 5 years later. Like, yeah, that was a bad forecast.

00:41:24.000 --> 00:41:27.000
And so he has criteria with the Good Judgment Project.

00:41:27.000 --> 00:41:31.000
And he's found some people who are really, really good super forecasters.

00:41:31.000 --> 00:41:37.000
And I'm wondering to what extent, and this would be a very nice sense-making, global-brain-y kind of thing,

00:41:37.000 --> 00:41:40.000
To what extent can or should

00:41:40.000 --> 00:41:48.000
people writing about stuff try to do better on these fronts, and then judge themselves afterward. And I highly respect

00:41:48.000 --> 00:41:54.000
bloggers and substackers and other sorts of people who occasionally say, hey, here's how I did on last year's

00:41:54.000 --> 00:42:01.000
predictions or on last, you know, whatever it is, when they go back and grade themselves, even if sometimes they're a little lenient on themselves,

00:42:01.000 --> 00:42:05.000
That's interesting, because at least there's some kind of feedback loop

00:42:05.000 --> 00:42:07.000
of what's happening there, right?

00:42:07.000 --> 00:42:16.000
Um, so, uh, I'm very interested in the feedback and the social feedback, and also then I'll add

00:42:16.000 --> 00:42:22.000
Forecasting is really hard because some of these systems that we're talking about, like global warming, tipping points, and all that,

00:42:22.000 --> 00:42:28.000
Deeply nonlinear, and by the time you detect the third dot or the fourth dot, the fifth dot is

00:42:28.000 --> 00:42:34.000
way the hell north of where you thought it was gonna be, and we're in serious, serious trouble, and how do you… how do you use

00:42:34.000 --> 00:42:40.000
the feedback I'm describing and public discourse and news and other sorts of things that are…

00:42:40.000 --> 00:42:43.000
heightened that are improved in some way by doing

00:42:43.000 --> 00:42:45.000
some of what I just described.

00:42:45.000 --> 00:42:50.000
Um, in a situation where, when one of these things runs amok, it could run really amok.

00:42:50.000 --> 00:42:52.000
the way Trump handles foreign policy,

00:42:52.000 --> 00:43:01.000
Man, if Putin feels cornered and decides to throw nukes, that's gonna change the game considerably, right? And I don't know how these things play out.

00:43:01.000 --> 00:43:04.000
But, um, but I'm wondering how all that, uh…

00:43:04.000 --> 00:43:07.000
how all that works. Gil, please.

00:43:07.000 --> 00:43:09.000
Totally yes, Jerry.

00:43:09.000 --> 00:43:14.000
And, um, you know, again, it's the hazard of, of, uh…

00:43:14.000 --> 00:43:18.000
you know, the lack of sensitivity and complexity.

00:43:18.000 --> 00:43:24.000
And for people to see nuance and see complex systems and understand the cause and effect is not all that it's cracked up to be.

00:43:24.000 --> 00:43:28.000
Uh, and how do you navigate, uh, in the midst of all that uncertainty?

00:43:28.000 --> 00:43:38.000
Uh, on the prediction thing, the great Ken Watt was trying to put together something decades ago to do a systematic retrospective analysis of predictions.

00:43:38.000 --> 00:43:49.000
Which I don't know if anybody's ever done. Um, you know, you look at market touts who are predicting the same thing for decades, and then all of a sudden they're right when that thing happens, you know, but they've been saying it every year, forever.

00:43:49.000 --> 00:43:55.000
I've been describing myself lately as a futurist who's given up predicting the future.

00:43:55.000 --> 00:43:58.000
Do you think it's a fool's game at this point.

00:43:58.000 --> 00:43:59.000
Um, something else I wanted to say about the…

00:43:59.000 --> 00:44:06.000
Um, the Institute for the Future says we don't do predictions, we make forecasts, which are

00:44:06.000 --> 00:44:10.000
practical, plausible projections of something that might happen in the future, but we don't know, and nobody can tell which one's gonna play out.

00:44:10.000 --> 00:44:15.000
Yeah, yeah.

00:44:15.000 --> 00:44:16.000
Great. Right.

00:44:16.000 --> 00:44:21.000
Yeah, and, you know, and that's the power of scenario analysis, among other tools, exactly for that. People think it's predictive, but it's not. It's for… it's to sensitize us to…

00:44:21.000 --> 00:44:25.000
possibility. Uh, and hopefully change the way that we think about stuff.

00:44:25.000 --> 00:44:28.000
Um, there was something else I wanted to say, but it slipped, so…

00:44:28.000 --> 00:44:30.000
Off to someone else.

00:44:30.000 --> 00:44:34.000
Oh, yeah, yes, the thing you said, Jerry, about, um…

00:44:34.000 --> 00:44:42.000
Uh, we haven't seen the impact of the farm labor shortage yet. Don't get too confident.

00:44:42.000 --> 00:44:46.000
Uh, it's still the first season. There's still more harvest to come. It's, uh…

00:44:46.000 --> 00:44:54.000
you know, I don't have… I don't have detailed analysis on it, but the mood that I'm getting is that there's a mess looming.

00:44:54.000 --> 00:44:55.000
I hear ya. Um…

00:44:55.000 --> 00:44:56.000
Yeah.

00:44:56.000 --> 00:45:04.000
And I'd love to sort of say that that means this number by this date, or something. And I don't know that I challenge OGMers to…

00:45:04.000 --> 00:45:09.000
to always pin things down that way, but we might… we might want to have a session

00:45:09.000 --> 00:45:12.000
About what a good forecast looks like, and just train ourselves a bit. Go find a couple videos and have somebody

00:45:12.000 --> 00:45:14.000
Yeah.

00:45:14.000 --> 00:45:16.000
Volunteer to brief us.

00:45:16.000 --> 00:45:17.000
For sure.

00:45:17.000 --> 00:45:19.000
on how to be more precise about forecasts.

00:45:19.000 --> 00:45:28.000
For sure. Let me personalize a bit, coming off of what Doug said. Um, on the Social Security thing, we've been looking at a bunch of financial and real estate decisions, and early this year,

00:45:28.000 --> 00:45:33.000
We decided that we couldn't make certain moves because Social Security might just get yanked.

00:45:33.000 --> 00:45:35.000
Which would completely change how our spectrum.

00:45:35.000 --> 00:45:42.000
financial options. We've come to the conclusion now that it's probably not going to get yanked for folks like us.

00:45:42.000 --> 00:45:47.000
you know, on… on… been… we've been on Social Security for 10 years, etc.

00:45:47.000 --> 00:45:51.000
Uh, for folks coming into the system, very much at risk. People not yet retired,

00:45:51.000 --> 00:45:57.000
don't count on it at all. People may be a year or two in, may be at risk. I think for later folks, probably not.

00:45:57.000 --> 00:46:00.000
But, again, so there's a calculation.

00:46:00.000 --> 00:46:06.000
based on very incomplete data and all sorts of stuff that we have no way to know anything about.

00:46:06.000 --> 00:46:09.000
And yet, we have to make decisions.

00:46:09.000 --> 00:46:15.000
And one of the more stressful things we've worked through, that we can remember.

00:46:15.000 --> 00:46:20.000
And decision-making under uncertainty is one of those monster themes, right?

00:46:20.000 --> 00:46:22.000
Um, Stacy, please.

00:46:22.000 --> 00:46:30.000
Yeah, um, speaking to your idea about prediction, as I was thinking about this yesterday, because as you know, I'm interested in engaging.

00:46:30.000 --> 00:46:38.000
people in conversations. And I was just thinking it would be so nice if we could have a conversation that starts with.

00:46:38.000 --> 00:46:42.000
If this is true, then we would expect to see this.

00:46:42.000 --> 00:46:50.000
If this is true, we would expect to see this. My particular area that I was focused on has to do with immigration.

00:46:50.000 --> 00:46:54.000
Because I'm trying to convince the people in my community.

00:46:54.000 --> 00:47:02.000
that this is a money grab and a for-profit detention, because I'm combating the local.

00:47:02.000 --> 00:47:10.000
misinformation that's going on. What I'm actually seeing… I mean, in one case, I'm very happy, after somebody was.

00:47:10.000 --> 00:47:14.000
detained for over 2 months. they were finally released.

00:47:14.000 --> 00:47:22.000
I'm grateful they were released. I don't want to throw attention on the judges that are eventually releasing the people.

00:47:22.000 --> 00:47:27.000
But at the same time, I have a feeling we're going to look back.

00:47:27.000 --> 00:47:32.000
And we're gonna see all this money that was spent detaining people.

00:47:32.000 --> 00:47:40.000
to finally release them back to their families. So to me, it would be productive to say.

00:47:40.000 --> 00:47:48.000
Okay, let's look at that. That's one scenario. Let's see how many people, after they finally show up in court.

00:47:48.000 --> 00:47:54.000
we wind up sending back. At least if we could have a conversation, and maybe.

00:47:54.000 --> 00:48:03.000
have that… taped. Have that drive the spotlight to look on individual cases.

00:48:03.000 --> 00:48:10.000
And what's going on locally, where, on a local level, we really see firsthand.

00:48:10.000 --> 00:48:15.000
who's getting targeted, and why they're getting targeted, and all those things.

00:48:15.000 --> 00:48:24.000
It could bring the people in the middle together. You know, Gil put in the chat that the speaker had said that one way of looking at the difference.

00:48:24.000 --> 00:48:30.000
between the left and the right is that the right look, you know, the right are, like, looking at themselves as protectors.

00:48:30.000 --> 00:48:37.000
And the left is liberators, and to a certain degree, I think that's true, and for me, I always look at the intersection.

00:48:37.000 --> 00:48:42.000
You know, where are those people right in the middle? Because depending on who I'm talking to.

00:48:42.000 --> 00:48:50.000
I try to get them to see the other piece that they're missing. So, like, if I'm talking to that protector person.

00:48:50.000 --> 00:48:56.000
I'm going to recognize that in showing how this action is a protecting one.

00:48:56.000 --> 00:49:05.000
And vice versa. But, um, again, we're always behind the eight ball of predicting, like, why can't we jump ahead.

00:49:05.000 --> 00:49:11.000
and get together, all of us, and say, okay, everybody, let's brainstorm.

00:49:11.000 --> 00:49:15.000
We're not saying who's right or wrong. If this is the case.

00:49:15.000 --> 00:49:19.000
This is what we're gonna see. If this is the case.

00:49:19.000 --> 00:49:25.000
This is what we're going to say. Let's just agree on… What would happen if.

00:49:25.000 --> 00:49:30.000
instead of digging down on, this is what's happening.

00:49:30.000 --> 00:49:31.000
So, some… thanks, Stacy. So, making these…

00:49:31.000 --> 00:49:33.000
Over.

00:49:33.000 --> 00:49:43.000
forecasts, and I'll use the word very loosely, more provisional or conditional on some facts on the ground, or things like that.

00:49:43.000 --> 00:49:46.000
Um, I think that makes sense.

00:49:46.000 --> 00:49:47.000
Yeah.

00:49:47.000 --> 00:49:51.000
It's the meaning on what the measurement would… Like, let's just agree on that, because also.

00:49:51.000 --> 00:49:56.000
It will help people come in at a beginner's level and generate some ideas.

00:49:56.000 --> 00:49:59.000
Like, let's just start at the beginning's level.

00:49:59.000 --> 00:50:04.000
Yeah. You've also reminded me that the same administration that is

00:50:04.000 --> 00:50:09.000
doing those kinds of things, um, has unmarked cars on the street with, uh,

00:50:09.000 --> 00:50:15.000
ICE people who have no badges visible and have masks on, who are abducting people.

00:50:15.000 --> 00:50:22.000
And, um, I grew up partly in Argentina. I'm old enough that we left Argentina just before the dirty war started.

00:50:22.000 --> 00:50:26.000
And I went back in…

00:50:26.000 --> 00:50:31.000
Uh, 89, I guess, at some point? I think… no, sorry, 80… in 85.

00:50:31.000 --> 00:50:38.000
I had a project, actually, that took me to Buenos Aires, Argentina, and uh… as a goodbye gift, they gave me the book Nunca Mas,

00:50:38.000 --> 00:50:42.000
Which means never again, which is a book compiled out of

00:50:42.000 --> 00:50:47.000
All of the testimonies from the Truth and Reconciliation Commissions that happened in Argentina after the Dirty War.

00:50:47.000 --> 00:50:52.000
And one of the interesting factors in Argentina was, during the dirty War,

00:50:52.000 --> 00:50:54.000
Um, the Ford Falcon.

00:50:54.000 --> 00:51:02.000
A dark green Ford Falcon was a very scary car to see in the street, because that's what the military police and others used

00:51:02.000 --> 00:51:07.000
To abduct people. So if a Ford Falcon pulled up in front of your house, they were probably gonna, like,

00:51:07.000 --> 00:51:10.000
search you and maybe take you away, and maybe you wouldn't be seen again.

00:51:10.000 --> 00:51:15.000
And so, for me, the idea that

00:51:15.000 --> 00:51:22.000
people on American streets, and I won't say American citizens, because maybe they're not, I don't know, but people walking down American streets are being abducted

00:51:22.000 --> 00:51:26.000
Uh, with no identification, and we don't know where they go, is deeply

00:51:26.000 --> 00:51:29.000
Deeply frightening, because it leads…

00:51:29.000 --> 00:51:31.000
for me, straight to things that I…

00:51:31.000 --> 00:51:33.000
think are horrible historically.

00:51:33.000 --> 00:51:41.000
Um… and I don't know which parts of that little narrative to complexify and to say, oh, but, and this there, and I don't know.

00:51:41.000 --> 00:51:46.000
I don't know. It's, um, it's… these are… we live in troubling, uh, scary times.

00:51:46.000 --> 00:51:50.000
And I'm… part of this conversation is to say

00:51:50.000 --> 00:51:56.000
How do we handle these conversations in a way that lets us be… remain

00:51:56.000 --> 00:51:59.000
a bit pliable or permeable.

00:51:59.000 --> 00:52:02.000
Uh, so that we can find more understanding, and so forth.

00:52:02.000 --> 00:52:04.000
Alright, Gil, go ahead.

00:52:04.000 --> 00:52:06.000
And, um…

00:52:06.000 --> 00:52:14.000
you know, put the masked… the masked armed thugs in unmarked vehicles together with stand-your-ground laws.

00:52:14.000 --> 00:52:17.000
And then what happens?

00:52:17.000 --> 00:52:19.000
Well, also, um…

00:52:19.000 --> 00:52:22.000
the Black Panther Party,

00:52:22.000 --> 00:52:25.000
originally was the Black Panther Party for Self-Defense, I believe.

00:52:25.000 --> 00:52:26.000
Mm-hmm.

00:52:26.000 --> 00:52:29.000
And they, um…

00:52:29.000 --> 00:52:31.000
found a law that said you can

00:52:31.000 --> 00:52:37.000
stand, uh, you can be armed and stand as long as you're X number of yards or feet away from police,

00:52:37.000 --> 00:52:41.000
You can stand there armed and watch them and, you know, it's legal.

00:52:41.000 --> 00:52:42.000
Uh, and so…

00:52:42.000 --> 00:52:45.000
No, but legal… but we're in a time when legal doesn't matter.

00:52:45.000 --> 00:52:46.000
I totally agree.

00:52:46.000 --> 00:52:52.000
Because what they're doing is not legal, and they're, you know, and they're arresting people who are standing there videoing them from across the street.

00:52:52.000 --> 00:52:53.000
So, yeah.

00:52:53.000 --> 00:53:01.000
Yeah, they're operating in extra-legal ways, and one of my fears is that the court system, the entire legal system, is now disabled.

00:53:01.000 --> 00:53:03.000
Well, hang on, um…

00:53:03.000 --> 00:53:06.000
Yeah. Good.

00:53:06.000 --> 00:53:18.000
One of the other talks at Sustainable Browns was from Andrew Winston, uh, saying that… I'm gonna go a little sideways for a moment here, saying that he keeps… he's a major speaker to sustainable business, and he's always asked, he says,

00:53:18.000 --> 00:53:20.000
is sustainability dead?

00:53:20.000 --> 00:53:24.000
And he said, no, it's not dead, it's under attack.

00:53:24.000 --> 00:53:34.000
Which is different. You know, and things aren't under attack unless there's reason for them to be attacked. So, same thing here. The court system is not over, it's very much under threat.

00:53:34.000 --> 00:53:42.000
Uh, most of the decisions, uh, I mean, there's, like, hundreds of lawsuits against these guys, and most of them, they have lost.

00:53:42.000 --> 00:53:46.000
Um, what's up for question is where the Supremes are gonna go.

00:53:46.000 --> 00:53:53.000
Uh, because we're at the mercy here of a 40-year project by Rehnquist and Alito to do what they're doing.

00:53:53.000 --> 00:53:54.000
Mm-hmm.

00:53:54.000 --> 00:53:57.000
Uh, this was laid out back during the Nixon administration.

00:53:57.000 --> 00:54:01.000
Or when I were rigging, I guess is what they were under. They were not… they're not quite old enough for that.

00:54:01.000 --> 00:54:12.000
Um, um, you know, so we don't know. You know, there's this voting rights decision that could come this week or next week that could change, you know, that could lock the elections down.

00:54:12.000 --> 00:54:19.000
For a long time to come, if we have elections. So, I don't mean to make light of it, uh, but the courts are an important battleground.

00:54:19.000 --> 00:54:28.000
Um, uh, notable yesterday, I don't know if people saw this on the news, but pretty much unified the national news organizations refused to

00:54:28.000 --> 00:54:31.000
to sign Pete Hegseth's loyalty oath.

00:54:31.000 --> 00:54:41.000
And maybe people are starting to realize that, uh, that instead of letting, uh, Trump pick you off one by one, as surprisingly the major law firms did.

00:54:41.000 --> 00:54:43.000
And a lot of the universities did.

00:54:43.000 --> 00:54:47.000
People can actually forge common purpose and fight back.

00:54:47.000 --> 00:54:53.000
Um, and what does that mean in terms of bad Supreme Court decisions? I don't know.

00:54:53.000 --> 00:54:57.000
Um, but I'm not, you know, game ain't over till the fat lady's sung, or whatever the…

00:54:57.000 --> 00:54:59.000
the expression is, and…

00:54:59.000 --> 00:55:03.000
She ain't sung yet.

00:55:03.000 --> 00:55:06.000
Surprised that saying had so much, you know, such long legs.

00:55:06.000 --> 00:55:07.000
Over time.

00:55:07.000 --> 00:55:10.000
Yeah. Yeah. Well, the Pat Lady had short legs, but that's a different thing.

00:55:10.000 --> 00:55:13.000
Yeah, who knows?

00:55:13.000 --> 00:55:16.000
Anyone else? Thoughts on this topic?

00:55:16.000 --> 00:55:18.000
concerns…

00:55:18.000 --> 00:55:35.000
disagreements? Wishes.

00:55:35.000 --> 00:55:38.000
Should we search topics?

00:55:38.000 --> 00:55:41.000
No, it's obviously time to be quiet for a while.

00:55:41.000 --> 00:55:48.000
We could be quiet for a little while, see what shows up.

00:55:48.000 --> 00:55:54.000
quiet. Um… I do think one of the strategies you outlined at the very start.

00:55:54.000 --> 00:56:02.000
is being quiet long enough to understand that you may have been wrong about something you assumed to be right.

00:56:02.000 --> 00:56:08.000
And, um… unfortunately, we're not given time to do that anymore.

00:56:08.000 --> 00:56:12.000
I mean, I don't think we've been given time to do that for 30 or 40 years.

00:56:12.000 --> 00:56:19.000
Um, we used to have, and I still go to church, and there's some meditation time there, but.

00:56:19.000 --> 00:56:30.000
Even that is typically 30 seconds, you know? I mean, if we have a really meaningful sermon, maybe there'll be 2 minutes where people just kind of.

00:56:30.000 --> 00:56:33.000
And, you know, what do I want to take home from this?

00:56:33.000 --> 00:56:42.000
But I do think we… We're so overstressed, we're so sleep-deprived.

00:56:42.000 --> 00:56:51.000
that we… we don't know how to handle the, uh… confused inputs that are coming from all these different directions and contradicting themselves.

00:56:51.000 --> 00:56:56.000
One of my favorite hashtags lately has been discombobulation.

00:56:56.000 --> 00:57:02.000
You know, disinformation… Leads to deception.

00:57:02.000 --> 00:57:07.000
leads to discord. Leads to discombobulation.

00:57:07.000 --> 00:57:12.000
leads to… despair and or apathy.

00:57:12.000 --> 00:57:21.000
And that's a short step to dictatorship. Because if enough people just sit on the sidelines and throw up their hands and say, I don't know what's going on.

00:57:21.000 --> 00:57:25.000
That's where we end up.

00:57:25.000 --> 00:57:27.000
Um, two…

00:57:27.000 --> 00:57:29.000
Two reactions to what you just said, Mike.

00:57:29.000 --> 00:57:33.000
One positive, one negative. The negative one is,

00:57:33.000 --> 00:57:39.000
One of the current tactics of the current, at least, far-right, is to flood the zone with shit.

00:57:39.000 --> 00:57:44.000
That is a very explicit tactic, that if you have people too busy

00:57:44.000 --> 00:57:47.000
to deal with, they'll just drop everything. And also,

00:57:47.000 --> 00:57:56.000
Too confused about which side to be on, because, oh, wait a minute, the baddie is funding the good guys that I'm listening to, maybe I should stop listening to the good guys?

00:57:56.000 --> 00:58:01.000
And, uh, there's a documentary I love called Hypernormalization by Adam Curtis.

00:58:01.000 --> 00:58:05.000
Where he talks about Putin and his lieutenant Serkov,

00:58:05.000 --> 00:58:12.000
who were doing this for years, years ago. They were sort of busy honing this, perfecting this art of flooding the zone with shit.

00:58:12.000 --> 00:58:14.000
And that's happening.

00:58:14.000 --> 00:58:20.000
Um, but on the other hand, maybe this is the positive side? I don't know. This is also about attention management.

00:58:20.000 --> 00:58:25.000
And, uh, Ken Homer just sent us a love… wrote us a lovely poem, you know, that he just read to us.

00:58:25.000 --> 00:58:30.000
about stepping out of the torrent and the conversations and things like that.

00:58:30.000 --> 00:58:36.000
And it's not that we aren't given the time, it's that we don't make the time.

00:58:36.000 --> 00:58:46.000
I think that it's possible, and when there's too much information, I don't mean you can subtly, magically make the time to know all of that and to sort it out.

00:58:46.000 --> 00:58:52.000
I think what you do is you step out of it and have focus on something else.

00:58:52.000 --> 00:58:57.000
But, uh, there's a growing little niche

00:58:57.000 --> 00:59:02.000
In the world about how do you cope with change, and how do you maintain equanimity,

00:59:02.000 --> 00:59:10.000
in the face of actual turbulence and political turbulence and emotional turbulence and other kinds of things that are happening.

00:59:10.000 --> 00:59:16.000
And that's probably a good topic for an OGM call at some point, uh, as well.

00:59:16.000 --> 00:59:19.000
guilties.

00:59:19.000 --> 00:59:21.000
Yeah, it is… it is a good topic.

00:59:21.000 --> 00:59:29.000
Um, one of the things we've done in our house is dramatically cut down on our news diet.

00:59:29.000 --> 00:59:36.000
So I suggest that as a possibility. Um, on the matter of time and quiet, and Mike, thanks for what you said.

00:59:36.000 --> 00:59:41.000
Um, I don't know if people have watched Charlie Kirk's…

00:59:41.000 --> 00:59:43.000
competitive debate.

00:59:43.000 --> 00:59:51.000
Forum. He… I've seen Mehdi Hassan do this on the left, and Charlie Kirk do this on the right, where they sit at a table,

00:59:51.000 --> 00:59:58.000
So it's like a chess match table, small table, facing off, and they're surrounded by a circle about 20 or 30 people.

00:59:58.000 --> 01:00:03.000
And anybody in the circle gets to come in and sit down opposing them and have a conversation with them.

01:00:03.000 --> 01:00:08.000
And it's like… it's like… what's the term for speed chess? You know, where you have the clock and you're moving really fast?

01:00:08.000 --> 01:00:14.000
It's a high-speed competitive debate format.

01:00:14.000 --> 01:00:21.000
Um, and it's interesting because it's, you know, it's showing off a kind of cognitive and communication skill.

01:00:21.000 --> 01:00:24.000
But it allows for no thought.

01:00:24.000 --> 01:00:29.000
Allows for no reflection. Allows for no consideration. Highly polarizing.

01:00:29.000 --> 01:00:37.000
And, um, it's really, really weird to watch. I've seen both these guys do it, and I hate both of them doing it.

01:00:37.000 --> 01:00:43.000
I watched one with Mehdi doing it, and I was really turned off. He was… everybody was interrupting everybody.

01:00:43.000 --> 01:00:52.000
Yeah, and he's like, you know, he's writing everybody's… I mean, there are things that I agree with him on, and found him hate… found myself hating him.

01:00:52.000 --> 01:01:00.000
Uh, and it's… and in all of these things, back to what we were saying before, it's taking potentially complex or complicated issues and saying,

01:01:00.000 --> 01:01:02.000
No, it's not complicated.

01:01:02.000 --> 01:01:09.000
One of the reasons I stepped out of Facebook, which I did, like, a month ago now, is that I was in conversations where people were kind of, you know,

01:01:09.000 --> 01:01:19.000
Not even people I knew. People who knew people I knew were jumping into conversations I was having and yelling at me, saying, it's not complicated. What's the matter with you?

01:01:19.000 --> 01:01:22.000
I think my guy really is, so…

01:01:22.000 --> 01:01:26.000
So I decided to step back. It's another kind of quiet, less social media.

01:01:26.000 --> 01:01:29.000
We're very selective social media.

01:01:29.000 --> 01:01:30.000
Mm-hmm. Mm-hmm.

01:01:30.000 --> 01:01:38.000
Which, reminder, we all know this here, but it's worth remind… remembering that in that machinery, we are the product.

01:01:38.000 --> 01:01:42.000
We think it's something that we're using. We're the product.

01:01:42.000 --> 01:01:46.000
Anytime the service is free.

01:01:46.000 --> 01:01:49.000
you know, the product.

01:01:49.000 --> 01:01:51.000
So, I'll stop here.

01:01:51.000 --> 01:02:02.000
Well, I'm not sure any… I'm not sure that with the conclusion, anytime the service is free, we are the product, because the incommons and in a different world, on a

01:02:02.000 --> 01:02:06.000
parallel plane in the multiverse.

01:02:06.000 --> 01:02:07.000
Totally.

01:02:07.000 --> 01:02:09.000
Um, lots of things can be free, and it's not because we are the product being sold off, it's because

01:02:09.000 --> 01:02:12.000
I heard that as I was saying it, Sherry.

01:02:12.000 --> 01:02:13.000
Yeah, yeah.

01:02:13.000 --> 01:02:20.000
We're actually sharing resources in an abundant way, yada yada yada, probably another good topic for an OGM call.

01:02:20.000 --> 01:02:21.000
Like that. Like…

01:02:21.000 --> 01:02:23.000
Yeah, with Kevin and his Mennonite carpenters, not bad at all. Totally, totally get it.

01:02:23.000 --> 01:02:26.000
Like that, exactly. So thank you for that.

01:02:26.000 --> 01:02:34.000
Scott, please.

01:02:34.000 --> 01:02:35.000
Uh, Scott, you need to unmute.

01:02:35.000 --> 01:02:40.000
You're muted.

01:02:40.000 --> 01:02:43.000
Scott, you need to come back to the keyboard. There you are, good.

01:02:43.000 --> 01:02:44.000
Yes, we're hearing you now.

01:02:44.000 --> 01:02:51.000
All right, how about now? How about now? All right. I'm actually on the road, so I will, uh… But… so you can all hear me?

01:02:51.000 --> 01:02:52.000
Yes, you sound like you're in a car, but we can hear you just fine.

01:02:52.000 --> 01:02:53.000
Yep.

01:02:53.000 --> 01:03:06.000
All right. I am in a car, but I will try to make it less… Let's cars out. Um… I am enjoying this particular call in its entirety more than I have in a while.

01:03:06.000 --> 01:03:13.000
I am seeing or hearing. a humbleness of certainty.

01:03:13.000 --> 01:03:18.000
that I… or uncertainty, rather. I'm not exactly sure how to say that.

01:03:18.000 --> 01:03:24.000
I'm appreciating everyone saying, you know, this is something… that I wasn't expecting.

01:03:24.000 --> 01:03:31.000
And it's making me think about something differently. And I'm actually open to that.

01:03:31.000 --> 01:03:36.000
And I think that that is, um… If there is a route.

01:03:36.000 --> 01:03:40.000
That's, you know, our current crisis, I think that that's.

01:03:40.000 --> 01:03:48.000
Definitely one of them. is that we are… I don't know if anybody saw, I wrote in the Plex.

01:03:48.000 --> 01:03:53.000
this most recent issue about. compression.

01:03:53.000 --> 01:03:55.000
Mm-hmm, yep.

01:03:55.000 --> 01:04:00.000
Sometimes I have a phrase that comes out, and I don't actually.

01:04:00.000 --> 01:04:04.000
Will it come out? It just comes out, and then I see it, and I think, huh.

01:04:04.000 --> 01:04:14.000
That's actually kind of neat. And it was, uh… consuming more of less.

01:04:14.000 --> 01:04:18.000
And I thought that was interesting, because the way I thought of that after I read it.

01:04:18.000 --> 01:04:30.000
after the words came out, I thought. Yeah, that's really what it is. It's just… this idea of… I already know what that is, so I don't need to consume any more of it.

01:04:30.000 --> 01:04:36.000
And I go look for the next thing, and the next thing, without actually really getting into the thing that.

01:04:36.000 --> 01:04:46.000
I've already summed up, in some way. But, um… Sorry, my thoughts are a little all over the place. I appreciated Stacy's comments about.

01:04:46.000 --> 01:04:55.000
making predictions, and then making second predictions. And just… putting some stake in there, instead of saying, I know exactly what's gonna happen.

01:04:55.000 --> 01:05:02.000
And we're probably wrong. at least in some way, we're probably wrong. I appreciated your.

01:05:02.000 --> 01:05:11.000
comment, Jerry, about, um. you know, futurists and trying to make predictions, and… guesses, and then actually being.

01:05:11.000 --> 01:05:16.000
held accountable to. to at least the prediction.

01:05:16.000 --> 01:05:21.000
You know, I think that that's all really important, and it's a humbleness.

01:05:21.000 --> 01:05:25.000
I think that's my only deep here. It's the willingness to say, you know.

01:05:25.000 --> 01:05:29.000
I bet I don't see everything. I bet I don't know everything.

01:05:29.000 --> 01:05:39.000
And if something shows up. Am I willing to incorporate that into my own mental model, allow it to be changed?

01:05:39.000 --> 01:05:44.000
Thank you very much. Totally, really appreciate your reflections on

01:05:44.000 --> 01:05:46.000
On the nature of this column.

01:05:46.000 --> 01:05:50.000
you're calling things out I hadn't really noticed about the call, which I love.

01:05:50.000 --> 01:05:53.000
So, that's great.

01:05:53.000 --> 01:05:57.000
Anyone else? Thoughts?

01:05:57.000 --> 01:06:02.000
Actually, let's go into that little moment of silence that Gil mentioned a moment ago.

01:06:02.000 --> 01:06:32.000
I will bring us back out in a moment.

01:07:00.000 --> 01:07:06.000
Thank you very much.

01:07:06.000 --> 01:07:10.000
reflections, jokes?

01:07:10.000 --> 01:07:21.000
Other things?

01:07:21.000 --> 01:07:22.000
Stacy.

01:07:22.000 --> 01:07:26.000
I did have one other thing, actually, that I forgot to mention.

01:07:26.000 --> 01:07:27.000
Go ahead, and then Stacey.

01:07:27.000 --> 01:07:32.000
Sorry, Jerry. when I was reading your email about.

01:07:32.000 --> 01:07:39.000
precipitated this. Here's the theme of the call. I was thinking of that.

01:07:39.000 --> 01:07:50.000
quote that I will misquote slightly. Which is, it's amazing… which you can get done if nobody cares who gets the credit.

01:07:50.000 --> 01:07:54.000
So, I'm just throwing that out there. I don't know if you want to.

01:07:54.000 --> 01:07:57.000
riff on that a little bit, but if that's what it seemed like.

01:07:57.000 --> 01:08:03.000
was happening, um. This is, you know, it sees fire, awesome!

01:08:03.000 --> 01:08:10.000
Right? Like, that's kind of what we want. But… there's the issue of credit.

01:08:10.000 --> 01:08:15.000
And… and that is part of it, at least.

01:08:15.000 --> 01:08:18.000
Thank you. The quote I have is from Harry Truman.

01:08:18.000 --> 01:08:22.000
It is amazing what you can accomplish if you do not care who gets the credit.

01:08:22.000 --> 01:08:25.000
And it's very likely one of those things that's been said by…

01:08:25.000 --> 01:08:41.000
Actually, there's a quote investigator article about this that has a whole bunch of other people saying it, and their phrase is, a man may do an immense deal of good if he does not care who gets the credit. And I'll post both of those in the chat.

01:08:41.000 --> 01:08:42.000
See? See?

01:08:42.000 --> 01:08:44.000
I thought Craig Vonnegut said that.

01:08:44.000 --> 01:08:55.000
It was Al Gore's favorite quotation when he was vice president, partly because it was said by a previous vice president when he was vice president and invisible.

01:08:55.000 --> 01:08:59.000
And every time Gorin tried to stand up and take credit for something.

01:08:59.000 --> 01:09:07.000
Boom! They just… they worked so hard to make sure… He, uh, was misrepresented, misquoted.

01:09:07.000 --> 01:09:14.000
At one point, he got excited about a project, a very cheap satellite, that was going to orbit in the L1 point between the.

01:09:14.000 --> 01:09:21.000
Earth and the Sun, and provide 24-hour-a-day coverage. of the sunny side of the Earth.

01:09:21.000 --> 01:09:28.000
I mean, literally less than $200 million. And, uh, as a NASA project goes, that's pretty darn cheap.

01:09:28.000 --> 01:09:35.000
And the Senate Republicans held it up for 5 years, just because Gore thought it was a good idea.

01:09:35.000 --> 01:09:49.000
The entire community thought it was a great idea, incredibly cost-effective, but… They held it up. They didn't want him getting any credit for anything. They knew he was gonna run for… for president, and they didn't want him to have any accomplishments.

01:09:49.000 --> 01:09:52.000
Which is a marvel to me because

01:09:52.000 --> 01:09:55.000
Gore is Obama's…

01:09:55.000 --> 01:09:58.000
Oh, sorry.

01:09:58.000 --> 01:09:59.000
Clinton's vice president.

01:09:59.000 --> 01:10:04.000
I've got the… yeah, Clinton's vice president, that's right. And the… because later, later,

01:10:04.000 --> 01:10:08.000
Um, Obama… I'm pretty certain the right doesn't want Obama to succeed on anything.

01:10:08.000 --> 01:10:16.000
And he does. He manages to have the economy just go chug, chug, chug, chug, chug, and he manages to pass some degree of

01:10:16.000 --> 01:10:24.000
of health coverage and so forth, that they've not been able to extinguish. I track in my brain the many times that the right has tried to get rid of Obamacare.

01:10:24.000 --> 01:10:29.000
And it's an astonishing, really, there have been astonishing battles fought to try to, you know,

01:10:29.000 --> 01:10:32.000
get rid of it. They've managed to weaken it, but not get rid of it entirely.

01:10:32.000 --> 01:10:39.000
At this point, at this point, the thing we haven't mentioned for 3 calls or whatever is the lockdown

01:10:39.000 --> 01:10:42.000
And, uh, the government showdown over the budget.

01:10:42.000 --> 01:10:45.000
And, uh, the shut… the government shut down,

01:10:45.000 --> 01:10:54.000
And one of the big issues is the continuation of the subsidies that allow Obamacare to be affordable. That is one of the monster issues on the table that the Democrats

01:10:54.000 --> 01:11:01.000
They've decided is a hill to die on for this particular issue, and it feels to me like the Democrats have the sort of

01:11:01.000 --> 01:11:03.000
moral upper hand on this one, although

01:11:03.000 --> 01:11:09.000
public opinion and moral upper hand don't always agree.

01:11:09.000 --> 01:11:11.000
Fortunately, there's alliteration against them. Schumer's shutdown.

01:11:11.000 --> 01:11:13.000
Yeah.

01:11:13.000 --> 01:11:17.000
Schumer shut down out. There you go.

01:11:17.000 --> 01:11:25.000
But yeah, 40 times, I think, they had votes or tried to… put a poison pill into the Obamacare program.

01:11:25.000 --> 01:11:29.000
Yeah, yeah, it's astonishing.

01:11:29.000 --> 01:11:32.000
And I gotta say,

01:11:32.000 --> 01:11:35.000
Trump too, which is how I refer to the second Trump administration,

01:11:35.000 --> 01:11:38.000
is payback for…

01:11:38.000 --> 01:11:46.000
Milk toast efforts within the bounds of the system to try to fight back on things that the right didn't like.

01:11:46.000 --> 01:11:48.000
And I'm sitting here thinking, SCOTUS,

01:11:48.000 --> 01:11:54.000
The Supreme Court of the United States is very Republican because they stole seats because

01:11:54.000 --> 01:11:55.000
The left didn't act up and say, hey, wait a minute, you can't do that. We're gonna do something dramatic,

01:11:55.000 --> 01:12:01.000
Thank you.

01:12:01.000 --> 01:12:06.000
to make sure that we get to vote on those seats. Like, like, two seats on Supreme Court.

01:12:06.000 --> 01:12:11.000
we're basically stolen, as far as I can tell.

01:12:11.000 --> 01:12:12.000
I'm… I don't understand, Jay, that you say that's… that that's…

01:12:12.000 --> 01:12:14.000
Yep.

01:12:14.000 --> 01:12:17.000
Trumpist reaction to what the Dems did.

01:12:17.000 --> 01:12:22.000
What we're seeing is the playing out of a 50-year explicitly written-about strategy.

01:12:22.000 --> 01:12:23.000
Also, yes.

01:12:23.000 --> 01:12:30.000
So, let's, you know, I think it's mythification to say, oh, they're angry at the Democrats who did or didn't do whatever. This has been…

01:12:30.000 --> 01:12:34.000
you know, they've been rolling out this game plan since 1973.

01:12:34.000 --> 01:12:39.000
Uh, since the PAL memo in 70, I think.

01:12:39.000 --> 01:12:40.000
Yeah, yeah, Powell memos…

01:12:40.000 --> 01:12:41.000
What was that one? Was that… I have the date wrong then, so I'm talking… I'm referencing the pal… referencing the PAL memo.

01:12:41.000 --> 01:12:42.000
Yep.

01:12:42.000 --> 01:12:47.000
And if people haven't seen it, there's a movie called Heist, The Stealing of the American Dream.

01:12:47.000 --> 01:12:55.000
that unfolds that story. It's a terrific piece of work. I'll find the link and post it for y'all.

01:12:55.000 --> 01:12:56.000
Please do.

01:12:56.000 --> 01:12:58.000
I'm not sure it doesn't trace back to the Civil War, Gil.

01:12:58.000 --> 01:13:08.000
Well, there's that, too, and you can take it back, you know, another 100 years before that. But in terms of an explicit published strategy.

01:13:08.000 --> 01:13:13.000
Um, and in the spirit of, you know, Maya Angelou, when people tell you who they are, believe them.

01:13:13.000 --> 01:13:18.000
You've got that there, you've got Bannon's writings, you've got Dugan's writings in the Russian sphere.

01:13:18.000 --> 01:13:23.000
Um, none of this is mysterious.

01:13:23.000 --> 01:13:24.000
Uh, yes, and…

01:13:24.000 --> 01:13:28.000
Unless you get your information from the mass media, in which case it's mysterious.

01:13:28.000 --> 01:13:33.000
So I… I… I'm… I agree with your framing of this is a much longer battle than I was just saying.

01:13:33.000 --> 01:13:36.000
Uh, partly, I think what I'm… what I was trying to say is,

01:13:36.000 --> 01:13:41.000
The rights attempts to stay within the lines of

01:13:41.000 --> 01:13:44.000
the legal system, et cetera, et cetera, did not work.

01:13:44.000 --> 01:13:49.000
They tried to bring things to the floor. The reason, I think,

01:13:49.000 --> 01:13:55.000
that most of what Trump does is by executive order and fiat and just acting outside of the bounds of what we think is…

01:13:55.000 --> 01:14:03.000
what is likely even legal to do, is that bringing things to the floor of Congress did not work for a long time. Trump won,

01:14:03.000 --> 01:14:08.000
Trump won, and a bunch of other efforts to tip over, you know, all these things.

01:14:08.000 --> 01:14:10.000
We're flailing.

01:14:10.000 --> 01:14:16.000
flailing. And the left is grateful that a bunch of adults in the room threw their bodies in front of

01:14:16.000 --> 01:14:21.000
The more radical things that Trump won wanted to do. And in between Trump 1 and Trump 2,

01:14:21.000 --> 01:14:24.000
Everybody on the far right said, well, great, that didn't work.

01:14:24.000 --> 01:14:28.000
We're going to take a much more, much more dramatic approach.

01:14:28.000 --> 01:14:35.000
Which is a fulfillment of things set in motion back in 1970, et cetera, et cetera.

01:14:35.000 --> 01:14:39.000
Which was a reaction to Barry Goldwater losing the election in 64.

01:14:39.000 --> 01:14:42.000
Which, through the Conservative Party into a dramatic crisis.

01:14:42.000 --> 01:14:43.000
Yep.

01:14:43.000 --> 01:14:47.000
into a huge identity crisis, out of which come these, I think,

01:14:47.000 --> 01:14:53.000
Long-term thinking brilliant strategies, and I don't see long-term thinkers on the left.

01:14:53.000 --> 01:14:58.000
And sorry, this has become a bit of a political conversation toward the end of our time together, but

01:14:58.000 --> 01:15:04.000
Um… thoughts on this other ways of seeing this welcome.

01:15:04.000 --> 01:15:10.000
Please, um, throw them onto the table.

01:15:10.000 --> 01:15:15.000
I don't think Powell contemplated Trump.

01:15:15.000 --> 01:15:17.000
Um, I don't think Newt Gingrich contemplated a Trump. Like, Newt…

01:15:17.000 --> 01:15:23.000
I think Powell… I think Powell was enough of an old, you know, small L liberal.

01:15:23.000 --> 01:15:24.000
Yeah.

01:15:24.000 --> 01:15:29.000
Um, to not be looking for a coup. He was looking for, you know, playing out within the game.

01:15:29.000 --> 01:15:32.000
Gingrich, um…

01:15:32.000 --> 01:15:37.000
Um, in Jane's interpretation, gets a lot of credit.

01:15:37.000 --> 01:15:38.000
Yes.

01:15:38.000 --> 01:15:40.000
for the mess. Because when he became Speaker, he changed the schedule.

01:15:40.000 --> 01:15:42.000
of the House of Representatives.

01:15:42.000 --> 01:15:43.000
And basically…

01:15:43.000 --> 01:15:44.000
Uh, he did many things.

01:15:44.000 --> 01:15:51.000
Yeah, but this one is a pivotal one, because he shortened the work week so that members could go home on the weekends.

01:15:51.000 --> 01:15:52.000
Mm-hmm.

01:15:52.000 --> 01:15:54.000
quote, to be with their constituents.

01:15:54.000 --> 01:16:00.000
But the result of that is that the social relationships between Republican and Democrat members and their families

01:16:00.000 --> 01:16:02.000
And their wives who had been friends.

01:16:02.000 --> 01:16:07.000
broke. And maybe was one of the pivotal

01:16:07.000 --> 01:16:12.000
One of the pivotal elements in the increasing polarization in the House.

01:16:12.000 --> 01:16:19.000
So, in my brain, I've got a thought, Gringrich created the current political rift in America. Under that, ways Gingrich transformed Congress.

01:16:19.000 --> 01:16:20.000
Hmm.

01:16:20.000 --> 01:16:25.000
Uh, do not cooperate, do not compromise, do not see bipartisan solutions ever on anything.

01:16:25.000 --> 01:16:28.000
Uh, they got rid of, uh,

01:16:28.000 --> 01:16:32.000
basically, uh, he stopped people from

01:16:32.000 --> 01:16:38.000
He instituted message discipline he wouldn't let Republicans room with Democrats. They used to share crash pads in D.C.

01:16:38.000 --> 01:16:39.000
Hmm.

01:16:39.000 --> 01:16:43.000
They would rent a house with 4 bedrooms, and then Republicans and Democrats would room together and dine together and all that.

01:16:43.000 --> 01:16:47.000
Hmm. Yeah.

01:16:47.000 --> 01:16:48.000
Damn.

01:16:48.000 --> 01:16:51.000
He made that basically illegal. He said, he said, you do that, we're not gonna fund you for the primary.

01:16:51.000 --> 01:16:52.000
Damn.

01:16:52.000 --> 01:16:55.000
And, you know, having a throttle,

01:16:55.000 --> 01:16:57.000
on the primaries was, uh,

01:16:57.000 --> 01:17:00.000
a huge, uh, power…

01:17:00.000 --> 01:17:01.000
power move that really worked. So…

01:17:01.000 --> 01:17:05.000
Did you share the link to that piece of the brainchair?

01:17:05.000 --> 01:17:06.000
Thank you.

01:17:06.000 --> 01:17:08.000
I just… I just put a link in the chat to Ways Gingrich transformed Congress. I did that before, I said,

01:17:08.000 --> 01:17:09.000
started screen sharing.

01:17:09.000 --> 01:17:10.000
Yeah. Thank you.

01:17:10.000 --> 01:17:17.000
There was a wonderful article in, uh, what was it, uh, Harper's years ago, about, uh, I think it was called The Family?

01:17:17.000 --> 01:17:19.000
Was that the name of it? Um…

01:17:19.000 --> 01:17:20.000
Could be, sounds familiar?

01:17:20.000 --> 01:17:26.000
staggering. Staggering. Basically, it was a, um…

01:17:26.000 --> 01:17:28.000
It… it…

01:17:28.000 --> 01:17:30.000
It was a club.

01:17:30.000 --> 01:17:34.000
Uh, uh, slash… it was, in effect, a condo.

01:17:34.000 --> 01:17:36.000
Um…

01:17:36.000 --> 01:17:42.000
a co-housing sort of situation, where a whole bunch of Republican, um…

01:17:42.000 --> 01:17:54.000
legislators were living together in a plex. Like, it was like a polycule. It was absolutely incredible. And this thing had been set up in the, uh, in, uh…

01:17:54.000 --> 01:17:55.000
It's the fellowship.

01:17:55.000 --> 01:17:57.000
the… is it the fellowship?

01:17:57.000 --> 01:18:00.000
Is this…

01:18:00.000 --> 01:18:04.000
Christian fundamentalist thing, so there's a mini-series called The Family,

01:18:04.000 --> 01:18:05.000
Hmm.

01:18:05.000 --> 01:18:10.000
Um, which was on Netflix, which was about the fellowship, and there's also a book called

01:18:10.000 --> 01:18:13.000
the family, the secret fundamentalism at the Heart of American Power. I think you mean that.

01:18:13.000 --> 01:18:14.000
Hmm.

01:18:14.000 --> 01:18:19.000
Yeah, yeah. I think it was founded in about 57 or something, is when the visionary, uh, had the vision.

01:18:19.000 --> 01:18:21.000
35.

01:18:21.000 --> 01:18:23.000
1935, holy cat.

01:18:23.000 --> 01:18:26.000
35, the fellowship. Hold on, let me do a screen share again.

01:18:26.000 --> 01:18:27.000
Uh, because I've got all this stuff in my brain.

01:18:27.000 --> 01:18:29.000
Anyway, incredible, incredible situation.

01:18:29.000 --> 01:18:35.000
So here, uh, so the… here's the fellowship, A Secret Society of Christian Fundamentalists.

01:18:35.000 --> 01:18:40.000
uh… funded by a lot of conservatives who hated the New Deal, because this is against the New Deal.

01:18:40.000 --> 01:18:48.000
Uh, Abraham Varreideg, Douglas Coe, names I don't remember even putting in my brain. But then in 2019, there was a mini-series,

01:18:48.000 --> 01:18:52.000
about it, uh, called the family. I'm just going to connect these things to my brain.

01:18:52.000 --> 01:18:57.000
I mean, to… these are my notes from today's call.

01:18:57.000 --> 01:19:03.000
And so the fellowship is basically the start of that.

01:19:03.000 --> 01:19:08.000
Okay. Anyway, everybody should know about this. It's… it is…

01:19:08.000 --> 01:19:13.000
It's really the essence, perhaps, of how the machine

01:19:13.000 --> 01:19:16.000
works on the right.

01:19:16.000 --> 01:19:21.000
And their main facility is a mile from where I live, and I often jog past it.

01:19:21.000 --> 01:19:22.000
Wow.

01:19:22.000 --> 01:19:23.000
Wow.

01:19:23.000 --> 01:19:24.000
It's hidden away in the woods. In Arlington, Virginia.

01:19:24.000 --> 01:19:27.000
Triple.

01:19:27.000 --> 01:19:33.000
And it's mostly occupied by. 20-somethings conservative Christian.

01:19:33.000 --> 01:19:43.000
men and women who may become their wives. Uh, and they all commute to the hill where they work for various conservative.

01:19:43.000 --> 01:19:53.000
Of course, of course the left has an equivalent, you know, instrument just like this. It's called the Zen Center of San Francisco.

01:19:53.000 --> 01:19:56.000
But, huh, thank you.

01:19:56.000 --> 01:20:03.000
Um, anyway, well, we've gone down this rabbit hole pretty deep. Any other thoughts along this line?

01:20:03.000 --> 01:20:09.000
I think, Gil, when you were saying this is a long, thought-out strategy, it's been playing out for a long time, I completely agree.

01:20:09.000 --> 01:20:10.000
Really?

01:20:10.000 --> 01:20:17.000
And I fear that there are many more terrific strategists on the right than on the left.

01:20:17.000 --> 01:20:24.000
On the left are a bunch of well-intentioned people who think policy is how to do things and want to build big institutions to solve social problems.

01:20:24.000 --> 01:20:28.000
Which I think is a problematic approach to social problems.

01:20:28.000 --> 01:20:29.000
I actually do.

01:20:29.000 --> 01:20:32.000
And who trusts reason and fairness more than power.

01:20:32.000 --> 01:20:33.000
But the other…

01:20:33.000 --> 01:20:37.000
Yes, and on the right are a bunch of people who understand power, and working together,

01:20:37.000 --> 01:20:39.000
more than all those other things.

01:20:39.000 --> 01:20:44.000
The other thing the right has had, though, which is…

01:20:44.000 --> 01:20:47.000
Wow. Let me just tell them what Mike.

01:20:47.000 --> 01:20:50.000
Oh, I thought, I thought… I thought ice was at your door.

01:20:50.000 --> 01:20:54.000
Or something. Um, um…

01:20:54.000 --> 01:20:59.000
is, um, large, consistent, stable funding.

01:20:59.000 --> 01:21:00.000
Yes.

01:21:00.000 --> 01:21:04.000
that built institutions and built farm teams and trained people, but…

01:21:04.000 --> 01:21:14.000
I mean, I'm on the, uh, I'm on the board of a fiscal sponsor, so I deal with a bunch of not-for-profits and foundations and so forth, and the amount of grief

01:21:14.000 --> 01:21:16.000
that folks have to go through to get funding.

01:21:16.000 --> 01:21:17.000
Hmm.

01:21:17.000 --> 01:21:25.000
The micromanagement that the foundations have over the folks they fund, the amount of time that's spent in reporting rather than doing the work.

01:21:25.000 --> 01:21:37.000
is horrific, and it's an echo in a lot of layers of American society, because you look at the growth of the administrative layer in everything from universities to healthcare to everywhere else.

01:21:37.000 --> 01:21:43.000
There's that mess, but, you know, with Scafy and Mellon and various others on the right, there's been very consistent funding, and

01:21:43.000 --> 01:21:51.000
I guess the other part of this, which is maybe problematic to the left, is that for the right, it's a very good investment.

01:21:51.000 --> 01:21:52.000
It has paid off quite well.

01:21:52.000 --> 01:21:58.000
Buying congresspeople is an incredibly good investment. The ROI's terrific.

01:21:58.000 --> 01:22:03.000
And that's not the language of the left, that's the language of the right, and they've been playing that.

01:22:03.000 --> 01:22:09.000
for a long time, very effectively.

01:22:09.000 --> 01:22:10.000
So…

01:22:10.000 --> 01:22:14.000
Totally agree. Um, there's my tracking of conservative foundations.

01:22:14.000 --> 01:22:15.000
Yeah, and the fellowship.

01:22:15.000 --> 01:22:19.000
the Koch Foundation's SCAFE… is it Scafy?

01:22:19.000 --> 01:22:21.000
I think… I think so, I don't know.

01:22:21.000 --> 01:22:24.000
Koch Family Heritage,

01:22:24.000 --> 01:22:30.000
Bradley, Lynn and Harry Bradley Foundation, Smith Richardson Foundation, these are all

01:22:30.000 --> 01:22:32.000
Deeply conservative foundations that have funded

01:22:32.000 --> 01:22:36.000
the movement we just talked about. So you're right. And, and…

01:22:36.000 --> 01:22:39.000
The left… ah.

01:22:39.000 --> 01:22:44.000
I'm busy listening very carefully for any progressive who's saying something different.

01:22:44.000 --> 01:22:45.000
Hmm.

01:22:45.000 --> 01:22:48.000
and sensible. And I'm not hearing any. I'm hearing a couple who…

01:22:48.000 --> 01:22:53.000
have struck authenticity, they're figuring out how to connect with people, that's great.

01:22:53.000 --> 01:22:57.000
But their messages don't sound any different from a traditional, uh,

01:22:57.000 --> 01:23:00.000
progressive. And I'm… I'm…

01:23:00.000 --> 01:23:04.000
really concerned that this is a battle of…

01:23:04.000 --> 01:23:07.000
ideologies where the left

01:23:07.000 --> 01:23:13.000
doesn't have a grip on any layer of how to do this better or right.

01:23:13.000 --> 01:23:16.000
So, Jerry, um…

01:23:16.000 --> 01:23:18.000
How could that be different?

01:23:18.000 --> 01:23:21.000
I… that's a… that's… so I'm… I'm really interested in how to…

01:23:21.000 --> 01:23:26.000
Let's have that be a topic.

01:23:26.000 --> 01:23:27.000
Yeah.

01:23:27.000 --> 01:23:31.000
I'm really interested in how to build a better world, and some of the calls we've had, I mean, we had a little series on what works in governance,

01:23:31.000 --> 01:23:37.000
Um, we had… I think I did 4 calls on… on little g governance instead of big G government.

01:23:37.000 --> 01:23:44.000
And my goal was to try to collect up a stack. Right now, my shorthand for this is, what are our next two stacks?

01:23:44.000 --> 01:23:49.000
And try to figure out what is a set of

01:23:49.000 --> 01:23:56.000
ways of doing decisions and making collective decisions as society and solving problems.

01:23:56.000 --> 01:24:01.000
What is a way of open sourcing those things so that communities can just grab them and implement them?

01:24:01.000 --> 01:24:05.000
As opposed to telling everybody to do X or Y or Z.

01:24:05.000 --> 01:24:10.000
Because I think people are rejecting mandates left, right, and center, so how do we make things

01:24:10.000 --> 01:24:12.000
so functional and so appealing,

01:24:12.000 --> 01:24:14.000
that, um…

01:24:14.000 --> 01:24:18.000
I don't know that I know Neighborhoodos, Kalia, thank you.

01:24:18.000 --> 01:24:19.000
I'm going to go look it up. Um…

01:24:19.000 --> 01:24:20.000
Hmm.

01:24:20.000 --> 01:24:23.000
How do we… how do we… how do we…

01:24:23.000 --> 01:24:31.000
put on offer a bunch of things that we know work in some places, and then make it very, very easy for other communities to implement them.

01:24:31.000 --> 01:24:36.000
And in a non-political way, because the left-right party system

01:24:36.000 --> 01:24:42.000
is stuck in everything we've been talking about for 87 minutes.

01:24:42.000 --> 01:24:45.000
Right? And so…

01:24:45.000 --> 01:24:51.000
How do… how do we make some alternate way of living together and making an abundant society

01:24:51.000 --> 01:24:58.000
happen, um, that gen… that then grows up from the bottom, and then if somebody wants to make a political party out of that, great.

01:24:58.000 --> 01:25:05.000
But they'll at least have some foundation to work from.

01:25:05.000 --> 01:25:21.000
I think… I think… there's a… there's an orientational… Shift… That's… that's not about… ways of doing things.

01:25:21.000 --> 01:25:26.000
I really think there's a… What's… what's been lost?

01:25:26.000 --> 01:25:37.000
What's missing in technology? And what's missing in… The capitalist system, which is really at the root of a lot of this.

01:25:37.000 --> 01:25:49.000
Um, is… Any moral, ethical, or value-orientation, transcendent of individual interest.

01:25:49.000 --> 01:26:05.000
Relative to the capitalist driver, which is profit. And, um… all of the structures and all of the… ways in which.

01:26:05.000 --> 01:26:18.000
underlying moral, ethical value considerations and empathy. It's a fundamental human… caring. Um… were supported had to do with.

01:26:18.000 --> 01:26:23.000
the… the actual…

01:26:23.000 --> 01:26:29.000
societal fabric. supporting connection between people, caring.

01:26:29.000 --> 01:26:34.000
of people for other people. And all of that's been sort of.

01:26:34.000 --> 01:26:39.000
denatured out of the system.

01:26:39.000 --> 01:26:49.000
And, um… The question is how to sort of… not provide… you can't provide that.

01:26:49.000 --> 01:26:57.000
But what I think and believe is that. We… we can spark it.

01:26:57.000 --> 01:27:01.000
And that the feelings that are in that domain of.

01:27:01.000 --> 01:27:09.000
empathy, and… care and value, and ethic.

01:27:09.000 --> 01:27:18.000
Um… feels better, and that the younger generations today.

01:27:18.000 --> 01:27:24.000
are actually… there's a vacuum. where that belongs, where that exists, where that can be.

01:27:24.000 --> 01:27:32.000
catalyzed, and anything that could come along. to offer that, I think, would explode, like.

01:27:32.000 --> 01:27:37.000
what happened in the 60s. Except for those generations.

01:27:37.000 --> 01:27:49.000
I don't think they're so less. But if you look and watch at what… Culturally, they're… swimming around, and it sure looks like it.

01:27:49.000 --> 01:27:53.000
But I think they're… they recognize the absence of.

01:27:53.000 --> 01:27:58.000
I think they're feeling the absence of. I don't think anybody's offering them.

01:27:58.000 --> 01:28:06.000
that.

01:28:06.000 --> 01:28:15.000
By some quirk of fate, we are right at the end of our call time, but that sounds like a really lovely thing, a lovely note to end our call on.

01:28:15.000 --> 01:28:18.000
I'm afraid we won't have Ken Homer around for a bit.

01:28:18.000 --> 01:28:26.000
Um, so we are poemless at the end of our call, which I… leaves a little gap in my heart.

01:28:26.000 --> 01:28:29.000
But thank you for, um,

01:28:29.000 --> 01:28:33.000
Joining in wholeheartedly in this conversation. I really, I really appreciate it.

01:28:33.000 --> 01:28:39.000
feedback afterthoughts, put them on the OGM mailing list.

01:28:39.000 --> 01:28:40.000
And let's see where this goes. Um, Kalia, does it make sense to have an OGM call about verifiable communities, so we can learn more and understand what the initiative is?

01:28:40.000 --> 01:28:52.000
Sorry.

01:28:52.000 --> 01:28:56.000
Taar, if you want to invite Grace.

01:28:56.000 --> 01:28:58.000
That'd be great.

01:28:58.000 --> 01:29:00.000
Yeah.

01:29:00.000 --> 01:29:01.000
Cool.

01:29:01.000 --> 01:29:07.000
Um, she's just about to have a whole deck about the initiative, so that's good timing.

01:29:07.000 --> 01:29:10.000
She's just about to have a what?

01:29:10.000 --> 01:29:11.000
a deck.

01:29:11.000 --> 01:29:14.000
a deck? Super. That is good timing.

01:29:14.000 --> 01:29:19.000
Awesome.

01:29:19.000 --> 01:29:22.000
So close.

01:29:22.000 --> 01:29:26.000
Um, thank you all. This has been, uh…

01:29:26.000 --> 01:29:31.000
really informative, groovy, and slightly frightening call.

01:29:31.000 --> 01:29:41.000
I will see you on the inner tubes, and uh… in another week.

