WEBVTT

00:00:00.000 --> 00:00:02.000
And, um, yeah, and I have… I have more time in my life.

00:00:02.000 --> 00:00:06.000
I'm sorry, we have bells going off here, I apologize for that. Where is that coming from?

00:00:06.000 --> 00:00:08.000
No worries about the bells.

00:00:08.000 --> 00:00:12.000
We're not… I don't think we're hearing them here. They might be in your background.

00:00:12.000 --> 00:00:16.000
Yeah, Zoom does a good job of eliminating background sounds.

00:00:16.000 --> 00:00:18.000
It does. It's got nice filters.

00:00:18.000 --> 00:00:26.000
Uh, this is the Open Global Mind weekly call on Thursday, September 25th, 2025.

00:00:26.000 --> 00:00:34.000
Gil was just reporting in on the many different Zoom meeting assistants he's been trying out, and a bit of an addiction, and how he had withdrawal.

00:00:34.000 --> 00:00:37.000
getting off Facebook just recently.

00:00:37.000 --> 00:00:41.000
And I was reminded of the scene in French Connection Part 2, I think.

00:00:41.000 --> 00:00:47.000
Where the French mafia addicts Popeye Doyle to heroin, and then he has to go cold turkey, and there's…

00:00:47.000 --> 00:00:50.000
I think I remember a really good scene when I was young.

00:00:50.000 --> 00:00:57.000
I was a little young for an R-rated movie back then, but uh… I remember a scene where he goes through withdrawal, and it was my first exposure to, like,

00:00:57.000 --> 00:00:59.000
what happens that way.

00:00:59.000 --> 00:01:07.000
I don't remember that at all. All I remember from that movie is the car chase under the elevated trains.

00:01:07.000 --> 00:01:08.000
Sure, Jerry, just…

00:01:08.000 --> 00:01:14.000
Yep. Which, apparently, they didn't… they didn't have a lot of clearance to do that. It's… the story, I think, is that they just kind of winged it.

00:01:14.000 --> 00:01:17.000
Hmm.

00:01:17.000 --> 00:01:21.000
Sorry, Jerry, just to… for posterity, and because we're recording this, just to clarify.

00:01:21.000 --> 00:01:27.000
Uh, that was the first time you said you weren't… you realized what cold turkey was, one of the many you've been through?

00:01:27.000 --> 00:01:28.000
Is that what you suggested? The joke, by the way.

00:01:28.000 --> 00:01:35.000
Yeah, I did not… I did not suggest that, but uh… but yeah.

00:01:35.000 --> 00:01:39.000
By the way, if I disappear, we've had two parkheads in the last, um.

00:01:39.000 --> 00:01:45.000
Oh, so if I disappear, it's not because of something you've said.

00:01:45.000 --> 00:01:46.000
So are the, uh, are the authorities…

00:01:46.000 --> 00:01:51.000
Or anyone said, uh, it's because we had a cut. Strange new world, strange new world of ours, two and a half years, I saw someone.

00:01:51.000 --> 00:01:55.000
Working on a local substation, and asked them what he was doing.

00:01:55.000 --> 00:01:59.000
He said they were… there were joining up extra parts of power.

00:01:59.000 --> 00:02:09.000
Into the substation, so if one path. Cuts out, there's another one kicks in straight away.

00:02:09.000 --> 00:02:10.000
Power, yeah, power cuts.

00:02:10.000 --> 00:02:11.000
We've had plenty of park cuts since then, whatever the… Whatever the system is…

00:02:11.000 --> 00:02:12.000
Power cut.

00:02:12.000 --> 00:02:15.000
Yeah, whatever the system is, it doesn't work. Or not officially.

00:02:15.000 --> 00:02:18.000
So clearly, an improvement.

00:02:18.000 --> 00:02:23.000
Well, they spent money, economy worked. People got chefs, you know, shareholdings or whatever.

00:02:23.000 --> 00:02:27.000
Yep.

00:02:27.000 --> 00:02:28.000
Cool. Um…

00:02:28.000 --> 00:02:32.000
System kicks on, moves on.

00:02:32.000 --> 00:02:35.000
Uh, Stacey, I am reading your email.

00:02:35.000 --> 00:02:37.000
And I think it's a nice idea.

00:02:37.000 --> 00:02:45.000
about the topic. Uh, I can either read what you just said, or you can explain what you said, which do you prefer?

00:02:45.000 --> 00:02:49.000
Well, if you understood it from reading it, I trust they will understand it.

00:02:49.000 --> 00:02:57.000
Cool. I think I'll just read it in in a sec.

00:02:57.000 --> 00:03:00.000
Where is everybody?

00:03:00.000 --> 00:03:04.000
Is there enough going on in the world for you?

00:03:04.000 --> 00:03:11.000
Yeah. Kind of crazy times.

00:03:11.000 --> 00:03:14.000
Let's dive into the topic, and I'll read, uh…

00:03:14.000 --> 00:03:17.000
I'll read Stacy's note to the Open Global Mind List.

00:03:17.000 --> 00:03:19.000
Which is, hi gang, for the topic of abundance.

00:03:19.000 --> 00:03:25.000
I'd like to request trying out a simple speed round exercise before going into our usual rounds of conversation,

00:03:25.000 --> 00:03:30.000
I propose that we each say in a few words, think of it as a title, phrase, headline,

00:03:30.000 --> 00:03:32.000
bumper sticker, whatever you want to call it.

00:03:32.000 --> 00:03:35.000
That only answers the what it is.

00:03:35.000 --> 00:03:41.000
Refrain from adding the how, where, when, and why. Just what abundance is, I think you're saying.

00:03:41.000 --> 00:03:42.000
At least for this quick round. Anyone can choose to say pass,

00:03:42.000 --> 00:03:44.000
Yes, with a button.

00:03:44.000 --> 00:03:54.000
Thank you for consideration. Uh, at least you didn't say thank you for attention to this matter, uh, which is how Trump ends many of his incredible, uh, Truth Social posts.

00:03:54.000 --> 00:03:58.000
Which is, of course, the source of news these days. That's how policy's made.

00:03:58.000 --> 00:04:06.000
Which is why the… which is why the wink was there, to make sure that you made that connection between attention and consideration.

00:04:06.000 --> 00:04:11.000
And the parallel between what I was saying and what Trump was saying.

00:04:11.000 --> 00:04:12.000
Very nice, very nice. There's Wink and also hearts, so…

00:04:12.000 --> 00:04:15.000
So there's a reason for that wink.

00:04:15.000 --> 00:04:17.000
Love that. Um…

00:04:17.000 --> 00:04:18.000
I thought their hearts were obvious.

00:04:18.000 --> 00:04:26.000
Beautiful. That sounds great. So, uh, why don't we make a little, uh, circle of the room and see what just the what,

00:04:26.000 --> 00:04:29.000
Not the how, why, what, not the explanatory stuff.

00:04:29.000 --> 00:04:37.000
And just a short phrase, it's our quick round robin, so don't go way deep, but think about what abundance

00:04:37.000 --> 00:04:43.000
is. And, uh, I think I'll just ask for volunteers, whoever would like to go.

00:04:43.000 --> 00:04:47.000
Stacey, why don't you go first?

00:04:47.000 --> 00:04:48.000
Love, love that.

00:04:48.000 --> 00:04:53.000
Because I thought about it. Abundance for me is having what you need.

00:04:53.000 --> 00:04:57.000
When you need it.

00:04:57.000 --> 00:05:00.000
Are we done? Is that good for everybody?

00:05:00.000 --> 00:05:06.000
Sure, sure, yeah. That's the point. We can add later.

00:05:06.000 --> 00:05:07.000
I'll go.

00:05:07.000 --> 00:05:08.000
Please.

00:05:08.000 --> 00:05:12.000
Uh, Jerry, I like your manner of asking for volunteers, that's excellent.

00:05:12.000 --> 00:05:20.000
I immediately thought of the passage in Pirkeavot, The Wisdom of the Father… Wisdom of the Ancestors, said, who is rich?

00:05:20.000 --> 00:05:25.000
The person who is content with their lot.

00:05:25.000 --> 00:05:27.000
Content with their life.

00:05:27.000 --> 00:05:28.000
Content.

00:05:28.000 --> 00:05:30.000
Content, yes, and that's what I thought I said.

00:05:30.000 --> 00:05:31.000
Yeah.

00:05:31.000 --> 00:05:36.000
Um, thanks, Gil. Who's next?

00:05:36.000 --> 00:05:42.000
Everybody's being so pithy and, like, right on, right on mission here. I'm a little, like,

00:05:42.000 --> 00:05:45.000
It's early, how'd that happen?

00:05:45.000 --> 00:05:47.000
Hi, Jesse.

00:05:47.000 --> 00:05:48.000
Everyone. Hi. I'm gonna say ikigai.

00:05:48.000 --> 00:05:52.000
Hello.

00:05:52.000 --> 00:05:56.000
Thank you, guys. So the overlapping diagram

00:05:56.000 --> 00:05:58.000
of, uh, what you…

00:05:58.000 --> 00:06:04.000
Do what you love, do what you are good at, do what the world needs, and do what you can pay… get paid for.

00:06:04.000 --> 00:06:08.000
There we go.

00:06:08.000 --> 00:06:13.000
Um, thank you. Who else would like to go?

00:06:13.000 --> 00:06:14.000
Abundance.

00:06:14.000 --> 00:06:17.000
I was saying pass, by the way, I'll just pass on that one.

00:06:17.000 --> 00:06:20.000
Alex passes.

00:06:20.000 --> 00:06:23.000
Excellent. Uh, Pete, Rick, Doug, Klaus?

00:06:23.000 --> 00:06:24.000
I mean?

00:06:24.000 --> 00:06:25.000
I have an oblique, um…

00:06:25.000 --> 00:06:38.000
contribution. Uh, love is all you need.

00:06:38.000 --> 00:06:41.000
Cool.

00:06:41.000 --> 00:06:47.000
Yeah, I would frame it along the same lines as skilled, abundance.

00:06:47.000 --> 00:07:00.000
Is, is, uh, to be at peace with… Now, what, uh, with the gifts you have been given.

00:07:00.000 --> 00:07:01.000
infinite possibility, love that.

00:07:01.000 --> 00:07:05.000
For me, I think, uh, infinite possibility.

00:07:05.000 --> 00:07:08.000
John, uh, you've come into…

00:07:08.000 --> 00:07:16.000
We're doing a very quick round on what abundance means. What we think abundance is in, like, a phrase or sentence or bumper sticker.

00:07:16.000 --> 00:07:19.000
And we're two-thirds of the way through the group.

00:07:19.000 --> 00:07:26.000
Um, so if you'd like to jump in, that's good. I'm going to be slightly controversial, and I'm going to say abundance is more than enough.

00:07:26.000 --> 00:07:46.000
That's a good answer.

00:07:46.000 --> 00:07:51.000
We also like to jump in?

00:07:51.000 --> 00:07:59.000
Well, I apologize for being late, but I'll roll with what you said, Jerry. More than enough is a good, good way to frame it.

00:07:59.000 --> 00:08:01.000
Thank you. Uh, Rick?

00:08:01.000 --> 00:08:04.000
False?

00:08:04.000 --> 00:08:06.000
Oh, that's right, that's right, Classman.

00:08:06.000 --> 00:08:07.000
Ricky, can you hear us? Come in, Rick. Come in, Rick.

00:08:07.000 --> 00:08:09.000
Went. We're just waiting for recreate.

00:08:09.000 --> 00:08:14.000
Oh, yes, yeah, yeah, I'm just, um, co-intelligence.

00:08:14.000 --> 00:08:18.000
Abundance is co-intelligence.

00:08:18.000 --> 00:08:22.000
Thank you. Um…

00:08:22.000 --> 00:08:23.000
Yeah, that worked well. Thanks, Stacy.

00:08:23.000 --> 00:08:26.000
Thank you, everybody.

00:08:26.000 --> 00:08:34.000
So, uh, Pete has a whole new avatar picture for his… I was like, oh wait, wait, this is new!

00:08:34.000 --> 00:08:41.000
It's like when we change our hairdo, like, what happened? Wait.

00:08:41.000 --> 00:08:50.000
So, I'm really interested in the contrast, because back in the day, Diamandis and Kotler wrote Abundance.

00:08:50.000 --> 00:08:57.000
And they kind of meant, uh, we now have the capacity to make between nanotech and

00:08:57.000 --> 00:09:03.000
And, uh, endless energy, and all these sort of… it was a techno-optimist manifesto of sorts.

00:09:03.000 --> 00:09:05.000
And it comes from a place of,

00:09:05.000 --> 00:09:13.000
oh my gosh, oh my gosh, like, we could… we could just overwhelm all these mo… all these places where there is scarcity with… with technology.

00:09:13.000 --> 00:09:21.000
And it's a little light on the barriers and between belief systems and regulations and politics and all that kind of stuff. It's pretty light on that.

00:09:21.000 --> 00:09:26.000
I've not read either of these books in full.

00:09:26.000 --> 00:09:37.000
But, um… but it was very much on the… in the techno-optimist, uh, vein. Then, very recently, Ezra Klein and Derek Thompson wrote Abundance, which I think doesn't have a subtitle.

00:09:37.000 --> 00:09:39.000
Which has become a piece of the democratic movement,

00:09:39.000 --> 00:09:46.000
and was saying, hey, one of the things that's preventing us from getting abundance on things like housing and other social goods,

00:09:46.000 --> 00:09:51.000
is over-regulation and constraints, and some people are critiquing this view as being kind of

00:09:51.000 --> 00:09:58.000
Neoliberal, it's very much, let's get the government, let's get regs out of the way so that we can generate abundance for everybody.

00:09:58.000 --> 00:10:03.000
Which is, uh, possible if we sort of let people get things built and done.

00:10:03.000 --> 00:10:09.000
Uh, the book, I think, has a very nice critique of progressives and liberals,

00:10:09.000 --> 00:10:13.000
who have layered in so many regs that it's hard to do things.

00:10:13.000 --> 00:10:16.000
I have a friend who's in commercial real estate here in Portland,

00:10:16.000 --> 00:10:24.000
And you only need to, like, glance at this topic, and he will regale you with stories about why it's so, so difficult

00:10:24.000 --> 00:10:26.000
Uh, to get things built or done.

00:10:26.000 --> 00:10:28.000
Uh, here in Portland.

00:10:28.000 --> 00:10:32.000
And then… and then…

00:10:32.000 --> 00:10:36.000
I've got a point of view on abundance that I'll just put in the room.

00:10:36.000 --> 00:10:39.000
Uh, which is that…

00:10:39.000 --> 00:10:45.000
humans who know how to live in community on the commons create abundance in many ways, together.

00:10:45.000 --> 00:10:48.000
And that it requires trust to do so.

00:10:48.000 --> 00:10:55.000
And so I created a little formula that I like, scarcity equals abundance minus trust.

00:10:55.000 --> 00:11:00.000
Which is not about either of the things that I just mentioned, the other two approaches from the other two books.

00:11:00.000 --> 00:11:03.000
It's more that…

00:11:03.000 --> 00:11:10.000
In places around the world, we used to know how to create abundance, and we didn't have to worry. People could be happy and well-fed.

00:11:10.000 --> 00:11:15.000
live well, and in some cases, Aboriginal cultures in Australia, for example,

00:11:15.000 --> 00:11:18.000
Way before the advent of things like money,

00:11:18.000 --> 00:11:23.000
Uh, you know, the payment of rent for shelter, all those kinds of things.

00:11:23.000 --> 00:11:31.000
And by raising this, I don't mean we should all abandon our homes and all currency and go back to a

00:11:31.000 --> 00:11:37.000
nomadic lifestyle, but I do mean that if we can manage to, uh,

00:11:37.000 --> 00:11:41.000
achieve small degrees of cooperation,

00:11:41.000 --> 00:11:45.000
a little bit like what, uh, Rick was saying a moment ago.

00:11:45.000 --> 00:11:51.000
Um, that we can… that we can collectively create abundance, much more than we think we can. That abundance is…

00:11:51.000 --> 00:11:59.000
is kind of at hand in how we think of resources and stewardship versus ownership and other things like that.

00:11:59.000 --> 00:12:02.000
Kevin and Kalia and Jose,

00:12:02.000 --> 00:12:08.000
We just did a little lightning round a moment ago about what we think abundance means.

00:12:08.000 --> 00:12:12.000
if it was a bumper sticker, kind of a really short phrase,

00:12:12.000 --> 00:12:28.000
a bumper sticker or sentence, if you'd like to take a swing at that, we'd love to hear what you think abundance means. You can also pass.

00:12:28.000 --> 00:12:29.000
Cool, got some specifics there. Kalia?

00:12:29.000 --> 00:12:33.000
Pooled and shared resources with, uh, mission-focused local investing.

00:12:33.000 --> 00:12:37.000
Um, I really like, um…

00:12:37.000 --> 00:12:42.000
Something that I've heard as sort of, um, a way…

00:12:42.000 --> 00:12:48.000
to get us through the wormhole that we're in, which is abundant enoughness.

00:12:48.000 --> 00:12:50.000
Like, there's a…

00:12:50.000 --> 00:12:55.000
Really a significant…

00:12:55.000 --> 00:12:59.000
challenge, where…

00:12:59.000 --> 00:13:06.000
People who have a lot, a lot are…

00:13:06.000 --> 00:13:11.000
continue to want a lot, and like…

00:13:11.000 --> 00:13:21.000
Like, how do people get into their nervous system? Like, they actually have enough, and they don't need to, like, accumulate more, and they can…

00:13:21.000 --> 00:13:28.000
choose to, like, co-create community together, because I'm in a bunch of circles…

00:13:28.000 --> 00:13:31.000
Where… like, people…

00:13:31.000 --> 00:13:39.000
Including this one. People say lots of nice things. Where's our community? Where some of us are living together?

00:13:39.000 --> 00:13:46.000
Um…

00:13:46.000 --> 00:13:52.000
you know, I mean, anyway, so abundant enoughness as a kind of frame that is a…

00:13:52.000 --> 00:13:56.000
sense of being that we can get into, so then that…

00:13:56.000 --> 00:14:03.000
people… those with resources are actually aligning and

00:14:03.000 --> 00:14:10.000
You know, and also, how are those people with resources, like, asking deeper questions about why are people hoarding?

00:14:10.000 --> 00:14:17.000
Well, they're hiding for good reason, so how do we help meet their needs without the need to hoard?

00:14:17.000 --> 00:14:21.000
Thanks, Goya. Um, Jose, did you want to…

00:14:21.000 --> 00:14:27.000
Jump in with a short…

00:14:27.000 --> 00:14:32.000
I, um… to be honest, I'm not sure what abundance means.

00:14:32.000 --> 00:14:34.000
Um…

00:14:34.000 --> 00:14:37.000
It's… it seems to be a good…

00:14:37.000 --> 00:14:42.000
catchphrase that we've all picked up, and a lot of us are talking about.

00:14:42.000 --> 00:14:45.000
But, um…

00:14:45.000 --> 00:14:49.000
I think abundance comes from technology, for the most part.

00:14:49.000 --> 00:14:52.000
whatever technology that means.

00:14:52.000 --> 00:14:57.000
Right? Social technology, physical technology, artifacts.

00:14:57.000 --> 00:14:59.000
Um…

00:14:59.000 --> 00:15:10.000
Is that what we mean by… by it? I don't know. I struggle with really sort of grasping what abundance means in these contexts.

00:15:10.000 --> 00:15:18.000
Thank you, Jose. Um, and I'll just add, there's a book from 2010 by Juliet Shore titled Plenitudes, The New Economics of True Wealth.

00:15:18.000 --> 00:15:26.000
Which plays with that notion that abundance is too much, that the goal of abundance winds up being a little bit like Peaches posted in the chat.

00:15:26.000 --> 00:15:32.000
consumer abundance. He writes, The Paradox of Abundance. We live in a world where we have a practical abundance of many things,

00:15:32.000 --> 00:15:38.000
food technology consumer goods, but overabundance of some, uh, for some people can cause addiction, affliction, disease,

00:15:38.000 --> 00:15:44.000
And the abundance isn't well distributed. Many people are starving and without basic needs. Totally agree.

00:15:44.000 --> 00:15:50.000
And so there's, like, this mirage that we all desire abundance, and I'm…

00:15:50.000 --> 00:15:53.000
I'm interested in Kalia's hack of the brain of,

00:15:53.000 --> 00:15:56.000
How do we convince more people that when they've got enough,

00:15:56.000 --> 00:16:05.000
It's good. They're gonna be fine, they're gonna be fine. More might actually even be damaging in different ways, either to them, or their family, or society. We don't know.

00:16:05.000 --> 00:16:09.000
But clearly, society is not very oriented in that way.

00:16:09.000 --> 00:16:12.000
With that, I will turn to the hands queue.

00:16:12.000 --> 00:16:14.000
And go to GIL.

00:16:14.000 --> 00:16:17.000
Yep. Yep.

00:16:17.000 --> 00:16:25.000
notable to me that until Pete's ad in the chat, none of us was talking about abundance as being lots of stuff.

00:16:25.000 --> 00:16:26.000
Mm-hmm.

00:16:26.000 --> 00:16:35.000
And I'll echo for those who came in later, my comment at the beginning was to reach back to a Jewish wisdom text called Pirkeavot, The Wisdom of the Ancestors.

00:16:35.000 --> 00:16:39.000
That asks, who is rich, the person who is content with their lot.

00:16:39.000 --> 00:16:46.000
Which I think is the mood of a lot of the comments, uh, that I've heard here. Jerry, you're, um…

00:16:46.000 --> 00:16:57.000
Uh, you're framing had a lot of moving parts in it, but I just want to pick up on the books. I haven't read either of them either. I know that I really need to read Ezra Klein because of where it is in the contemporary dialogue.

00:16:57.000 --> 00:17:00.000
Uh, but I'm really struck by how

00:17:00.000 --> 00:17:12.000
how off the debate over too much regulation versus too little regulation is. Uh, we, all of us, depend on it, and there's too much in many places. I mean, I live in Berkeley, I know a little bit about housing regulation being a pain in the ass.

00:17:12.000 --> 00:17:23.000
But, you know, these things happen because people built buildings that fell down on people's heads and were fire traps and et cetera. So, you know, that's part of what the Commons does, is set boundaries.

00:17:23.000 --> 00:17:25.000
of what we do together.

00:17:25.000 --> 00:17:31.000
Uh, and so… and I've had, in my professional work, I've had a bit to do with intelligent regulation.

00:17:31.000 --> 00:17:34.000
Where, um…

00:17:34.000 --> 00:17:43.000
Where businesses can actually embrace it, because it provides certainty and clarity, and not burdensome paperwork barriers to getting things done, but makes things work better. And it's a question of

00:17:43.000 --> 00:17:47.000
how we're designed, and by whom and for what.

00:17:47.000 --> 00:17:51.000
Uh, so, it's an example of just, you know,

00:17:51.000 --> 00:17:57.000
And I don't know if I'm… I don't know if I'm accurately blaming Klein for this, I generally like his work, but I'm surprised by what I hear about this

00:17:57.000 --> 00:18:05.000
this book as being, you know, a kind of, you know, maybe a seriously misframed argument.

00:18:05.000 --> 00:18:11.000
Which is part of what I was hoping we would sort of touch in this conversation. Thanks for putting that on the table, Gil.

00:18:11.000 --> 00:18:13.000
Uh, John?

00:18:13.000 --> 00:18:17.000
Yeah, this isn't a… well, I'll just say, um…

00:18:17.000 --> 00:18:23.000
I'm… I'm interested also in the connection, and this goes back to Kalia's comment, is…

00:18:23.000 --> 00:18:29.000
Um, the term affluence, which, you know, has gotten a little bit of a…

00:18:29.000 --> 00:18:33.000
bad association, like, with affluenza and that kind of thing, but…

00:18:33.000 --> 00:18:38.000
Like, you go back to the origins of affluence and its abundant flow.

00:18:38.000 --> 00:18:43.000
And so I think, I think when you're talking about abundance, it's also…

00:18:43.000 --> 00:18:49.000
important, you know, to think of that verb element of it, you know, the flow, um…

00:18:49.000 --> 00:18:54.000
of abundance versus the hoarding of abundance, I think, is a real key.

00:18:54.000 --> 00:18:57.000
Um…

00:18:57.000 --> 00:19:06.000
And I think it's… I think it's interesting, you know, how words… the meanings of words change over time, but with the origin of affluence, affluence…

00:19:06.000 --> 00:19:12.000
You know, that's… there's a fluid flow, you know, element to that, and so…

00:19:12.000 --> 00:19:15.000
the idea of, in today's culture, where affluence,

00:19:15.000 --> 00:19:23.000
You know, the mental picture that may come to mind is this hoarding, you know, accrual type of thing is not what that…

00:19:23.000 --> 00:19:25.000
what that term was originally.

00:19:25.000 --> 00:19:31.000
you know, pointing to it all, so I think that's important.

00:19:31.000 --> 00:19:39.000
I love that. Thank you, John. And I think abundant flow, the perception of abundant flow, is what causes people to relax,

00:19:39.000 --> 00:19:41.000
And think maybe they don't need to hoard.

00:19:41.000 --> 00:19:48.000
So, seeing that there's more than enough for everybody in whatever the resource is that they're talking about,

00:19:48.000 --> 00:19:53.000
I think lets people relax, so there's… there's, I think, a bunch of nuance there about

00:19:53.000 --> 00:19:55.000
what we perceive to be available,

00:19:55.000 --> 00:20:01.000
How durable we think it'll be, you know, all that kind of thing. Gil, I think your hand is still up from earlier.

00:20:01.000 --> 00:20:04.000
Uh, so I'll go to class.

00:20:04.000 --> 00:20:10.000
Yeah, I think that what we perceive abundance depends very much on.

00:20:10.000 --> 00:20:19.000
On our personal position to it, our… the way we… we… see ourselves and the world around us, because there's no way that.

00:20:19.000 --> 00:20:27.000
Physical goods and physical well-being can… is… will ever be evenly distributed. There will always be… Some who have more than others.

00:20:27.000 --> 00:20:34.000
Um, but the… the… both… both in the New Testament way of thinking, in Buddhism.

00:20:34.000 --> 00:20:39.000
You know, it's about how you position yourself within the world around you.

00:20:39.000 --> 00:20:44.000
So the notion of suffering, you know, you cause yourself to suffer by.

00:20:44.000 --> 00:20:47.000
By wanting, you know, by wishing to have, and so on.

00:20:47.000 --> 00:20:52.000
And so… so I think it's… it's… it's a very unique concept.

00:20:52.000 --> 00:20:57.000
On a very individual level.

00:20:57.000 --> 00:21:03.000
And also has really interesting complications on a cultural, societal level around the world.

00:21:03.000 --> 00:21:08.000
There are lots of, I think, different perceptions of it, that only a few of which were probably

00:21:08.000 --> 00:21:10.000
aware of in different ways.

00:21:10.000 --> 00:21:13.000
Uh, Jesse, please.

00:21:13.000 --> 00:21:17.000
Thanks, Eric. Can you repeat that statement that you said about abundance without trust?

00:21:17.000 --> 00:21:19.000
Can you repeat that?

00:21:19.000 --> 00:21:21.000
Sure, uh, scarcity equals abundance minus trust, meaning

00:21:21.000 --> 00:21:23.000
That's right.

00:21:23.000 --> 00:21:27.000
Meaning, humans knew how to create abundance, but it took trust to do it.

00:21:27.000 --> 00:21:33.000
So when you… when you squish out the trust in those systems, you get scarcity.

00:21:33.000 --> 00:21:46.000
And then capitalism, by the way, loves scarcity. I went to business school where they teach you that scarcity equals value.

00:21:46.000 --> 00:21:47.000
Yeah.

00:21:47.000 --> 00:21:49.000
And what they mean, partly, is that unless there's scarcity, there's no business model, so you better create some scarcity, et cetera, et cetera, et cetera, and I never… I never liked that framing at all.

00:21:49.000 --> 00:22:01.000
Yeah, thank you for that. And then John's, um, version of, of without hoarding, it seems like that statement could be used without hoarding as well. Um, and you said something about if you have enough,

00:22:01.000 --> 00:22:06.000
Um, then there's no… maybe there's no tendency to, and I heard this story of a person

00:22:06.000 --> 00:22:11.000
overseas, who was with someone who was panhandling, I don't know the word these days, but…

00:22:11.000 --> 00:22:17.000
Um, and he… he was in the more poorer part of the neighborhood.

00:22:17.000 --> 00:22:26.000
And he said, um, he walked by, and he's like, why don't you just go up the street in the richer part of the neighborhood? And he's like, oh, I've done that. They don't give as much.

00:22:26.000 --> 00:22:34.000
And so, I'm seeing that people, when you get enough, it's not enough ever. It's, like, evolutionary.

00:22:34.000 --> 00:22:39.000
And also, I want to bring up the book that was given to me the other day called Pendulum.

00:22:39.000 --> 00:22:49.000
And, um, it's like every 40 years, we go from me to we, and not the me to we that we know of, but a different kind of, um, cooperative version of life.

00:22:49.000 --> 00:22:59.000
That, um, was spoken about, um, to more of individualism, and it's like a system, this just pendulum that's kind of, we're in it, and we're, um…

00:22:59.000 --> 00:23:09.000
not necessarily everywhere in the world, I guess, but definitely in America. I can see that.

00:23:09.000 --> 00:23:10.000
Thank you. John, please.

00:23:10.000 --> 00:23:24.000
I just wanna… just wanna riff off what Klaus said and what you said, Jerry, about scarcity equals abundance minus trust. In my experience, scarcity can also equal abundance minus awareness.

00:23:24.000 --> 00:23:28.000
gave a presentation to a group of agricultural

00:23:28.000 --> 00:23:31.000
producers up in Walla Walla, um, a year ago,

00:23:31.000 --> 00:23:38.000
Where I went through this whole thing of the hydrographs, the streamflow, the amount of water flowing through the watershed.

00:23:38.000 --> 00:23:41.000
And I finished my presentation, and…

00:23:41.000 --> 00:23:47.000
It was silent, and then this one guy spoke up and said, I don't… I don't know that I believe what you just said.

00:23:47.000 --> 00:23:55.000
And, I mean, it's like, there was no conjecture or anything in it. It was just all, you know, streamflow gauges and mathematics and whatnot.

00:23:55.000 --> 00:23:57.000
But it drove home to me…

00:23:57.000 --> 00:23:59.000
Like, here I had this…

00:23:59.000 --> 00:24:02.000
pretty clear picture in my mind of the abundance

00:24:02.000 --> 00:24:08.000
And these other guys in the room, like, didn't have that mental picture at all.

00:24:08.000 --> 00:24:17.000
And I think trust is an issue there, but upstream of trust is, like, if you're not even aware of the abundance, or as Klaus said, if you're…

00:24:17.000 --> 00:24:24.000
your perspective, you're seeing the system like you don't have water, then water is scarce. If you have plenty of water.

00:24:24.000 --> 00:24:31.000
Water is abundant, and I agree, I agree with that.

00:24:31.000 --> 00:24:34.000
Thank you. Um, there's a bunch of interesting

00:24:34.000 --> 00:24:37.000
interlocking concepts here. Klaus was putting in the chat.

00:24:37.000 --> 00:24:40.000
about Tanha and Santuti.

00:24:40.000 --> 00:24:44.000
different concepts, I think, from Sanskrit.

00:24:44.000 --> 00:24:50.000
And there's also a parigrapha, which is non-grasping, so it's similar. And these are all…

00:24:50.000 --> 00:24:58.000
Um, these are sort of Paragraja is one of the Yamas, or abstinences, of yoga, of original yoga from Patanjali.

00:24:58.000 --> 00:25:05.000
Yoga was a mental practice for a long, long, long time before it was a physical practice with asanas.

00:25:05.000 --> 00:25:08.000
And it has really good advice for living.

00:25:08.000 --> 00:25:11.000
It's really nicely done.

00:25:11.000 --> 00:25:15.000
And if more of us paid attention to some of the presets there, maybe we would have

00:25:15.000 --> 00:25:19.000
more abundance collectively.

00:25:19.000 --> 00:25:21.000
I'm also struck with, uh…

00:25:21.000 --> 00:25:27.000
water, um, um, there's a name for this sort of watershed management. There's a different word for it, but

00:25:27.000 --> 00:25:32.000
working your land with swales and other kinds of things so that

00:25:32.000 --> 00:25:37.000
You have your land catches and holds, retains more water.

00:25:37.000 --> 00:25:44.000
than industrially farmed land or other kinds of lands do. And that creates an abundance of water on your property.

00:25:44.000 --> 00:25:53.000
Dave Witzel and his wife Claudia and I visited Jumping Frogs Farms in… way above Petaluma many, many years ago.

00:25:53.000 --> 00:26:00.000
And, uh, we were talking to the two… the couple who own the farm, and they said, you know, there was really bad rainstorm last season,

00:26:00.000 --> 00:26:05.000
And, uh, I was sitting at home reading a book by the fireplace, and I got a call from a neighbor who said,

00:26:05.000 --> 00:26:07.000
Oh my gosh, oh my gosh, do you guys need help?

00:26:07.000 --> 00:26:10.000
And all their neighbors were industrial farmers.

00:26:10.000 --> 00:26:16.000
And the neighbor was like, oh my gosh, oh my gosh, do you need help? We're flooding, we have all kinds of bad things happening. And she described to us how

00:26:16.000 --> 00:26:24.000
Um, they had a bunch of ponds and a bunch of very absorbent land on their property. Nothing bad was happening to their property because

00:26:24.000 --> 00:26:34.000
It was equipped to actually soak in really nice rains, and she was not worried. She was busy, like, enjoying reading a book.

00:26:34.000 --> 00:26:39.000
So that's a form of abundance. Jesse, can you say a little bit more about Pendulum?

00:26:39.000 --> 00:26:43.000
Oh, uh, well, the core theory is that

00:26:43.000 --> 00:26:50.000
Um, there's two extremes that we oscillate from me, periods of, like, individual, like, self-focused.

00:26:50.000 --> 00:26:54.000
And we periods that are collective and community-focused.

00:26:54.000 --> 00:26:59.000
And this pattern is kind of like a 40-year swing between those extremes.

00:26:59.000 --> 00:27:03.000
Um, and we're, like, there's a fulcrum of…

00:27:03.000 --> 00:27:05.000
Where the early 2000s,

00:27:05.000 --> 00:27:10.000
And the early 60s make opposite ends.

00:27:10.000 --> 00:27:14.000
And it's kind of reflected in music.

00:27:14.000 --> 00:27:18.000
Um, and art trends, and those societal swings are…

00:27:18.000 --> 00:27:22.000
like, just 10-year periods where they behave in predictable ways.

00:27:22.000 --> 00:27:26.000
And it traces back all the way back 3,000 years.

00:27:26.000 --> 00:27:30.000
And they kind of say how the East reflects the West.

00:27:30.000 --> 00:27:43.000
40 years behind, kind of thing, so I'm not sure. I haven't, like, read the whole book, but it was an interesting concept. It seems like it's mathematical, but, you know, everything's not predictable and human.

00:27:43.000 --> 00:27:45.000
But that's… it was an interesting thing.

00:27:45.000 --> 00:27:47.000
To see.

00:27:47.000 --> 00:27:51.000
Lovely, thank you for sharing that. I hadn't heard about the book, and um…

00:27:51.000 --> 00:27:53.000
really, uh…

00:27:53.000 --> 00:27:58.000
It's interesting. How is it… it was written in 2012, how has it not gotten more attention?

00:27:58.000 --> 00:28:08.000
Well, I would definitely look at it and, you know, see maybe why, but I haven't found it

00:28:08.000 --> 00:28:09.000
Yeah.

00:28:09.000 --> 00:28:11.000
I went… I didn't go deep enough to figure that out, but I see that there might be business implications for

00:28:11.000 --> 00:28:17.000
you know, why successful politicians or entertainers succeed?

00:28:17.000 --> 00:28:20.000
Um, based on the pendulum swing that we're in?

00:28:20.000 --> 00:28:28.000
like, certain music and certain words, like, I'm starting to hear the same kind of music that we did in the 70s right now, and there's, like, the bell bottoms, we came back, and…

00:28:28.000 --> 00:28:32.000
Um, it was a brief thing, but, you know, it just is interesting.

00:28:32.000 --> 00:28:34.000
It's enough to be like, uh-huh.

00:28:34.000 --> 00:28:37.000
There's… yeah, exactly.

00:28:37.000 --> 00:28:43.000
And there's a whole class of literature on cyclical theories of history.

00:28:43.000 --> 00:28:52.000
Uh, from the Great Transition to the fourth turning to, I don't know, there's like a… this is a whole class of literature, but this one seems like a really pragmatic explanation. I was like, well, things here, here, this is how things swing.

00:28:52.000 --> 00:28:59.000
Yeah, and, like, it's weird that, you know, we have this community-centered purpose, like, how can I serve?

00:28:59.000 --> 00:29:06.000
is, you know, a very strong book at one point that aligns with that we society, um,

00:29:06.000 --> 00:29:14.000
But… I don't know, what is Trump? Like…

00:29:14.000 --> 00:29:18.000
Love that. Yeah, thanks for bringing the book to our attention. I really appreciate it.

00:29:18.000 --> 00:29:21.000
the addition of the conversation. Stacy.

00:29:21.000 --> 00:29:26.000
Yeah, so if I can just start from where I am and connect to what a lot of you have said, and Jerry.

00:29:26.000 --> 00:29:31.000
Total… I think you're spot on with… I know you're spot on with the trust thing.

00:29:31.000 --> 00:29:36.000
But I want to mention how. Media and billionaires, and the…

00:29:36.000 --> 00:29:41.000
Conflicting stories are eroding that trust and how it pertains to now.

00:29:41.000 --> 00:29:49.000
Kalia put a comment in about the need for housing. And free transit, and um…

00:29:49.000 --> 00:29:55.000
A lot of the conversations I have are around what's happening in New York City with Mondani.

00:29:55.000 --> 00:30:01.000
And I just want to read to you one of the comments that I got in my private messages.

00:30:01.000 --> 00:30:06.000
Because it ties into some other things that are happening that have to do with free speech.

00:30:06.000 --> 00:30:11.000
And all the other cultural things that are happening. That the media is a big part of.

00:30:11.000 --> 00:30:17.000
So this is the message I got. You cunt whole Arab lover, cunt.

00:30:17.000 --> 00:30:22.000
Get the fuck out of New York. That scumbag will not be mayor, you cunt.

00:30:22.000 --> 00:30:26.000
This is just one of many. That I get quite frequently.

00:30:26.000 --> 00:30:30.000
Great, Scott.

00:30:30.000 --> 00:30:31.000
Stacy, why do you… why do you stay for that?

00:30:31.000 --> 00:30:34.000
That being said.

00:30:34.000 --> 00:30:38.000
I'm speaking, excuse me. Um, people get this all the time.

00:30:38.000 --> 00:30:46.000
And free speech is a very big issue. I know from speaking to people in other states.

00:30:46.000 --> 00:30:51.000
I know from my friends in Florida that there were tanks that drove by.

00:30:51.000 --> 00:30:58.000
In Black neighborhoods that were meant to intimidate people. Into not voting.

00:30:58.000 --> 00:31:05.000
I'm very clear on what's been happening for years. And I'm very clear that nobody's gonna shut me up.

00:31:05.000 --> 00:31:10.000
I was out the other night, and somebody… a friend came up to me and hugged me, and she said.

00:31:10.000 --> 00:31:16.000
Am I going to get put on a list? And she said it half-jokingly, but we weren't really joking.

00:31:16.000 --> 00:31:30.000
Um, anyway, what I wanted… so I got into conversation, and my conversations now are mostly local, and by… So, I put up a post, and it was about Cat Stevens tickets being $632.

00:31:30.000 --> 00:31:37.000
Because the argument I get from. People that are affluent in my community is.

00:31:37.000 --> 00:31:42.000
All the businesses are going to leave New York City. If we elect Mendani.

00:31:42.000 --> 00:31:45.000
I'm sorry, this is my new foster dog, and there's a story behind him, too.

00:31:45.000 --> 00:31:47.000
Hmm, okay.

00:31:47.000 --> 00:31:58.000
Um… So, I have people that are now defending the billionaires, and they're afraid that the billionaires are going to leave New York City.

00:31:58.000 --> 00:32:06.000
If, heaven forbid, we have affordable housing and free transportation. This gives me an opportunity to speak to them.

00:32:06.000 --> 00:32:11.000
The gentleman that posted that. I then took his post.

00:32:11.000 --> 00:32:18.000
And publicly put it right up there. Because after I looked through his page and saw all of his Jesus quotes.

00:32:18.000 --> 00:32:24.000
I wanted the community to see who this guy is. I'm not afraid of him.

00:32:24.000 --> 00:32:27.000
So, in answer to your question, Gil, I keep doing it.

00:32:27.000 --> 00:32:34.000
Because I know that there are good people on both sides, especially in my community.

00:32:34.000 --> 00:32:42.000
And I know that there was a lot of manipulation. Um, very quick short story that will also answer that, if I may.

00:32:42.000 --> 00:32:47.000
Well, maybe… You know, I'm gonna stop, take care of the dog.

00:32:47.000 --> 00:32:54.000
And then hopefully I'll get the opportunity to speak again later.

00:32:54.000 --> 00:32:55.000
Cool. Um, thank you.

00:32:55.000 --> 00:32:58.000
Yeah, let me do that, thank you.

00:32:58.000 --> 00:33:01.000
Uh, Kevin?

00:33:01.000 --> 00:33:09.000
Yeah, abundance. So I'm doing a thing to create it. I'd like to describe, if I could for a minute.

00:33:09.000 --> 00:33:16.000
Uh, you know, we lost our house. It's actually in the phrase, uninhabitable. We didn't lose it. It could be redone.

00:33:16.000 --> 00:33:23.000
And 1 in 6 people in my neighborhood, I just want to know, are low status, unincorporated neighborhood.

00:33:23.000 --> 00:33:31.000
Lost their houses. Higher… highest of anything in the… in the Southeast, and um…

00:33:31.000 --> 00:33:37.000
So we're gonna do a non-profit housing fund. And because it's a non-profit.

00:33:37.000 --> 00:33:44.000
It means everybody can talk about it, and so, you know, a PTA officer can talk to a volleyball coach about it.

00:33:44.000 --> 00:33:52.000
And it'll be community-directed capital, and the community will get more money back than the affluent people who write big checks.

00:33:52.000 --> 00:33:58.000
And so we're going to use that to help this low-status neighborhood have a seat at the table.

00:33:58.000 --> 00:34:09.000
And there's starting a Latino business association, just the population grew by 18%, and it was the cheapest place, so… It's a lot of Latino, but there's no…

00:34:09.000 --> 00:34:16.000
Clarified way for aid groups to write them a check. The Restaurant Association had an association, and so there was a restaurant.

00:34:16.000 --> 00:34:30.000
Employee support fund, but the food trucks and caterers and Latino folks, there was no place to write a check, so they're creating an entity to be at the table, and it matters right now.

00:34:30.000 --> 00:34:34.000
Because there are these small area plans being put out, and that's, like.

00:34:34.000 --> 00:34:42.000
Redesigning this place after the disaster, right? And one of them is the counties, and it's broad, and it's messy.

00:34:42.000 --> 00:34:59.000
And… but then there's a separate small area plan that's competing to be the story, and it's led by people with the Chamber of Commerce and realtors, and they only do outreach to Latinos, you know, on one occasion or whatever. But obviously, they're… they would cause displacement.

00:34:59.000 --> 00:35:07.000
Right? Because they're… they're motivated. For increasing property values, and increasing property values puts the people who were at risk of.

00:35:07.000 --> 00:35:27.000
Because it's a place people already fled to. It's $100,000 less per house than the rest of the county, so more Latino, more… Black folks that got, uh, pushed away. And so we're going to create a political power using a fund, and then the fund will also have to increase biodiversity, because everybody's house is at risk because the ground got scoured.

00:35:27.000 --> 00:35:41.000
So we have dead soil, and you need biodiversity to hold the soil to reduce the housing risk, so we can… we can, you know, we can… we can measure the housing success by the health of the river.

00:35:41.000 --> 00:35:46.000
And then along with a number of people who are housed. So I think it's going to be a real popular story.

00:35:46.000 --> 00:35:58.000
And uh… and we got a whole lot of the partners engaged, and I got, you know, the best community organizer says this is a really good plan, and… And folks who are, you know.

00:35:58.000 --> 00:36:02.000
There's a real credible community group that we're designing it for.

00:36:02.000 --> 00:36:15.000
Uh, called Suenovo Communities Together, and they're the… Social safety net below everybody else, you know, when you have no rent or utility bill, you go to them, and they do it about $60,000.

00:36:15.000 --> 00:36:19.000
A month, they've done that really good job, and they realize, well, we need to solve housing, you know.

00:36:19.000 --> 00:36:25.000
400 people lost their houses, so, uh, so we're gonna start with housing and create biodiversity.

00:36:25.000 --> 00:36:31.000
So I think it should be pretty fun, and you know, might even include my house, who knows, you know?

00:36:31.000 --> 00:36:34.000
So… just… and this should be fun.

00:36:34.000 --> 00:36:38.000
Kevin, thank you for describing that. It is just curious,

00:36:38.000 --> 00:36:44.000
Is that activity convincing you to stay closer to spontanoa? Because I think you've been pulled… you've been pulling…

00:36:44.000 --> 00:36:45.000
You've been pulling yourselves away from Svanoa because it's just been so sad?

00:36:45.000 --> 00:36:54.000
Yeah, it… Yeah, you know, that's interesting, because we moved to the River Arts District, which is a highly, uh…

00:36:54.000 --> 00:37:08.000
Access place, you know, it's… it's where the artists are, and they want to be more like this road in Santa Fe, where rich folks come and buy art, and they don't live in the loss of being displaced is not a problem, and so the Chamber of Commerce and the Tourism Development is.

00:37:08.000 --> 00:37:18.000
All behind the artists who were taking their, their… well-resourced artists taking their future in their hands, and so it's, like, not much for me to do.

00:37:18.000 --> 00:37:22.000
And then this came along, that somebody reached out and said, you know.

00:37:22.000 --> 00:37:29.000
Could you use some of this neighborhood economic stuff around the problems we're trying to address? You know, they're trying to do.

00:37:29.000 --> 00:37:34.000
Food and housing and transportation, but housing is the one that's making everything worse.

00:37:34.000 --> 00:37:44.000
So we're gonna, you know, they lead their Latino and biracial and all that, and, you know, we're designing it for this really trusted community entity.

00:37:44.000 --> 00:37:55.000
That has, you know, housing groups around it, mountain home, mountain housing and habitat, and… land trusts, you know, all kinds of big stakeholder resources around it.

00:37:55.000 --> 00:38:07.000
But I don't think nobody's ever measured, uh, you know, low-income housing to… reducing risk by biodiversity, so I think that's kind of an intriguing, uh.

00:38:07.000 --> 00:38:10.000
Question that we want to do both of those things.

00:38:10.000 --> 00:38:15.000
I love that. Thanks, Kevin. And then you're making me wonder many things, one of which is,

00:38:15.000 --> 00:38:21.000
Why aren't property and casualty insurance companies all over this? Why aren't they all into

00:38:21.000 --> 00:38:24.000
So, the ecological ways to reduce

00:38:24.000 --> 00:38:28.000
environmental risks, et cetera, et cetera, et cetera. They should be…

00:38:28.000 --> 00:38:31.000
They should be promoting, funding, explaining

00:38:31.000 --> 00:38:36.000
storytelling, everything, and all they're really doing is, like, calculating

00:38:36.000 --> 00:38:39.000
you know, calculating stats and then raising rates.

00:38:39.000 --> 00:38:45.000
or pulling out of dangerous reasons… regions, because… but it's uninsurable.

00:38:45.000 --> 00:38:51.000
We did what we could. We raised rates as far as we could, and then it's, you know, uninsurable. That maybe I'm just not perceiving their efforts, but…

00:38:51.000 --> 00:38:58.000
Yeah. Yeah, we have some startups who were doing community embedded insurance. You know, you're not able to, uh, make a profit on, uh.

00:38:58.000 --> 00:39:09.000
Property. Now, with climate things. It needs to be collectively owned, and the return goes back into reducing risk. That model makes sense, you know.

00:39:09.000 --> 00:39:15.000
Extract your profits, you know, in property insurance is short-term, and you need to put it into something that will.

00:39:15.000 --> 00:39:21.000
Be there when things go worse, you know. So, we're linking in, uh.

00:39:21.000 --> 00:39:26.000
Community-embedded insurances. You know, people are pooling and sharing their resources together, sharing risk.

00:39:26.000 --> 00:39:27.000
So,

00:39:27.000 --> 00:39:29.000
So, you know, and then the community owns the balance sheet.

00:39:29.000 --> 00:39:36.000
Yeah, yeah, so let me pull on one more thing you said, which is, it seems like, um, terrible climate events are making places

00:39:36.000 --> 00:39:41.000
Uninsurable or uninvestable as real estate, which is driving

00:39:41.000 --> 00:39:45.000
The collective… not collectivization, but community land trusts. Basically, the restructuring of ownership or stewardship of land

00:39:45.000 --> 00:39:50.000
Yeah, yep.

00:39:50.000 --> 00:39:51.000
Which is a good thing.

00:39:51.000 --> 00:40:02.000
Yeah. The one session I'm, uh, moderating is the one that puts all weird stuff together. It's collective purchasing, and it's the library of things from Shareable.

00:40:02.000 --> 00:40:08.000
And it's a real grassroots crowdfunding, and so what if you just pooled and shared your resources, but then you found a way to.

00:40:08.000 --> 00:40:23.000
For the community to invest alongside your pooling and sharing. I mean, nobody's done that, and that would be a… a really easy, you know, uh… too adhesive approach. We're looking for some of these things that you could launch together, where if you launch one.

00:40:23.000 --> 00:40:26.000
It helps the other. And some of those things are happening.

00:40:26.000 --> 00:40:30.000
You know, there is infrastructure coming, you know, and uh… Sure.

00:40:30.000 --> 00:40:35.000
Thank you, that was great. Really, um, super… I love what you're… what you're working on.

00:40:35.000 --> 00:40:37.000
Uh, Stacy, please.

00:40:37.000 --> 00:40:38.000
Yeah.

00:40:38.000 --> 00:40:39.000
I think it should be fun.

00:40:39.000 --> 00:40:45.000
I have a very cynical, conspiratorial answer to your question about insurance companies.

00:40:45.000 --> 00:40:49.000
And that is that I do believe they want people to lose their properties.

00:40:49.000 --> 00:40:53.000
So that they can be bought up. Very simple.

00:40:53.000 --> 00:40:59.000
I can smell the cynicism on that one. Thanks, Stacey.

00:40:59.000 --> 00:41:00.000
Uh, Pete?

00:41:00.000 --> 00:41:08.000
I wanted to chime in with some thoughts about that answer, too. As Stacy, I really like yours, and I think that happened, certainly.

00:41:08.000 --> 00:41:16.000
I think there's also a structural thing in the way that we run our economy, and hierarchical

00:41:16.000 --> 00:41:18.000
hierarchical…

00:41:18.000 --> 00:41:28.000
corporate entities and their decision-making. Um, I think it's… it's easy for people on the ground to see a situation and go, you know, there's a…

00:41:28.000 --> 00:41:33.000
a thoughtful, system-friendly approach to

00:41:33.000 --> 00:41:35.000
Um, making the situation better.

00:41:35.000 --> 00:41:43.000
But when you report to somebody who reports to somebody who reports to somebody, it goes up to the boardroom, and the…

00:41:43.000 --> 00:41:48.000
upper management, and they don't… they don't have that same nuance of decision-making.

00:41:48.000 --> 00:41:51.000
So, I think… I think we see over and over…

00:41:51.000 --> 00:41:58.000
big hierarchical, uh, corporate structures make really dumb decisions, not because…

00:41:58.000 --> 00:42:07.000
It's the best kind of decision to make, but we've rewarded the creation of these big, dumb hierarchical things that are…

00:42:07.000 --> 00:42:12.000
theoretically kind of easy to manage, um, and… and just accrete size.

00:42:12.000 --> 00:42:24.000
Uh, so… so, of course, they make dumb decisions, um, uh, instead of thoughtful systems-friendly approaches to situations on the ground.

00:42:24.000 --> 00:42:28.000
Thank you. Um, I… I…

00:42:28.000 --> 00:42:31.000
I would love to hear from four-sighted…

00:42:31.000 --> 00:42:36.000
business folks who are doing the opposite somewhere, that would be great. It'd be a…

00:42:36.000 --> 00:42:43.000
Our joy to my heart to have people jump into this conversation who are like, no, no, no, we had this initiative, we did this thing,

00:42:43.000 --> 00:42:45.000
Look, look, look, it's, you know, all over the place, but…

00:42:45.000 --> 00:42:46.000
I'm not… I'm not seeing it yet.

00:42:46.000 --> 00:42:47.000
It's a very interesting conversation. Thanks for asking.

00:42:47.000 --> 00:42:49.000
Jesse?

00:42:49.000 --> 00:42:51.000
Um, while I'm working on one.

00:42:51.000 --> 00:42:52.000
Excellent.

00:42:52.000 --> 00:42:59.000
Talking… talking with the city of Seattle, I'm talking with, um, cooperatives, and we're starting to visualize, um,

00:42:59.000 --> 00:43:12.000
Uh, place-based resources, not just talent, but also goods and services, so we can match them and start… I realize that when we start visualizing these resources, you can start seeing the gaps that Stacy starts seeing, um, you know,

00:43:12.000 --> 00:43:18.000
When you verbalize that, that's one thing, but when you have… when you can… when you can visualize the dumb decisions,

00:43:18.000 --> 00:43:25.000
And start looking at data-informed decisions, um, visualization really helps. So, Kevin…

00:43:25.000 --> 00:43:31.000
I have lots of people who are Stanford Housing. It doesn't sound like you have an actual…

00:43:31.000 --> 00:43:38.000
You have everyone you need at the table for housing, um, but as we move away from conceptual definitions of abundance,

00:43:38.000 --> 00:43:42.000
to meeting people's needs in a specific place-based community.

00:43:42.000 --> 00:43:48.000
I sincerely believe that visualization of talents and goods and services

00:43:48.000 --> 00:43:49.000
supports the needs of that community, and I would love to support and talk with you

00:43:49.000 --> 00:43:53.000
Yeah.

00:43:53.000 --> 00:44:01.000
Um, because when we're working with land trusts, that's a perfect example of utilizing the fingers of

00:44:01.000 --> 00:44:02.000
Um, the people that they're working with.

00:44:02.000 --> 00:44:03.000
Yeah.

00:44:03.000 --> 00:44:04.000
And so I'll just place… I'll put the mapping project we're putting down

00:44:04.000 --> 00:44:16.000
Yeah. I would love to talk to you about that. You know, I've done some pretty serious mapping out. I was telling this story, if I can tell you a brief mapping story, it's kind of interesting, I think.

00:44:16.000 --> 00:44:20.000
I was working with Mark Beam, as some of you know, and Gary Bowles.

00:44:20.000 --> 00:44:26.000
And we were mapping, uh, the distribution of malaria nets in Uganda.

00:44:26.000 --> 00:44:28.000
Link to the Global Fund on AIDS and, uh, you know, etc.

00:44:28.000 --> 00:44:31.000
Yes.

00:44:31.000 --> 00:44:41.000
And we were able to show that the nets were going to where Musandi's cronies were, as opposed to where the malaria area. There's a gray market in it.

00:44:41.000 --> 00:44:52.000
And, you know, I was working with Jeffrey Sachs, which you should never do, at the ERSE Institute, and he said, you know, I'm going to hold up $40 million to Ms. Venney, and they said.

00:44:52.000 --> 00:45:07.000
Dude, we move millions a year. You know, 70… $30 million is not going to make us have a conscience, you know? We won't take your money. We're taking everybody else's money, don't worry about it. And so he didn't realize that.

00:45:07.000 --> 00:45:24.000
Showing clearly that they were wrong. Would not make them… change their behavior at all, because the guy misread the power in the room. I mean, that's the problem with Jeffrey Sachs. He lives in this abstract world where he thought $30 million was gonna make a billionaire.

00:45:24.000 --> 00:45:25.000
Yeah.

00:45:25.000 --> 00:45:27.000
Gravel. So anyway, yeah, no, I believe in mapping. I think this really needs it.

00:45:27.000 --> 00:45:32.000
And working with the Uganda, I'm working with someone right now who, um,

00:45:32.000 --> 00:45:37.000
They haven't had food. You know, aid was removed from President Trump.

00:45:37.000 --> 00:45:40.000
Um, they haven't had food for two and a half weeks.

00:45:40.000 --> 00:45:42.000
And they're like…

00:45:42.000 --> 00:45:47.000
they don't… they're not a resilient, self-efficient, um,

00:45:47.000 --> 00:45:48.000
Yeah.

00:45:48.000 --> 00:45:55.000
And so, um, all they need is used cooking oil to create soap so they can create hygiene and have the business angle that he's going on.

00:45:55.000 --> 00:45:58.000
But right now, it's just like food. They don't have it. Two and a half weeks now.

00:45:58.000 --> 00:46:07.000
It's just really… it's… it's saddening, so…

00:46:07.000 --> 00:46:08.000
All right, that's do it.

00:46:08.000 --> 00:46:19.000
Wow. I'd love to talk to you later in October when my conference is coming up, like, in 3 days, about visualization for this project when I get back home. I think it's really important, yeah, there's a lot of… stories you can… because there's trails with markers and things here, right? I mean, so you could embed.

00:46:19.000 --> 00:46:26.000
Your content, you know, along this trail with this story. I mean, this is, you know, this trail is where the first massacre was, you know.

00:46:26.000 --> 00:46:29.000
That kind of thing. So, yeah, there's a lot of it.

00:46:29.000 --> 00:46:48.000
Yeah, because, you know, people are doing greenways. There's a lot of money for greenways, and the greenways get markers, and there's QR codes, etc. There's stories you could, uh… Yeah, because the housing fund will be lower risk if we're more biodiverse. So, you know, that's… people want to picture those two things together.

00:46:48.000 --> 00:46:51.000
Thanks, guys. Um…

00:46:51.000 --> 00:46:53.000
Gil?

00:46:53.000 --> 00:47:04.000
Yeah, I love the conversation about mapping, both physical mapping and systems mapping, and causal loops, and all sorts of ways of helping people see and perceive the complexity they know. There's a guy named Scott Spann,

00:47:04.000 --> 00:47:13.000
Uh, who's done remarkable work with multi-stakeholder community mapping, where people, a large group of people, build the maps together.

00:47:13.000 --> 00:47:24.000
Um, and, um, you know, there'll be a… there'll be a starting… maybe a starting point, hypothetical map, and the question is, okay, what… what in your world are you not seeing on the wall? Put it on.

00:47:24.000 --> 00:47:30.000
And they keep doing that until it's a complete representation of all the stakeholders in the community. It's driven some remarkable

00:47:30.000 --> 00:47:33.000
projects of transformation. Kevin, I want to connect you up with him.

00:47:33.000 --> 00:47:37.000
Uh, after the conference, perhaps. And, uh, I'd love to

00:47:37.000 --> 00:47:42.000
be in this conversation you guys are having. Back on the insurance… excuse me,

00:47:42.000 --> 00:47:44.000
Back on the insurance theme,

00:47:44.000 --> 00:47:54.000
Um, you know, we see this really starkly in the aftermath of the LA fires, where the state's response was, let's lighten the regulations so people can rebuild faster.

00:47:54.000 --> 00:47:58.000
Rather than, let's have regulations that has people…

00:47:58.000 --> 00:48:03.000
Bye, Kevin. That has… that encourages people to build buildings that are fire resilient.

00:48:03.000 --> 00:48:10.000
Uh, and we've all seen pictures of earthquakes where entire neighborhoods are flattened and one house is still standing.

00:48:10.000 --> 00:48:17.000
Uh, or floods, where somebody sort of, you know, there's a community in Florida that survived the hurricane, the last round of hurricanes, completely intact.

00:48:17.000 --> 00:48:24.000
Because of their land use planning, sponge, you know, sponge land use, resilient buildings, and so forth.

00:48:24.000 --> 00:48:32.000
There are ways at that, and there's an opportunity for insurance. The precedent was 100 and some odd years ago in Fireman's Fund, which was doing business safety insurance.

00:48:32.000 --> 00:48:40.000
started to provide free safety audits for the businesses they were insuring to come in and show them how to reduce their risk.

00:48:40.000 --> 00:48:47.000
At no cost to the businesses, and, you know, crazy like a fox for Fireman's Fund, because it meant less payouts for damage for them.

00:48:47.000 --> 00:48:54.000
And that's a model that has been, you know, mostly honored in the breach in the industry since then, but there's enormous opportunity.

00:48:54.000 --> 00:49:11.000
For strategic insurance play. Joshua Harrison from the Center for the Study of the Force Majeure and I and our GPTs are working on some white papers on laying out a different kind of insurance, business-focused insurance industry strategy, whereby companies could do the kind of things we're talking about.

00:49:11.000 --> 00:49:16.000
Rather than just saying, oh, no, the calculations say we can't insure you so we can write off entire states.

00:49:16.000 --> 00:49:24.000
When screw you. Very different approach.

00:49:24.000 --> 00:49:25.000
You know?

00:49:25.000 --> 00:49:27.000
Um, we're going at warp speed. We haven't even hit the hour yet. Why don't we slow down for a second?

00:49:27.000 --> 00:49:57.000
And uh… take a pause, and I'll bring us back in just a second.

00:50:40.000 --> 00:50:46.000
Just reflecting on the… I'm looking at the chat a little bit, and this conversation, and I'm realizing that

00:50:46.000 --> 00:50:52.000
there… there seem to be, from my amateur perspective, many things we've created as

00:50:52.000 --> 00:50:55.000
policy, law, regulation,

00:50:55.000 --> 00:51:00.000
that lead to scarcity or break abundance. One of those is zoning.

00:51:00.000 --> 00:51:08.000
One of those, for example, is we created wilderness areas and national parks where we drove people who understood how to manage the landscape off the land.

00:51:08.000 --> 00:51:10.000
We don't, you know, don't let people live in there.

00:51:10.000 --> 00:51:13.000
Which I think is a mistake.

00:51:13.000 --> 00:51:19.000
And we're now, in some places, they're reconsidering the mistake and thinking, oh, maybe we should reverse track on that, but…

00:51:19.000 --> 00:51:22.000
It's only a couple hundred years… it's 100 years plus too late.

00:51:22.000 --> 00:51:26.000
Um, on those things, but it seems like we bake

00:51:26.000 --> 00:51:29.000
We make a lot of decisions

00:51:29.000 --> 00:51:31.000
that aren't based on…

00:51:31.000 --> 00:51:36.000
rational, systemic thinking, then we bake those in as laws, and then we, you know,

00:51:36.000 --> 00:51:40.000
50 years later go, gosh, that didn't turn out so well.

00:51:40.000 --> 00:51:44.000
And I don't like that we do that as societies.

00:51:44.000 --> 00:51:49.000
Alright, Klaus, please.

00:51:49.000 --> 00:51:56.000
Yeah, the conversations just sparked, uh, something… we signed a contract with this co-pier, the, uh.

00:51:56.000 --> 00:52:08.000
Akuli generations, and they are headquartered in Kenya, in Nairobi. Um, and the intention is to connect, um.

00:52:08.000 --> 00:52:13.000
To connect local farmers, groups of local farmers, with resources that are available.

00:52:13.000 --> 00:52:20.000
Within the EU, mostly, in mostly EU-funded, but also. Within… within Africa.

00:52:20.000 --> 00:52:27.000
So they have… they already have 40 locations mapped out in Indonesia, different African states, and a couple, uh.

00:52:27.000 --> 00:52:38.000
Mediterranean countries, they are providing the AI intelligence. Technology embedded in their… in their system.

00:52:38.000 --> 00:52:47.000
And I'm, you know, personally developing. A strategic frame on how to engage, but the challenge here really is.

00:52:47.000 --> 00:52:54.000
That the, um… It requires a change in behavior of subsistence farmers.

00:52:54.000 --> 00:52:59.000
Um, they have to combine them, first of all, into groups, because.

00:52:59.000 --> 00:53:07.000
A small farmer is just not cost-effective to… to represent in any form or shape, so we are combining.

00:53:07.000 --> 00:53:15.000
Groups of farmers into, like, a hundred of them. They are governed by elders, it's a non-hierarchical system.

00:53:15.000 --> 00:53:22.000
That's all secured through the management structures. Um, and by combining them.

00:53:22.000 --> 00:53:30.000
And then consolidating their behavior, meaning we are developing. A regenerative practice that's… that's…

00:53:30.000 --> 00:53:34.000
Cook, that's the right one for their location and for their markets.

00:53:34.000 --> 00:53:38.000
Meaning the types of cops they're coin, the methods they're using.

00:53:38.000 --> 00:53:46.000
Are going to be uniquely tailored to their particular location. We can then tokenize this.

00:53:46.000 --> 00:53:50.000
Put it in contract forms. Organize it, and then bring it back to…

00:53:50.000 --> 00:54:00.000
The European Union, uh, uh. Agencies know that, uh, that are distributing these funds.

00:54:00.000 --> 00:54:11.000
So there's a… there's a pretty disciplined, uh. Requirement for this entire contracting scheme and for the entire MRV.

00:54:11.000 --> 00:54:16.000
I mean, missionments, reporting and values structure that goes with it.

00:54:16.000 --> 00:54:22.000
But I think the… the… The real challenge is that we have… we are floating.

00:54:22.000 --> 00:54:30.000
You know, at the theoretical and policy level. Um, with some great ideas, lots of money in there.

00:54:30.000 --> 00:54:40.000
But there's the vertical… link missing, you know, how do you… how do you operationalize this, uh, on the ground?

00:54:40.000 --> 00:54:48.000
Um, so we… so the AI system that we now have developed, now it's a 5-agent, uh.

00:54:48.000 --> 00:54:52.000
System that tracks the entire supply chain from farm to market.

00:54:52.000 --> 00:54:58.000
Um, and then… then there's a sixth agent, it's the enterprise agent, where we are customizing to.

00:54:58.000 --> 00:55:06.000
A specific location. Uh, to, to, uh… to then know what is going on in…

00:55:06.000 --> 00:55:15.000
In these… in these individual account… accounting groups. Um, but that's really, uh, in general, you know, the…

00:55:15.000 --> 00:55:23.000
It doesn't help to, uh, to what USAID did, for example, is buy food from American farmers.

00:55:23.000 --> 00:55:33.000
And put it into, uh, subsistence markets. That doesn't help, because the moment your food goes away, the whole system collapses, right?

00:55:33.000 --> 00:55:39.000
Um, there was no attempt. To assist these subsistence groups.

00:55:39.000 --> 00:55:51.000
To become self-sufficient, and to grow their own food. Now, and to, uh, and so the emphasis is on, let's sell them GMO seeds, which is actually really what happened.

00:55:51.000 --> 00:55:57.000
You know, Bill Gates all over the place, building synthetic nitrogen fertilizer plants in Africa.

00:55:57.000 --> 00:56:08.000
So the type of help that was given. Was really very selfish, you know? I mean, it was… it was not, uh, let's make these guys.

00:56:08.000 --> 00:56:17.000
Independence, or they can live. So that's… that's the overarching, you know.

00:56:17.000 --> 00:56:23.000
Strategic intent that we have, you know, is to connect these available resources.

00:56:23.000 --> 00:56:27.000
You know, with on-the-ground activity.

00:56:27.000 --> 00:56:37.000
Thanks, Klaus. I've heard some much more positive stories about development aid, because there have been some thorough and eviscerating critiques of development aid,

00:56:37.000 --> 00:56:42.000
you know, hey, we ship food in and the local farmers can't make a living anymore, et cetera, et cetera, but I think that

00:56:42.000 --> 00:56:49.000
somewhere in some places, and I don't know who, where, it's more nuanced than that, and they have been trying to teach

00:56:49.000 --> 00:56:53.000
Farmers to, you know, bootstrap farmers to get back into business, et cetera, et cetera. I don't…

00:56:53.000 --> 00:56:59.000
I don't know that it's as vicious as it just sounded from what you just said.

00:56:59.000 --> 00:57:00.000
Is it that bad?

00:57:00.000 --> 00:57:08.000
It is vicious, as I was just saying. It is horrible. I mean, they destroyed entire landscapes with GMO seeds and…

00:57:08.000 --> 00:57:13.000
And since that ignited nitrogen, inserting synthetic nitrogen into the arena.

00:57:13.000 --> 00:57:23.000
Was just, I mean, it's just criminal. And this is how often Bill Gates. And I don't submit bad intentions to someone like Bill Gates. He probably thought he's doing the right thing.

00:57:23.000 --> 00:57:34.000
He's actually embedded, he's a major investor in Monsanto. You know, it's actually embedded with these groups, and developing customized high-yield seeds, and…

00:57:34.000 --> 00:57:41.000
You know, the chemical support structure, but it is… it was just devastating. And you're dealing with completely uneducated.

00:57:41.000 --> 00:57:48.000
Subsistence farmers. Uh, you know, and you don't have the extensions and all that support.

00:57:48.000 --> 00:57:54.000
So, no, it's, uh, it's… but Africa is absolutely waking up.

00:57:54.000 --> 00:58:05.000
Now, to, uh, to what happened to them, and to make these changes, so… We are actually partnered with the University of Nairobi Extension.

00:58:05.000 --> 00:58:15.000
To, uh, uh, where they are guiding the process and providing us the credentials that we need in order to, you know, be packaged as, uh.

00:58:15.000 --> 00:58:18.000
Up the chain.

00:58:18.000 --> 00:58:25.000
Thank you. Uh, Doug, please.

00:58:25.000 --> 00:58:28.000
Muted.

00:58:28.000 --> 00:58:37.000
Just to augment the Bill Gates ironies, um… So, his big thing were these… these nets.

00:58:37.000 --> 00:58:45.000
Mosquito netting. In service to, you know, addressing the malaria problem.

00:58:45.000 --> 00:58:50.000
But as Klaus just mentioned. He's up to his neck in Monsanto.

00:58:50.000 --> 00:58:55.000
And… A friend of mine, Bernie Krause, who was a bio…

00:58:55.000 --> 00:59:02.000
Ecological bioacoustician. Um, you know, pointed out that.

00:59:02.000 --> 00:59:09.000
Um, those chemicals are eradicating. Amphibians, frogs.

00:59:09.000 --> 00:59:16.000
Frogs eat mosquitoes. Like, if you want to go natural systems, and you want to go.

00:59:16.000 --> 00:59:25.000
Regenerative, and you want to go non-colonial, non-patriarchal, non-capitalist. And actually speak to needs and problems.

00:59:25.000 --> 00:59:32.000
Um. That is not what Bill Gates is in the business of doing.

00:59:32.000 --> 00:59:40.000
Or any of them, for that matter. The billionaires, you know, are… Centered in their billions, or centered in capital.

00:59:40.000 --> 00:59:45.000
And everything they do is centered in capital and monopolization of.

00:59:45.000 --> 00:59:51.000
Which now extends to food. And GMO seed, and all of it.

00:59:51.000 --> 00:59:58.000
Um, I wanted to loop back around. But, Pete, if you wanted to be on this subject, then I'll stop here.

00:59:58.000 --> 01:00:01.000
And come back after you. Um, because I wanted to loop back around to… Something that was raised.

01:00:01.000 --> 01:00:05.000
Go ahead, Doug.

01:00:05.000 --> 01:00:11.000
Um, so… somebody mentioned, um, causal loop mapping.

01:00:11.000 --> 01:00:17.000
And so, I'm… I'm… at the genesis point, so this is really early, but…

01:00:17.000 --> 01:00:23.000
Some of you know Gene Bellinger, who's sort of, you know, the GOAT of.

01:00:23.000 --> 01:00:32.000
Causal loop mapping and model making very complex systems. And, um… And he did a Klaus.

01:00:32.000 --> 01:00:37.000
With causal loop mapping and AI. And he sort of developed, you know.

01:00:37.000 --> 01:00:44.000
Version 1 of a… of an AI template to augment his causal…

01:00:44.000 --> 01:00:51.000
Mapping exercise. And it sort of caught my eye, because…

01:00:51.000 --> 01:00:59.000
Um, causal loop mapping… done properly, human-mediated. This is not automating.

01:00:59.000 --> 01:01:07.000
Causal loops analysis. But it's… it… augmenting it with AI dramatically speeds it up.

01:01:07.000 --> 01:01:16.000
And also holds, at the end of the process, holds the… the promise of surfacing causes and things, variables.

01:01:16.000 --> 01:01:20.000
That, um, the person doing the mapping might have missed, but.

01:01:20.000 --> 01:01:25.000
It's because of the volume of data and speed, it makes connections.

01:01:25.000 --> 01:01:30.000
Right? So we can deepen the… the richness of the output.

01:01:30.000 --> 01:01:40.000
Well, in parallel to that. Um, I've been working in folks who have frameworks addressing the soft stuff, which is…

01:01:40.000 --> 01:01:45.000
The human, the emotional. Dimensions of people.

01:01:45.000 --> 01:01:53.000
Co-creating together, and also people engaged in dealing with. Crisis areas and challenges, global challenges.

01:01:53.000 --> 01:02:00.000
And so… Um, there's a… there's a possibility.

01:02:00.000 --> 01:02:07.000
To stir into genes, causal loop mapping is dealing with nouns. It's dealing with the physical world, it's dealing with.

01:02:07.000 --> 01:02:13.000
You know, all of the mechanistic Industrial Revolution-oriented ingredients of a system.

01:02:13.000 --> 01:02:21.000
Um, and… but, uh, there's a guy named Bill Smith who has a… a framework called AIC Appreciation.

01:02:21.000 --> 01:02:29.000
Influence and control. Which is a rather elaborate framework, but applicable in a very systems-oriented way.

01:02:29.000 --> 01:02:34.000
That speaks to… purpose, and power.

01:02:34.000 --> 01:02:44.000
So, as an informing inquiry into guiding decision making. Factoring for those dimensions.

01:02:44.000 --> 01:02:53.000
So the balancing act between. Appreciation, which is sort of, you know, the ideal and the goal, the source, the…

01:02:53.000 --> 01:02:58.000
Purpose end of it, and then control is the mechanics and the doing, and the machinery.

01:02:58.000 --> 01:03:09.000
And the infrastructure and the what, where, when, why. Um, so I believe that framework could be integrated into Gene's mapping to factor for those dimensions.

01:03:09.000 --> 01:03:15.000
So that's piece number two. Piece number three… is somebody who we just lost, a guy named Barry Court.

01:03:15.000 --> 01:03:22.000
And Barry was unique. He was a systems guy. And one of his things was.

01:03:22.000 --> 01:03:29.000
Emotion in education. And he developed a framework for integrating the emotional dimensions.

01:03:29.000 --> 01:03:36.000
Sort of enabling a valuing weighting of them. As variable.

01:03:36.000 --> 01:03:45.000
Framework plugin within other analytical contexts. And I think that could also be integrated into this causal loop mapping.

01:03:45.000 --> 01:03:50.000
So now we're starting to actually. Three-dimensionally, four-dimensionally.

01:03:50.000 --> 01:03:59.000
Expand the nature of the inquiry and the analysis. In looking at complex system dynamics and what's really going on.

01:03:59.000 --> 01:04:02.000
And then, you know, clearly, why? Like, what's all this about?

01:04:02.000 --> 01:04:09.000
So, Danella Meadows, right, who's known for. Finding the concept of.

01:04:09.000 --> 01:04:15.000
Leverage points. So you have a cause loop map, you know, like genes… one of Gene's greatest, grandest was the Middle East.

01:04:15.000 --> 01:04:22.000
Like, 5,000 nodes. It was insane and magnificent. But, like, what are the nodes.

01:04:22.000 --> 01:04:29.000
That hold the potential. For the most impact, in terms of where do you target.

01:04:29.000 --> 01:04:34.000
And Danella Meadows sort of surfaced that concept of leverage points.

01:04:34.000 --> 01:04:41.000
So, if we could do this richer mapping, factoring for the human and the being dimensions.

01:04:41.000 --> 01:04:45.000
And we can then identify leverage points, and we can have the output of that.

01:04:45.000 --> 01:04:53.000
Provide guidance and insight. To inform and enable better decision-making on a policy level.

01:04:53.000 --> 01:05:01.000
Or on a financial funding and resource level. Or on a multi-stakeholder level, maximizing across.

01:05:01.000 --> 01:05:06.000
All of those dimensions. You know, start to have something.

01:05:06.000 --> 01:05:09.000
Now, with all of that said, you know, enter yours truly.

01:05:09.000 --> 01:05:18.000
Um. So, to go to the metaphor, the still picture to motion pictures?

01:05:18.000 --> 01:05:27.000
So, because of the speed and robustness of AI's capability as an enabling technology, not a source or driver.

01:05:27.000 --> 01:05:32.000
Now take everything I just said and imagine that as a running.

01:05:32.000 --> 01:05:42.000
Process. With the variable inputs on the front end being real-time.

01:05:42.000 --> 01:05:52.000
So, it's an exponential leveling up. Of… and creating a mechanism for a living, real-time causal loop analysis mapping.

01:05:52.000 --> 01:06:03.000
Tracking of leverage points, tracking of changes. I think it's possible to build this.

01:06:03.000 --> 01:06:11.000
Um, and I'm at the beginning. And I welcome anybody that wants to… you know, like, sign on and help.

01:06:11.000 --> 01:06:17.000
Um, because I'm not a… I'm not Pete. Like, I wish I was you, Pete. I'm not you.

01:06:17.000 --> 01:06:18.000
Alas, none of us is Pete. I don't know how that works.

01:06:18.000 --> 01:06:21.000
Like a technology-wise, you know. I'm… I'm… yeah, I'm a diligent.

01:06:21.000 --> 01:06:23.000
Only Pete is Pete.

01:06:23.000 --> 01:06:34.000
You know, I'm a dilettante, I'm not, like… I don't… you know, I have a clear vision of the technologies involved in the pieces. I don't think it's that complicated.

01:06:34.000 --> 01:06:42.000
In terms of anything needing to be invented, it's really about just… pressing it all into place in service.

01:06:42.000 --> 01:06:48.000
But anyway, um… I really think we… you know, if possible.

01:06:48.000 --> 01:06:59.000
It would be really great to level up. The dimensionality of the inquiry and the analysis, an orientation being brought.

01:06:59.000 --> 01:07:06.000
To these contacts. So, I want to end with the last punctuation mark, which is I'm working.

01:07:06.000 --> 01:07:10.000
With a woman named Louise McCullen in Ireland, who's focused on.

01:07:10.000 --> 01:07:19.000
Survivors of domestic abuse in a woman, um. 30-year-old young lawyer, brilliant woman in, um.

01:07:19.000 --> 01:07:25.000
In Nairobi. Uh, same territory, but…

01:07:25.000 --> 01:07:31.000
Supporting women coming out the back end in entrepreneurial endeavors and community-level support.

01:07:31.000 --> 01:07:37.000
And intermediating with other aid sources and all the rest. The woman in Nairobi, Tessie.

01:07:37.000 --> 01:07:45.000
Shared a piece of a puzzle. So she has this nonprofit foundation, she's bootstrapped, she's helping women, she's engaged in.

01:07:45.000 --> 01:07:55.000
Rubber meets the road, doing what she's doing. And a problem she shared was that, based on the culture of corruption in Nairobi.

01:07:55.000 --> 01:08:04.000
Um, that the women that she's training. To be the care provider, you know, benefits.

01:08:04.000 --> 01:08:10.000
Caseworker folk. In her foundation to the women in the community.

01:08:10.000 --> 01:08:20.000
Um, have so much distrust that. In her offering to train them to serve the Foundation.

01:08:20.000 --> 01:08:25.000
They want to know what's in it for her, like, why is she offering them this for free?

01:08:25.000 --> 01:08:35.000
Like, why is she offering to train them? As, you know, like, there's nothing free, like, where are the strings?

01:08:35.000 --> 01:08:41.000
And… and I… I raise that just because. What it points to is.

01:08:41.000 --> 01:08:47.000
The weak link is always… in humans being human beings.

01:08:47.000 --> 01:08:56.000
The weak link is that. People are people, they're not machinery, they're not parts of a machine, they're not cogs.

01:08:56.000 --> 01:09:03.000
And the soft dimensions, the cultural dimensions, the fear and belief and deprivation and trauma dimensions.

01:09:03.000 --> 01:09:09.000
Make or break it? And 85-90% of everything that exists today.

01:09:09.000 --> 01:09:16.000
Doesn't even acknowledge they exist, much less recognize that they're the leverage point.

01:09:16.000 --> 01:09:22.000
I apologize for the length of that run, but I'm complete.

01:09:22.000 --> 01:09:25.000
Excellent. Thanks, Doug.

01:09:25.000 --> 01:09:30.000
Got a lot of things in the room. Appreciate that.

01:09:30.000 --> 01:09:34.000
Um, that was great, Doug. No need to order an apology.

01:09:34.000 --> 01:09:38.000
Um, and hit me up about, uh, call the loop, um, real-time…

01:09:38.000 --> 01:09:42.000
thingy. That sounds fun. Um…

01:09:42.000 --> 01:09:46.000
I… since we're on the topic of abundance and… and…

01:09:46.000 --> 01:09:50.000
And maybe, in a way, kind of the indigestion that comes

01:09:50.000 --> 01:09:56.000
seems to come from it, or lack of, um,

01:09:56.000 --> 01:09:59.000
Lack of appropriate distribution or something.

01:09:59.000 --> 01:10:07.000
Um, I wanted to make a shout out. I wish Ken were here to say this instead of me. Um, I want to make a shout out to Hospicing Modernity.

01:10:07.000 --> 01:10:14.000
Um, the book by Vanessa Andrealdi. If you haven't seen it, she approaches

01:10:14.000 --> 01:10:23.000
the thing that we're in, the thing that we've built. She calls it the longer title, the longer name she's got for it is Modernity Slash Coloniality.

01:10:23.000 --> 01:10:25.000
Um, she approaches…

01:10:25.000 --> 01:10:28.000
modeling where we are,

01:10:28.000 --> 01:10:35.000
And then what to think about it, and what to do with that… without paralysis in a way that is different from

01:10:35.000 --> 01:10:41.000
anything else I've seen. And so, if you haven't seen it, I think you owe your… owe yourself…

01:10:41.000 --> 01:10:46.000
a deep look at, you know, the approach that she's got.

01:10:46.000 --> 01:10:49.000
Um, uh, and…

01:10:49.000 --> 01:11:00.000
can… doesn't have a lot of time in his life, I think, right now, because he's starting to move, but Ken is kind of a central resource for me in finding out more about the book, and we've got some of us doing

01:11:00.000 --> 01:11:05.000
some inquiry about it, um, uh, partly through Signal and other places. Um…

01:11:05.000 --> 01:11:11.000
Uh, so that's kind of it.

01:11:11.000 --> 01:11:18.000
Thank you, Raj.

01:11:18.000 --> 01:11:21.000
We're having abundant thoughts about abundance.

01:11:21.000 --> 01:11:24.000
Any other perspectives? You want to bring some other…

01:11:24.000 --> 01:11:31.000
some other angle on the question in.

01:11:31.000 --> 01:11:34.000
I keep coming back to the notion that

01:11:34.000 --> 01:11:37.000
Consumerism creates the illusion of abundance.

01:11:37.000 --> 01:11:40.000
that has been…

01:11:40.000 --> 01:11:43.000
Entrancing for many people.

01:11:43.000 --> 01:11:45.000
Um, there are…

01:11:45.000 --> 01:11:50.000
amusing videos on YouTube of North Koreans or people who

01:11:50.000 --> 01:11:52.000
grew up in the Soviet Union.

01:11:52.000 --> 01:11:57.000
Coming to an American hypermarket, or some other thing, and just seeing

01:11:57.000 --> 01:12:02.000
how much stuff there is, how much… how much stuff is available.

01:12:02.000 --> 01:12:06.000
Um, I… I some… I haven't been in a department store for a while, but

01:12:06.000 --> 01:12:12.000
Last few times I went through, like, the women's… women's… I used to go shopping with my mom a bunch,

01:12:12.000 --> 01:12:16.000
the women's clothing areas are just endless racks, and I look around, I'm like,

01:12:16.000 --> 01:12:22.000
Hmm, wouldn't wear that, wouldn't wear that, wouldn't like to wear that, that looks ugly. Oh my god, what happened there?

01:12:22.000 --> 01:12:30.000
And just acres and acres and acres of stuff out, in the hope that somebody will pick it up and take it home.

01:12:30.000 --> 01:12:33.000
buy it with money. Stacey, please.

01:12:33.000 --> 01:12:41.000
Stacy, has your… has your cynicism heightened, or dampened a little bit with the call?

01:12:41.000 --> 01:12:48.000
Well, that's actually what my comment's about. So, I recognized that my cynicism.

01:12:48.000 --> 01:12:52.000
May be a result that, from an energetic point of view.

01:12:52.000 --> 01:12:59.000
I am actually where Trump. Begin. I am at the heart.

01:12:59.000 --> 01:13:05.000
Of where he began. Where consumerism is, where capitalism is.

01:13:05.000 --> 01:13:12.000
I'm in New York City. I know his type, I know the types of the people that surround him.

01:13:12.000 --> 01:13:17.000
Probably more than most of you in this room. I also know types like you.

01:13:17.000 --> 01:13:24.000
But I grew up around the types of people that he grew up around on all different economic levels.

01:13:24.000 --> 01:13:28.000
So that could have a piece of it. Because, as I've said many times.

01:13:28.000 --> 01:13:36.000
I can get into his mindset. The difference is, I have a different morality and a different set of ethics.

01:13:36.000 --> 01:13:41.000
Which, as we've noted many times, doesn't work as well to be successful in business.

01:13:41.000 --> 01:13:45.000
Um, so now to get back to the trust piece of it.

01:13:45.000 --> 01:13:51.000
And the leverage points. I've consistently, because I'm in the soft space.

01:13:51.000 --> 01:13:57.000
Working on building trust and building bridges. And that's where Romeo comes in.

01:13:57.000 --> 01:14:05.000
Romeo is the guy on my lap. Romeo came to me because, um, last week in a NIAC.

01:14:05.000 --> 01:14:11.000
Space, a call came out, an urgent need for temporary foster care.

01:14:11.000 --> 01:14:18.000
For this adorable little dog. And you guys know how much Marley meant to me, and people keep saying.

01:14:18.000 --> 01:14:22.000
Are you going to get another dog? And as much as I loved Marley.

01:14:22.000 --> 01:14:27.000
I didn't want the responsibility. I'm loving my life. I'm out 5 nights a week.

01:14:27.000 --> 01:14:31.000
I'm on the music scene, I'm independent, I'm like a teenager.

01:14:31.000 --> 01:14:36.000
I like it. But… I knew this dog was for me, because.

01:14:36.000 --> 01:14:41.000
Nobody's gonna take care of him better than I can. Well, here's the story of Romeo.

01:14:41.000 --> 01:14:46.000
Romeo's father. Was picked up by ICE.

01:14:46.000 --> 01:14:52.000
As he was dropping his kids off at camp. And because he was the sole provider.

01:14:52.000 --> 01:14:59.000
His wife and children. No longer have a home. So until they can find their home.

01:14:59.000 --> 01:15:04.000
That accepts dogs. I'm taking care of Romeo.

01:15:04.000 --> 01:15:11.000
Now, in my town. Me and Romeo go out and meet people, the way me and Marley used to meet people.

01:15:11.000 --> 01:15:19.000
And he's become the ambassador. So I make sure, because I can usually get a sense of where somebody is.

01:15:19.000 --> 01:15:27.000
In their heart space, let's say. And so, people that may not have had compassion or empathy.

01:15:27.000 --> 01:15:31.000
For Romeo's family. Have total compassion.

01:15:31.000 --> 01:15:39.000
For Romia. They also get a different way of looking at the situation.

01:15:39.000 --> 01:15:44.000
So, I mean, you might find it amusing if you know who Curtis Sliwa is.

01:15:44.000 --> 01:15:55.000
I call him, uh, misogynist. Four-time married vigilante liar, but that's just me. But he's now campaigning.

01:15:55.000 --> 01:16:01.000
For animal rights. Which confirms to me what I already knew, that.

01:16:01.000 --> 01:16:07.000
These people actually love animals, or many of them, at least the ones that criss-crossed do.

01:16:07.000 --> 01:16:14.000
Anyway, the point I'm trying to make… what was the point, is this is Romeo, and he's going to be with me for a while, and.

01:16:14.000 --> 01:16:18.000
Hopefully, I'll take some time to write something up on Facebook.

01:16:18.000 --> 01:16:22.000
Because that's the world I play in, so Gil, to your point.

01:16:22.000 --> 01:16:27.000
Those people know me. I've been speaking there for 10 years.

01:16:27.000 --> 01:16:33.000
And whether they like me or hate me. For the most part, the people that know me.

01:16:33.000 --> 01:16:42.000
They know that what I'm saying is me. I am true to my character. So whether you like my character, or you hate my character.

01:16:42.000 --> 01:16:51.000
You can trust my character. So, for me, it's a matter of trust.

01:16:51.000 --> 01:16:52.000
Thanks, Stacey.

01:16:52.000 --> 01:16:54.000
Thank you.

01:16:54.000 --> 01:16:57.000
Alex?

01:16:57.000 --> 01:17:05.000
I'm gonna move slightly away from everything you've said, so… Jess, if you're still on track with this path.

01:17:05.000 --> 01:17:11.000
Would you like to speak first, rather than… me, kind of, derailing the conversation somewhat.

01:17:11.000 --> 01:17:19.000
No, I wanted to kind of more converge everyone together, so I will go more at the end. Thank you.

01:17:19.000 --> 01:17:20.000
Go, Alex.

01:17:20.000 --> 01:17:25.000
Okay, let me scatter them, then, the first place. It's very interesting what you've said, and for me, for my mind, the way my mind.

01:17:25.000 --> 01:17:33.000
It works, but it was all very interesting, and… The thing that I always… think about, though. I live in a world of…

01:17:33.000 --> 01:17:39.000
My mental picture of the world, I should say, is one of… special interests doing their thing.

01:17:39.000 --> 01:17:45.000
Biggest special interest is, of course, capitalism. And it pushes and.

01:17:45.000 --> 01:17:56.000
Drives in a way that says abundance is… a lot of everything that, as a lot of you have said, is not really needed.

01:17:56.000 --> 01:18:00.000
And trying to convince people to step back, even if you try and convince.

01:18:00.000 --> 01:18:08.000
5 people to step back, there's another million over there. Doing whatever we don't want them to do, because it's…

01:18:08.000 --> 01:18:15.000
Wasting resources, etc. And I just wonder, the way you think, it's actually a question for you guys, is…

01:18:15.000 --> 01:18:19.000
We're talking about it, we're saying the right things, and believe the right things.

01:18:19.000 --> 01:18:28.000
But how are we going to change anything other than talking about the right things? You know, is it sort of… There's too few of us, there's too few across the world.

01:18:28.000 --> 01:18:35.000
And this is a systemic thing, that's all I'll just keep going on about this. The systemic things are pushing in.

01:18:35.000 --> 01:18:38.000
And, you know, at the back of my mind, I think.

01:18:38.000 --> 01:18:44.000
If you take the Amish as a subculture, sorry, if I use the wrong word, I apologize.

01:18:44.000 --> 01:18:50.000
Whatever they are. And then… But there… there's a few of those sort of communities that are…

01:18:50.000 --> 01:18:57.000
Are living on the benefit of everybody else. Accepting them, that they are as they are, but…

01:18:57.000 --> 01:19:05.000
They're being nurtured, in a way. And that's not how the real world works. And how are we going to change that without being…

01:19:05.000 --> 01:19:12.000
Dictatorial about it. Just your thoughts, I don't think we're going to change it, but…

01:19:12.000 --> 01:19:17.000
Anybody have any?

01:19:17.000 --> 01:19:27.000
Thanks, Thomas. Um, if you have suggestions or answers for Alex, I'm in the queue, please. Let's go to Jesse.

01:19:27.000 --> 01:19:30.000
Great question. Um…

01:19:30.000 --> 01:19:35.000
I think I, you know, we're asking that every day of ourselves, um, and…

01:19:35.000 --> 01:19:44.000
Um, and in order to unify and change the… indeed, the change I wish to see in this call, in this community of Jerry's,

01:19:44.000 --> 01:19:48.000
And all us, um, I have continuously tried to map

01:19:48.000 --> 01:19:50.000
the intelligence in this room?

01:19:50.000 --> 01:19:52.000
It's incredible.

01:19:52.000 --> 01:19:56.000
We have 9 people on the OGM room.

01:19:56.000 --> 01:20:06.000
Um, Stacy doesn't really, you know, she wanted to have a virtual room that's open 24-7. I created that. It's available, Stacy, let's connect.

01:20:06.000 --> 01:20:08.000
I don't want a virtual room, though, I'm sorry.

01:20:08.000 --> 01:20:16.000
Well, this is a virtual room, you and me right here in this call, and so I would love to create conversation, because I believe

01:20:16.000 --> 01:20:27.000
the answer that you're… you just raised is born out of community. It depends on which community you're in. So, if you're in a local-based community, that answer's different than if you're in an OGM community.

01:20:27.000 --> 01:20:31.000
So, depending on who you're with, that answer emerges.

01:20:31.000 --> 01:20:36.000
So, I loved the prompt at the beginning of this call.

01:20:36.000 --> 01:20:39.000
And the questions were…

01:20:39.000 --> 01:20:46.000
answered based on different life stages, different consciousness levels, different needs.

01:20:46.000 --> 01:20:52.000
And… and we're just kind of resonating with the world, as we all have different

01:20:52.000 --> 01:21:04.000
different perspectives and different needs, but if we wanted to start honing in and converging at least just this community, and see where those touchpoints are, and as, um, Doug was bringing up,

01:21:04.000 --> 01:21:10.000
Let's go. I am ready with… to… to soar here, because, um…

01:21:10.000 --> 01:21:12.000
Talking is one thing, and um…

01:21:12.000 --> 01:21:16.000
And converging and acting as another, so…

01:21:16.000 --> 01:21:25.000
I'll put in the link again. And Stacy, you and I, let's talk afterwards and figure out what would work for you, because I want to serve you, and how you are…

01:21:25.000 --> 01:21:33.000
You are amazing in community, and I want to… I want your inspiration to be, um, a seed.

01:21:33.000 --> 01:21:34.000
Yeah, yes, yes, please.

01:21:34.000 --> 01:21:38.000
Thank you. Can I just respond to that really quick? Yeah, let me explain.

01:21:38.000 --> 01:21:47.000
This community has served me. This is the virtual world. So, Jesse, what your… what you created.

01:21:47.000 --> 01:21:53.000
That's to serve others. I already felt, like… it's… it's almost like going back.

01:21:53.000 --> 01:21:57.000
What you're doing, and what I hope I inspired you to create.

01:21:57.000 --> 01:22:03.000
Is deconstructing. What I already lived into.

01:22:03.000 --> 01:22:10.000
If that makes sense. So, I don't want to go and find a new virtual world to play in.

01:22:10.000 --> 01:22:19.000
I'm actually leaving the virtual world. I spent yesterday with Romeo sitting outside the club that I usually go to.

01:22:19.000 --> 01:22:26.000
Talking to people. Somebody sat. And was telling me about his memories coming up about 9-11.

01:22:26.000 --> 01:22:32.000
Somebody who's more towards the right. And I got to sit with them and talk to them and be in the world.

01:22:32.000 --> 01:22:33.000
Yeah.

01:22:33.000 --> 01:22:42.000
I… so, my journey's a little different. I am different, so I don't want you to take it the wrong way.

01:22:42.000 --> 01:22:43.000
I…

01:22:43.000 --> 01:22:46.000
I'm unique, but I… but I love that virtual world. But this was it for me.

01:22:46.000 --> 01:22:54.000
Um, Stacy, we're actually talking about the same thing, because I'm trying to get people off the virtual world into their community, into their place space, so…

01:22:54.000 --> 01:23:07.000
I'm gonna put this link in here, based on Dunbar Research, it shows that we only need about 50 people in our lives that we are committed to, and they're committed to… I mean, they're committed to us, and there's reciprocation, and if that is there,

01:23:07.000 --> 01:23:10.000
In a place-based or digital, you decide.

01:23:10.000 --> 01:23:13.000
Um, we can thrive. It shows…

01:23:13.000 --> 01:23:18.000
Based on research, we can thrive in smaller communities. And so, um…

01:23:18.000 --> 01:23:23.000
Let's talk about that a little bit more, but it's all about getting back into our… into our

01:23:23.000 --> 01:23:30.000
community. If it's place-based, yes, for sure.

01:23:30.000 --> 01:23:31.000
Yes.

01:23:31.000 --> 01:23:34.000
What I would just say is find the people first. And then use those spaces to coordinate.

01:23:34.000 --> 01:23:35.000
Yes.

01:23:35.000 --> 01:23:39.000
But find the people that you want to spend time with.

01:23:39.000 --> 01:23:40.000
That's the key, that you want to be with.

01:23:40.000 --> 01:23:48.000
And that's… that's the link I just put in there, so thank you. And 42 is the meaning of life, so that's why 42.

01:23:48.000 --> 01:23:50.000
Cool, thank you. Thank you both.

01:23:50.000 --> 01:23:55.000
Um, before going to class, I just want to ask us to use the chat.

01:23:55.000 --> 01:24:02.000
to answer Jesse's challenge. It's like, hey, what kinds of things might we engage in together?

01:24:02.000 --> 01:24:03.000
Who's weight?

01:24:03.000 --> 01:24:10.000
Uh, that would be juicy for you, that, uh, we, the people in this group listening to this call right this second, this week, a very, very local we,

01:24:10.000 --> 01:24:13.000
And one thing I'm interested in is…

01:24:13.000 --> 01:24:20.000
doing something provocative to tease, cajole, poke, provoke the insurance companies. Like, I'm like,

01:24:20.000 --> 01:24:25.000
Little tired… little tired of them not stepping up and helping change the world, shape the world for the good.

01:24:25.000 --> 01:24:29.000
Uh, in some way, and I would love to do something provocative

01:24:29.000 --> 01:24:32.000
Toward the insurance company, so…

01:24:32.000 --> 01:24:39.000
me if you'd like to play with that together, and maybe there's something there, but I bet there's a bunch of other things that have been

01:24:39.000 --> 01:24:43.000
In our minds that if we share them into the chat, we might find two, three people

01:24:43.000 --> 01:24:48.000
want to get together and do things, and then go off and do them, which would be great. And if you do any of that,

01:24:48.000 --> 01:24:50.000
come back and tell us about it later.

01:24:50.000 --> 01:24:54.000
Klaus, thank you for your patience.

01:24:54.000 --> 01:25:07.000
Yeah, along the same lines as Jesse was just outlining, and Stacy, I like the… Um, neighborhoods of sanity concept, um…

01:25:07.000 --> 01:25:18.000
What is really happening in the regenerative movement right now. Is a concept someone else described as islands of coherence.

01:25:18.000 --> 01:25:26.000
Um, so the real… the realization that we can't spread lateral, you know, and boil the ocean, so to speak.

01:25:26.000 --> 01:25:39.000
You have to take one community at a time. And the reason why… why that is so important is because we are, on the one hand, talking at the narrative level, right? Storylines. And so we are creating stories.

01:25:39.000 --> 01:25:47.000
Of change, of transition. But then, Donil Meadows comes to mind, right? The pyramid of, uh…

01:25:47.000 --> 01:25:55.000
Of a system where, yes, you have the narrative level that really… that really condenses the story.

01:25:55.000 --> 01:26:05.000
But then that same narrative has to stay intact. As it rolls down the pyramid. Oh, I really call it an inverted pyramid, right? Because.

01:26:05.000 --> 01:26:14.000
The narrative is at the base. And of holding up the entire pyramid. So as you go through those layers, now, through the administrative part.

01:26:14.000 --> 01:26:26.000
The operational part. That story has to stay intact. And motivate and direct, you know, the action.

01:26:26.000 --> 01:26:35.000
Of people in that community, so that really takes… you know, a transition. Now, it takes a convergence.

01:26:35.000 --> 01:26:55.000
You know, of, uh, of many different layers there. And so… I'm… I'm… you know, you know, I'm working with Spiral Dynamics, so when we go into the base layers of this pyramid.

01:26:55.000 --> 01:27:06.000
That's when you are operating in PLU. Right? People who are, uh, in, in… like Mike Johnson is the epitome of blue, uh, the Speaker of the House.

01:27:06.000 --> 01:27:13.000
So that's a different language, and that language is actually… has been evolving over, you know, 2,000 years.

01:27:13.000 --> 01:27:21.000
That's New Testament language that gets you into the hearts and minds of people who are operating in that layer.

01:27:21.000 --> 01:27:28.000
So, we shouldn't hesitate. You know, to… because it's religion and all this stuff.

01:27:28.000 --> 01:27:34.000
We shouldn't hesitate to use that language. Uh, in order to reach out, because…

01:27:34.000 --> 01:27:40.000
That's the world that, you know, this, uh. Group has been embedded in.

01:27:40.000 --> 01:27:48.000
And cool up in. You know, school, Sunday school, and… You know, Bible studies and all of this stuff. That's the language they understand.

01:27:48.000 --> 01:27:57.000
So we can make… we have metaphors. That are instantly recognizable and resonate, yeah?

01:27:57.000 --> 01:28:14.000
Um, and I think there is this… Um, note this translation where there's a lot of knee-jerk reactions of, you know, I can't use this, this is childish, or this is whatever. No, this is the language of people you're trying to reach.

01:28:14.000 --> 01:28:23.000
No, and uh… Uh, and so, so, why not, why not, why not, uh, use it to its fullest?

01:28:23.000 --> 01:28:28.000
And there's a hunger right now. Now, you can see in the pop… you can see these…

01:28:28.000 --> 01:28:41.000
Often misguided attempts to bring religion into the… conversation, but in the way it's done, it's more exploitative than supportive.

01:28:41.000 --> 01:28:51.000
Yeah? Um… So there are pockets of, of, uh, like this one congressperson in Texas, who is a pastor.

01:28:51.000 --> 01:28:58.000
You know, wonderfully articulate, and he is… I'm afraid and unintimidated to.

01:28:58.000 --> 01:29:11.000
Use biblical language to address his waters. Yeah, and so that's… I think this is… this… we have to change minds, we have to change narratives.

01:29:11.000 --> 01:29:20.000
No, we have to change stories. And we are pretty much consolidated on the story we have at the top. I mean, amongst ourselves here.

01:29:20.000 --> 01:29:25.000
You know, the story is pretty clear what it should be, where we should be going, and so on.

01:29:25.000 --> 01:29:29.000
That this is not the challenge. The challenge is to translate this story.

01:29:29.000 --> 01:29:33.000
Right? So it echoes in the different layers of this pyramid.

01:29:33.000 --> 01:29:38.000
In each… in each phase of them. Sorry, didn't mean to preach.

01:29:38.000 --> 01:29:40.000
That's right. Thanks, Thus.

01:29:40.000 --> 01:29:49.000
I just noticed we're coming up on the end of our time. Klaus, you may have the last word. We have no Sir Ken Homer with us today, but I think I've found a poem that I would like to read in.

01:29:49.000 --> 01:29:53.000
as our clothes.

01:29:53.000 --> 01:29:56.000
Uh, so Gil, off to you.

01:29:56.000 --> 01:30:01.000
Sorry, I thought you were giving claps the last word. Just very briefly, Klaus, I appreciate very much what you're saying, and I want to just

01:30:01.000 --> 01:30:04.000
flag a contradiction in what I heard of what you're saying.

01:30:04.000 --> 01:30:09.000
Uh, which is about understanding people's language and speaking to them in that, but that can be manipulative, you said.

01:30:09.000 --> 01:30:16.000
I think. Um, and exploitative. So there's a challenge there of how to do that that

01:30:16.000 --> 01:30:19.000
centers the listening more than the speaking.

01:30:19.000 --> 01:30:27.000
Like, how do I engage with somebody who's in a very different language and worldview than me, so that we can understand each other different than me

01:30:27.000 --> 01:30:31.000
learning how to use their language so I can get them to do what they want.

01:30:31.000 --> 01:30:37.000
Because that sort of re-recapitulates the same problem. So, and it's a delicate dance.

01:30:37.000 --> 01:30:43.000
to do that. But I think that's what you're pointing to, and you flagged the contradiction. I just wanted to highlight that, that

01:30:43.000 --> 01:30:49.000
I heard a quote somewhere, I thought it was attributed to Gandhi, but I can't find it anywhere.

01:30:49.000 --> 01:30:53.000
Um, but somebody once told me that all persuasion is violence.

01:30:53.000 --> 01:31:00.000
And it's, you know, it's an extreme statement, it's provocative, but there's something, for me, very generative in thinking into that.

01:31:00.000 --> 01:31:07.000
Um, how do I meet minds with other people and find better common purpose together without

01:31:07.000 --> 01:31:10.000
Trying to bend them to my will.

01:31:10.000 --> 01:31:12.000
The best I've found…

01:31:12.000 --> 01:31:15.000
Sorry.

01:31:15.000 --> 01:31:16.000
Jerry, thank you.

01:31:16.000 --> 01:31:17.000
Yeah, no, absolutely listening. Two years, one loss, right?

01:31:17.000 --> 01:31:23.000
You mentioned… I think you brought this up on the call of, uh, 828?

01:31:23.000 --> 01:31:27.000
Uh, and I looked it up, and closest I got was Sally Miller Gearhart.

01:31:27.000 --> 01:31:30.000
Close enough for me, I love it. Thank you so much.

01:31:30.000 --> 01:31:37.000
Yeah, that was my best tracking. Pete can probably do better than me on this, but uh…

01:31:37.000 --> 01:31:40.000
Just saying, I'm not… I'm just a yellow belt.

01:31:40.000 --> 01:31:43.000
On the… on this.

01:31:43.000 --> 01:31:48.000
Uh, Stacy, you're gonna have a last word, which seems somehow appropriate, because you have the opening sound, too.

01:31:48.000 --> 01:31:56.000
I know you wanted… I think… I just think this is an appropriate story for this last interaction.

01:31:56.000 --> 01:32:04.000
So, in a conversation with my mother. Who voted for Trump three times. She's very old, you know, she's old, she's…

01:32:04.000 --> 01:32:11.000
You know, we're going through our last things. She was very upset, I'm trying to calm her down, I don't want to fight with her.

01:32:11.000 --> 01:32:21.000
Now, I'm Jewish, we had no religious training, I'm actually the only one that ever… I mean, my father was bar mitzvahed because his family, you know, did that.

01:32:21.000 --> 01:32:24.000
They were Democrats, they had Kennedy in their house, my mother's.

01:32:24.000 --> 01:32:33.000
Right? She was all Uncle Sam. So she's talking to me. She's always… she always… she sounds… it has to… she sounds like an evangelical.

01:32:33.000 --> 01:32:41.000
She's always talking about the Lord, the Lord, the Lord. So she was worried about something, so I said, Mom, let's pray together.

01:32:41.000 --> 01:32:47.000
So, but I prayed to her, and I was calling in Gaia.

01:32:47.000 --> 01:32:55.000
And anyway, she got very upset with me, and I forgot why I brought up this story, but it had to do with the language. Oh, and that's what it was.

01:32:55.000 --> 01:33:05.000
It was the delicate dance. Because even though I was using what she kept saying about prayer and how important prayer was.

01:33:05.000 --> 01:33:17.000
Now I was willing to… pray with her. And… you know, I said, you know, call upon grandma, and, you know, we call… and she believes in that, too. She really does.

01:33:17.000 --> 01:33:23.000
But it was just very interesting, because when I wasn't going in the direction she wanted.

01:33:23.000 --> 01:33:30.000
She got very, very angry. And that's what happens when you use somebody's own language, and we saw that with Charlie Kirk.

01:33:30.000 --> 01:33:39.000
When people used his own words. People can get really angry, so it is a delicate dance, because.

01:33:39.000 --> 01:33:45.000
When you're dealing at a certain level of. Purposely trying to not be aware.

01:33:45.000 --> 01:33:48.000
All the… all the emotions come out to push you away.

01:33:48.000 --> 01:33:54.000
So, this wasn't the most articulate way to explain it, but it's a starting point for another conversation.

01:33:54.000 --> 01:33:58.000
Thank you, Stacey. And you're reminding me a belated Shanatava.

01:33:58.000 --> 01:33:59.000
to those who celebrate.

01:33:59.000 --> 01:34:00.000
Over.

01:34:00.000 --> 01:34:02.000
Happy New Year.

01:34:02.000 --> 01:34:03.000
Thank you.

01:34:03.000 --> 01:34:04.000
Um, thanks. Uh…

01:34:04.000 --> 01:34:06.000
2. Thank you.

01:34:06.000 --> 01:34:15.000
Doug, thank you very much. Uh, I… the poem that, uh, I will now read is by Cheshwav Miwash.

01:34:15.000 --> 01:34:17.000
I think that's how to pronounce his name?

01:34:17.000 --> 01:34:19.000
It's titled Love.

01:34:19.000 --> 01:34:21.000
and it goes as follows.

01:34:21.000 --> 01:34:26.000
Love means to learn to look at yourself, the way one looks at distant things.

01:34:26.000 --> 01:34:28.000
For you are only one thing.

01:34:28.000 --> 01:34:32.000
Among many. And whoever sees that way,

01:34:32.000 --> 01:34:36.000
Heals his heart without knowing it, from various ills.

01:34:36.000 --> 01:34:39.000
A bird and a tree say hi to him.

01:34:39.000 --> 01:34:46.000
trend. Then, he wants to use himself and things so that they stand in the glow of ripeness.

01:34:46.000 --> 01:34:50.000
It doesn't matter whether he knows what he serves,

01:34:50.000 --> 01:34:59.000
Who serves best doesn't always understand.

01:34:59.000 --> 01:35:00.000
Can you read it again, Sherry?

01:35:00.000 --> 01:35:03.000
Sure.

01:35:03.000 --> 01:35:06.000
Love means to learn, to look at yourself.

01:35:06.000 --> 01:35:08.000
The way one looks at distant things.

01:35:08.000 --> 01:35:11.000
For you are only one thing among many.

01:35:11.000 --> 01:35:15.000
And whoever sees that way heals his heart, without knowing it.

01:35:15.000 --> 01:35:17.000
from various ills.

01:35:17.000 --> 01:35:20.000
a bird and a tree say to him,

01:35:20.000 --> 01:35:22.000
Friend.

01:35:22.000 --> 01:35:25.000
Then he wants to use himself and things.

01:35:25.000 --> 01:35:29.000
So that they stand in the glow of ripeness.

01:35:29.000 --> 01:35:33.000
It doesn't matter whether he knows what he serves.

01:35:33.000 --> 01:35:43.000
Who serves best doesn't always understand.

01:35:43.000 --> 01:35:44.000
Uh, it's in the chat already.

01:35:44.000 --> 01:35:45.000
Beautiful.

01:35:45.000 --> 01:35:46.000
Thank you. Can you give us a link? Thank you.

01:35:46.000 --> 01:35:49.000
Thanks, Saul. Um…

01:35:49.000 --> 01:35:50.000
Thank you.

01:35:50.000 --> 01:35:53.000
Thanks for a wonderful conversation, really appreciate this.

01:35:53.000 --> 01:35:55.000
Um, and the way…

01:35:55.000 --> 01:35:59.000
The way we all approach these kinds of conversations makes my heart sing, so…

01:35:59.000 --> 01:36:01.000
Thank you very much.

01:36:01.000 --> 01:36:03.000
Excellent.

01:36:03.000 --> 01:36:10.000
Thank you.

