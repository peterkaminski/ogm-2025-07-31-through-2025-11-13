WEBVTT

1
00:00:02.350 --> 00:00:03.770
Jerry Michalski: Boss, would you like to be host.

2
00:00:04.400 --> 00:00:05.290
Klaus Mager: Okay.

3
00:00:06.140 --> 00:00:07.230
Jerry Michalski: Sounds good.

4
00:00:08.140 --> 00:00:11.948
Jerry Michalski: Do with the call what you will, whatever whatever makes sense for you. And

5
00:00:12.690 --> 00:00:18.769
Jerry Michalski: I will look at the recording later and post it. But thank you very much. I'm gonna go keep vacating.

6
00:00:19.270 --> 00:00:20.170
Jessie Upp DayBalancer.com: Hey, Kate!

7
00:00:20.170 --> 00:00:21.020
Jessie Upp DayBalancer.com: Enjoy!

8
00:00:21.020 --> 00:00:21.250
Jessie Upp DayBalancer.com: Oh.

9
00:00:21.480 --> 00:00:21.890
Jerry Michalski: Thanks.

10
00:00:21.890 --> 00:00:22.295
Stacey Druss: Bye.

11
00:00:22.700 --> 00:00:23.780
Klaus Mager: I'm jealous.

12
00:00:24.250 --> 00:00:25.960
Gil Friend • Sustainability OG • CxO Coach: Yeah, truly.

13
00:00:26.500 --> 00:00:30.090
Klaus Mager: It's such a wonderful place. Yeah. Wonderful culture.

14
00:00:30.910 --> 00:00:33.409
Klaus Mager: Oh, so what are we doing today?

15
00:00:36.400 --> 00:00:37.990
Gil Friend • Sustainability OG • CxO Coach: We're we're milling about.

16
00:00:38.610 --> 00:00:41.485
Jessie Upp DayBalancer.com: Like my cat has

17
00:00:42.640 --> 00:00:51.610
Jessie Upp DayBalancer.com: a uti, so there's she's peeing in the bathtub, and there's blood everywhere. That's where I'm at like. That's what's going on. It's just terrible.

18
00:00:51.610 --> 00:00:52.679
Gil Friend • Sustainability OG • CxO Coach: Oh, golly!

19
00:00:53.730 --> 00:00:56.149
Klaus Mager: Row too little time to

20
00:00:56.390 --> 00:01:09.449
Klaus Mager: to get it together, and then maybe you can give us an update, Jesse, on what you're working on. I saw in the Plex a little story, but maybe you can let us know what's what's happening with you.

21
00:01:10.530 --> 00:01:13.906
Jessie Upp DayBalancer.com: Yeah, definitely, right now or later.

22
00:01:14.330 --> 00:01:15.670
Klaus Mager: Yeah. Ready. Go for it.

23
00:01:16.580 --> 00:01:17.230
Jessie Upp DayBalancer.com: Sure.

24
00:01:17.350 --> 00:01:33.850
Jessie Upp DayBalancer.com: So yeah, when you when you start a passion project that doesn't have an intention to make money, guess what happens. You don't make money, so that's where I'm at. I've loved every second of building this, and just, you know, when you give it away it becomes bigger than you

25
00:01:34.070 --> 00:01:35.660
Jessie Upp DayBalancer.com: bigger than you.

26
00:01:36.010 --> 00:01:40.629
Jessie Upp DayBalancer.com: and that's my favorite part of a project is when it becomes larger than the self and.

27
00:01:40.630 --> 00:01:41.269
Gil Friend • Sustainability OG • CxO Coach: I'm muted.

28
00:01:41.270 --> 00:01:57.970
Jessie Upp DayBalancer.com: We're at that point. We have 400 people that are brilliant. Every single one of these people are amazing. They give gifts. I just talked with Dave over at Campfire and yesterday for a couple hours. And it was amazing because we both had a realization that

29
00:01:58.160 --> 00:02:05.280
Jessie Upp DayBalancer.com: it's really not about getting your needs met. Necessarily. Obviously, that's like a given. You have to thrive.

30
00:02:05.420 --> 00:02:07.749
Jessie Upp DayBalancer.com: But it's all about.

31
00:02:08.080 --> 00:02:13.590
Jessie Upp DayBalancer.com: You have gifts. Give them our community needs them, and

32
00:02:13.800 --> 00:02:32.780
Jessie Upp DayBalancer.com: we need. We need people's contribution to community in their local zip code and to the people that are surrounding them. And a lot of times we're living in this scarcity mode, and or we just don't have the resources to give. But we do. We always have something to give. So.

33
00:02:32.780 --> 00:02:39.370
Gil Friend • Sustainability OG • CxO Coach: Jesse. Could. Jesse, could you summarize what this is, and what it does? And what's your vision for it?

34
00:02:40.310 --> 00:02:56.989
Jessie Upp DayBalancer.com: Yeah. So what it does is it helps people 1st of all define how they thrive, and in that they can. That is partly their ikigai, what they what do, what they love, do what they, what they're good at, do, what the world needs that kind of thing.

35
00:02:57.080 --> 00:03:26.289
Jessie Upp DayBalancer.com: Be that. And in that you're able to give back to your community. And so it's a matching system. So once you do, once you do that definition, you're immediately matched, you know your map, your your needs and your haves are mapped into the system. So then there's an automatic version of everyone getting matched up with each other's needs and haves. And it's a beautiful, self-sustaining ecosystem. And it's already happening. People are getting matched up.

36
00:03:28.260 --> 00:03:31.930
Jessie Upp DayBalancer.com: But yeah, it just needs a little bit of the next lift.

37
00:03:33.320 --> 00:03:34.240
Gil Friend • Sustainability OG • CxO Coach: Thank you.

38
00:03:35.340 --> 00:03:35.670
Jessie Upp DayBalancer.com: Damn!

39
00:03:37.320 --> 00:03:39.478
Klaus Mager: Yeah, there are so many

40
00:03:40.090 --> 00:03:43.544
Klaus Mager: of these initiatives you invent also,

41
00:03:44.250 --> 00:03:51.859
Klaus Mager: that are that are trying to pull community members together and and assist people, and so on. But

42
00:03:52.420 --> 00:04:15.019
Klaus Mager: my! My observation is a lot of it is fractured now it we're working on it. It is really a lack of coordination. And how in the world do you get into coordination on on things of that sort? Some communities have been able to pull together initiatives that engage everyone.

43
00:04:15.240 --> 00:04:33.079
Klaus Mager: and you have to have finance in the middle of it somehow, because even when people invest, you know and donate their time and money. If it is not coordinated in some form, it just doesn't have the effectiveness that you're looking for.

44
00:04:33.450 --> 00:04:34.049
Jessie Upp DayBalancer.com: Yeah.

45
00:04:35.270 --> 00:04:50.239
Jessie Upp DayBalancer.com: yeah, I love that. We're a talent solutions company. And we've we have a full, sophisticated talent management system on the back end. So people can, you know, post jobs for free and get matched to candidates for free. It is a talent system.

46
00:04:50.300 --> 00:05:19.770
Jessie Upp DayBalancer.com: So it's an economic resilience factor here. And it's just a matter of people, you know, sharing their jobs and building their teams. But we are pivoting to events. So those people that are already having, you know, a lot of participants come into their event or their community event. What happens? They they meet, and then they're really excited about doing things together, and they have a dinner, and they have music. And then what happens is the momentum subsides

47
00:05:19.770 --> 00:05:23.110
Jessie Upp DayBalancer.com: after the event stops. I have noticed that

48
00:05:23.260 --> 00:05:42.279
Jessie Upp DayBalancer.com: for all my life. That's what events do is they bring people together, and then there's not a mechanism to pull these people together consistently in between events, the annual events. So this is what that is now. And so we're pivoting to the event industry. So community leaders can really provide the in between mechanism.

49
00:05:42.470 --> 00:05:45.119
Klaus Mager: So do you have found ways now to monetize this.

50
00:05:45.770 --> 00:05:52.779
Klaus Mager: I'm sorry. It's a horrible work, I know, but I mean you. You have to. You have to make a living somehow, right?

51
00:05:53.930 --> 00:06:13.470
Jessie Upp DayBalancer.com: Yeah. So the the money would hopefully go into the event industry, because there is there is money in the event industry. So to ask the event producer to give this opportunity for their participants to match up with each other instantly within the event and during the after the event. So it lives on.

52
00:06:14.066 --> 00:06:16.729
Jessie Upp DayBalancer.com: I think that's where the money is gonna come from.

53
00:06:17.200 --> 00:06:18.810
Klaus Mager: Hmm, okay.

54
00:06:19.170 --> 00:06:20.320
Klaus Mager: Well, thank you.

55
00:06:20.320 --> 00:06:21.700
Jessie Upp DayBalancer.com: Yeah, thanks for asking.

56
00:06:22.450 --> 00:06:28.340
Klaus Mager: So we have, Kyle. I saw a new face behind this screen.

57
00:06:29.107 --> 00:06:32.529
Klaus Mager: Do you? Wanna do you? Wanna introduce yourself?

58
00:06:35.720 --> 00:06:36.860
Klaus Mager: Hi! There.

59
00:06:37.040 --> 00:06:38.460
Karl Hebenstreit, Jr. (Alexandria, VA): Hello, Hello!

60
00:06:39.130 --> 00:06:43.940
Karl Hebenstreit, Jr. (Alexandria, VA): So is there a topic for today? Or just general introduction?

61
00:06:43.940 --> 00:06:49.410
Klaus Mager: Which is talking. We haven't. We haven't found a topic yet.

62
00:06:49.850 --> 00:06:53.830
Karl Hebenstreit, Jr. (Alexandria, VA): Okay, so I'm a

63
00:06:55.980 --> 00:07:14.149
Karl Hebenstreit, Jr. (Alexandria, VA): been working on getting the well, following up from the sessions I had a couple of weeks ago, which was mostly people from this community that attended got a meeting this afternoon to talk with somebody about setting up a a Google

64
00:07:14.560 --> 00:07:18.270
Karl Hebenstreit, Jr. (Alexandria, VA): Workspace and things. And then

65
00:07:18.600 --> 00:07:23.260
Karl Hebenstreit, Jr. (Alexandria, VA): my thoughts are that have a have a Google group that would be for that

66
00:07:24.660 --> 00:07:30.017
Karl Hebenstreit, Jr. (Alexandria, VA): today's moonshots. But it gets into the whole, really, the whole goal. Things like

67
00:07:31.130 --> 00:07:35.059
Karl Hebenstreit, Jr. (Alexandria, VA): Jim Collins talks about big, hairy, audacious goals.

68
00:07:35.180 --> 00:07:41.449
Karl Hebenstreit, Jr. (Alexandria, VA): or whatever, too. I see there being a connection there. But I'll be working on putting some stuff together, and

69
00:07:42.320 --> 00:07:49.850
Karl Hebenstreit, Jr. (Alexandria, VA): need to wrap up the last week of the term here, get some papers done by next Sunday, so, keeping myself busy there.

70
00:07:50.540 --> 00:07:51.650
Klaus Mager: Alright.

71
00:07:55.504 --> 00:07:58.195
Klaus Mager: Just called Mike. How are you doing.

72
00:07:59.360 --> 00:08:05.750
Mike Nelson: Juggling many things, getting ready to head to Taipei, and then Manila

73
00:08:05.910 --> 00:08:07.790
Mike Nelson: at the end of next week.

74
00:08:08.020 --> 00:08:14.720
Mike Nelson: and then I'll have a 3 or 4 day stop in Seattle on the way home from Manila to see my folks.

75
00:08:15.120 --> 00:08:15.850
Mike Nelson: Yeah.

76
00:08:16.270 --> 00:08:22.920
Mike Nelson: my daughter's meeting me up there, and for the 1st time in more than a year and a half she'll get to see her. Her grandparents.

77
00:08:23.050 --> 00:08:24.629
Klaus Mager: As well as.

78
00:08:24.740 --> 00:08:28.830
Mike Nelson: Some of our of our old family friends. That'll be nice.

79
00:08:28.830 --> 00:08:29.410
Klaus Mager: Cool.

80
00:08:29.410 --> 00:08:35.910
Mike Nelson: But unfortunately, we just found out that some of the key people we wanted to meet in the Philippines are

81
00:08:36.150 --> 00:08:55.849
Mike Nelson: are tied up so it's very frustrating when you're trying to organize these kind of long distance meetings, and everybody has, you know, 5 things going on at the same time. It used to be. You set up things 5 weeks in advance, and if you try to do that now, they inevitably cancel and reschedule. And you've got

82
00:08:57.570 --> 00:09:02.367
Mike Nelson: i i i don't know if face to face meetings make any sense anymore.

83
00:09:02.950 --> 00:09:06.600
Klaus Mager: In the age of Zoom. Can we ask what you're working on.

84
00:09:06.990 --> 00:09:16.309
Mike Nelson: Well, in in Taipei I'm giving a keynote speech at the World Innovation Technology and Services Alliance.

85
00:09:16.560 --> 00:09:22.479
Mike Nelson: It's about 50 national, it trade associations. They meet every year.

86
00:09:22.780 --> 00:09:24.170
Gil Friend • Sustainability OG • CxO Coach: What are you going to tell? Like.

87
00:09:24.620 --> 00:09:25.400
Mike Nelson: Pardon me.

88
00:09:25.400 --> 00:09:27.620
Gil Friend • Sustainability OG • CxO Coach: That sounds really cool. What are you going to tell them.

89
00:09:28.730 --> 00:09:42.469
Mike Nelson: It's a talk on the need for digital leadership and political vision in the digital area. So it's a little bit what we did in the Clinton Administration back in starting in 1993,

90
00:09:43.000 --> 00:09:48.660
Mike Nelson: you know, if you don't get the President, or at least the Vice President or the Prime minister

91
00:09:49.180 --> 00:09:53.930
Mike Nelson: engaged, and at least saying a few things about where we're going.

92
00:09:54.610 --> 00:10:06.670
Mike Nelson: Everybody tries to pull in 7 directions, and you don't get anywhere, or you get 7 different directions sent. Everybody's confused. And we're seeing more and more of that.

93
00:10:06.890 --> 00:10:11.250
Mike Nelson: The most obvious example is in the area of encryption

94
00:10:11.400 --> 00:10:14.969
Mike Nelson: where the police hate the idea of encryption.

95
00:10:15.590 --> 00:10:21.860
Mike Nelson: cybersecurity, experts and privacy advocates feel it's essential to have end-to-end encryption.

96
00:10:21.980 --> 00:10:24.020
Mike Nelson: So we kind of stumble along.

97
00:10:24.280 --> 00:10:34.480
Mike Nelson: But there's many other places where you have these conflicts between agencies and interests, online copyrights, another one where

98
00:10:34.920 --> 00:10:40.740
Mike Nelson: it's not just the AI companies that want to be able to share and easily reuse content.

99
00:10:42.360 --> 00:10:46.610
Mike Nelson: Everybody, from librarians to scholars, to educators.

100
00:10:47.310 --> 00:10:53.490
Mike Nelson: Don't think it's a good idea that somebody has to pay every time they want to use a sentence of somebody else's words.

101
00:10:54.080 --> 00:11:00.430
Mike Nelson: But we just, we have no vision. We we have, or we have 7 visions. We have the pay per play

102
00:11:00.560 --> 00:11:07.730
Mike Nelson: vision of certain people in the copyright industry who would redesign the Internet, take care, take

103
00:11:08.710 --> 00:11:18.170
Mike Nelson: steps to make sure there's no anonymity, so everybody can be tracked and everybody can be charged when they download a Britney spears.

104
00:11:20.580 --> 00:11:21.035
Klaus Mager: Wow!

105
00:11:21.490 --> 00:11:27.149
Mike Nelson: But it's also going to be interesting because Taiwan is in a bit of a political.

106
00:11:28.570 --> 00:11:30.799
Mike Nelson: I'm trying to think of the right word.

107
00:11:30.960 --> 00:11:37.620
Mike Nelson: Things are a little unstable right now. There are a lot of different tension.

108
00:11:37.620 --> 00:11:40.120
Gil Friend • Sustainability OG • CxO Coach: Why why should they be different than anybody else.

109
00:11:40.120 --> 00:11:46.279
Mike Nelson: Well, they're different, because, unlike the Us. With its 3 branches of government, they have 5.

110
00:11:46.530 --> 00:11:51.110
Mike Nelson: Oh, my! And and they're not all in the hands of the same party.

111
00:11:52.010 --> 00:11:53.249
Mike Nelson: So it's a

112
00:11:53.810 --> 00:12:03.510
Mike Nelson: it's an interesting time. Have any of you been to Manila? I've never been to Manila, so I'm curious. If anybody has any reflections on.

113
00:12:03.510 --> 00:12:06.280
Mike Nelson: I'm not how to understand the place.

114
00:12:06.600 --> 00:12:13.414
Klaus Mager: Oh, it's a very modern city. There's nothing, nothing unique about it.

115
00:12:14.210 --> 00:12:19.309
Klaus Mager: I mean, if you have been in Singapore, you have, you know it's it's it's the same.

116
00:12:19.990 --> 00:12:30.059
Klaus Mager: But I mean your your statement about lack of vision. That's really true for every corner of the of the place, isn't it? I mean.

117
00:12:30.260 --> 00:12:42.979
Klaus Mager: there's there's just there's just so much conflict around any topic where. So how do you? How do you go in any direction? You're just thrilling.

118
00:12:43.150 --> 00:12:49.739
Mike Nelson: Yeah, my focus is on the digital vision of the future and how to get people less scared and more excited.

119
00:12:49.900 --> 00:12:53.939
Mike Nelson: We did that incredibly well in the nineties, and of course we had

120
00:12:55.330 --> 00:13:02.199
Mike Nelson: companies spending hundreds of millions, if not billions of dollars, over the course of 10 years to

121
00:13:02.340 --> 00:13:04.369
Mike Nelson: paint the happy image of

122
00:13:05.860 --> 00:13:17.259
Mike Nelson: apple books or macbooks that let you talk to grandma and digital libraries that schoolchildren in the most remote corners of the country could could use.

123
00:13:17.430 --> 00:13:19.210
Mike Nelson: and we achieved a lot of that.

124
00:13:19.530 --> 00:13:24.069
Mike Nelson: We also ended up with a lot of people abusing the system.

125
00:13:24.710 --> 00:13:27.269
Mike Nelson: There is a vision that I've just

126
00:13:28.000 --> 00:13:36.329
Mike Nelson: gotten very excited about one of my colleagues at the Carnegie Endowment has come out with a book called The Information Animal.

127
00:13:37.210 --> 00:13:42.949
Mike Nelson: and it's all about taking an ecology approach to

128
00:13:43.280 --> 00:13:46.079
Mike Nelson: the information environment that we work in.

129
00:13:46.190 --> 00:14:06.509
Mike Nelson: so trying to understand all the different things that influence the information that we digest and all the things that affect how we interpret that information. Alicia Wanlis is brilliant, WANL. ESS. And this book is not getting nearly as much attention as it should.

130
00:14:06.790 --> 00:14:13.265
Mike Nelson: I will put a link to the webcast that she just did for

131
00:14:15.490 --> 00:14:24.019
Mike Nelson: There's a let me let me just see if I can pull it up quickly. There's a podcast

132
00:14:24.510 --> 00:14:31.270
Mike Nelson: called spies and lies. I think it is, but very well done.

133
00:14:33.490 --> 00:14:38.570
Mike Nelson: And yeah, no secrets, secrets and spies.

134
00:14:39.170 --> 00:14:39.820
Klaus Mager: Hmm.

135
00:14:39.980 --> 00:14:40.495
Mike Nelson: And

136
00:14:41.740 --> 00:14:42.569
Doug Breitbart: I can't.

137
00:14:42.570 --> 00:14:49.334
Mike Nelson: Rather than read the book you can. You can listen to this. It's it's it's 80 80 min. And

138
00:14:49.820 --> 00:14:55.719
Mike Nelson: you, you can watch the 1st 5 min of highlights, but I encourage you to to dig a little deeper.

139
00:15:04.280 --> 00:15:05.120
Klaus Mager: Thanks.

140
00:15:05.120 --> 00:15:08.110
Mike Nelson: Did someone have a question? I heard the start of a question.

141
00:15:08.110 --> 00:15:15.669
Doug Breitbart: Yeah, Mike, you start. You said all the things that influence the information we you were summarizing her.

142
00:15:15.670 --> 00:15:22.129
Mike Nelson: Yeah, the information that we can have access to and how we react to that information.

143
00:15:23.538 --> 00:15:27.209
Mike Nelson: A lot of that second part is cultural.

144
00:15:27.350 --> 00:15:35.400
Mike Nelson: whether you trust the sources that you rely on, or unfortunately, we've

145
00:15:35.650 --> 00:15:42.479
Mike Nelson: given people in many, many countries very little reason to trust any about anything about anybody

146
00:15:42.670 --> 00:15:49.360
Mike Nelson: from anybody. So we have all the conspiracy theories, and she spends a lot of time on conspiracy theories.

147
00:15:49.520 --> 00:15:52.070
Mike Nelson: She started life, or she started her

148
00:15:53.120 --> 00:15:59.080
Mike Nelson: a career, getting a degree in Russian and back, then

149
00:15:59.630 --> 00:16:09.230
Mike Nelson: back. Then, you know, everything was peace and harmony, and the Cold War was over, and they were actually closing down Russian programs because nobody was taking

150
00:16:09.460 --> 00:16:17.160
Mike Nelson: Russian language. Certainly the advanced Russian language courses. But she stuck with it. And, thank God, she did.

151
00:16:17.290 --> 00:16:29.549
Mike Nelson: since they're doing such a great job of sharing of, you know, all sorts of crap and not just in English. Obviously they use Russian to reach a lot of audiences

152
00:16:30.960 --> 00:16:38.270
Mike Nelson: from the Russian speakers in Estonia and Lithuania to Russian speakers in Central Asia.

153
00:16:38.620 --> 00:16:44.019
Mike Nelson: and of course Putin has completely brainwashed his own people. He's had 35 years to do that.

154
00:16:46.450 --> 00:16:55.669
Mike Nelson: although they must be getting a little bit upset, I mean, when every family knows somebody who was sent off to Ukraine and come back dead or wounded.

155
00:16:56.500 --> 00:16:57.110
Klaus Mager: Hmm.

156
00:16:57.530 --> 00:17:04.149
Doug Breitbart: You know. I I just had a conversation, you know, conversation with some colleagues about

157
00:17:05.311 --> 00:17:07.719
Doug Breitbart: our our challenge with AI

158
00:17:09.710 --> 00:17:13.689
Doug Breitbart: It's sort of the cotton candy, of cognition.

159
00:17:13.890 --> 00:17:14.430
Mike Nelson: Hmm.

160
00:17:14.970 --> 00:17:21.989
Doug Breitbart: Where it looks like it makes sense. It seems to convey meaning

161
00:17:22.798 --> 00:17:25.590
Doug Breitbart: but it sort of evaporates

162
00:17:25.940 --> 00:17:30.120
Doug Breitbart: and and lacks mortality and depth and

163
00:17:30.570 --> 00:17:35.050
Doug Breitbart: actual nuance and understanding, because the underlying machinery and mechanism

164
00:17:35.520 --> 00:17:47.839
Doug Breitbart: is basically a glorified advanced text recognition word processor on steroids, not something that actually has understanding or meaning involved in that.

165
00:17:48.270 --> 00:17:56.269
Doug Breitbart: And this, it's popping up. The reason it it's sort of

166
00:17:56.660 --> 00:18:06.169
Doug Breitbart: is a dimension of this same domain that your colleague is in right, because there's the on a on a course level.

167
00:18:06.410 --> 00:18:16.530
Doug Breitbart: There's the interface of people with bad information and propaganda, you know, propaganda and and and and and

168
00:18:17.560 --> 00:18:23.680
Doug Breitbart: and stuff designed to manipulate and influence and and deceive

169
00:18:26.000 --> 00:18:30.120
Doug Breitbart: but on a more subtle and fine-tuned level the same

170
00:18:30.350 --> 00:18:32.999
Doug Breitbart: operand is at work in AI.

171
00:18:33.550 --> 00:18:35.179
Mike Nelson: Hmm, okay, do you have you

172
00:18:35.750 --> 00:18:41.680
Mike Nelson: trademark? That phrase? Yet is make sure, I got that right the cotton candy of information, or the cotton.

173
00:18:41.680 --> 00:18:46.080
Doug Breitbart: No, the the cotton candy of cognition, immation.

174
00:18:46.080 --> 00:18:53.770
Mike Nelson: Of writing meets cognition. Yeah, quite brilliant. Actually, yeah,

175
00:18:55.030 --> 00:19:05.500
Doug Breitbart: But you know where our our offerings are in the human, touchy-feely energetic spaces and dynamics, by in between people

176
00:19:05.790 --> 00:19:06.940
Doug Breitbart: and

177
00:19:08.220 --> 00:19:18.680
Doug Breitbart: where challenges and problems can be mapped back to that domain, and how we can help, you know, help

178
00:19:18.950 --> 00:19:22.300
Doug Breitbart: people co-creating together, and organizations.

179
00:19:23.990 --> 00:19:27.580
Doug Breitbart: Clear the blocks and and restore flow and

180
00:19:27.710 --> 00:19:34.190
Doug Breitbart: and and and connection on a living basis between people and

181
00:19:36.410 --> 00:19:40.609
Doug Breitbart: And at this point, every time we

182
00:19:40.750 --> 00:19:47.289
Doug Breitbart: we can viscerally, and I think this is true on a pretty wide level

183
00:19:47.750 --> 00:19:52.370
Doug Breitbart: that we can viscerally tell within a sentence whether

184
00:19:52.540 --> 00:19:54.890
Doug Breitbart: AI has been used to generate it.

185
00:19:56.430 --> 00:20:01.479
Doug Breitbart: And and if it tips over 1520%

186
00:20:01.640 --> 00:20:12.210
Doug Breitbart: of just like cleaning grammar, and or, you know, doing advanced word processing function, if it tips over that into actual purporting to be content.

187
00:20:12.470 --> 00:20:16.100
Doug Breitbart: we immediately reject it, and stop reading.

188
00:20:21.740 --> 00:20:38.130
Mike Nelson: Tech dirt blogs, I mean, he just he had a wonderful tweet just recently, where he said somebody was responding to what Grok said about itself, you know. He had asked. Somebody had asked, Well, what what do you? What do you feel about this?

189
00:20:38.240 --> 00:20:42.379
Mike Nelson: And it came back with some structured, you know, content.

190
00:20:42.600 --> 00:20:47.200
Mike Nelson: That had no meaning, and and Mike was just like, let me let me do it again here, right?

191
00:20:47.720 --> 00:21:01.399
Mike Nelson: Maybe working. I think I need to remind you that an AI program has no self awareness. It has no knowledge of how it was built, or you know what what it does. It does not test itself.

192
00:21:01.400 --> 00:21:02.860
Doug Breitbart: There's no sentence.

193
00:21:02.860 --> 00:21:03.890
Mike Nelson: Is simply.

194
00:21:04.183 --> 00:21:04.770
Doug Breitbart: Hey, guys.

195
00:21:04.770 --> 00:21:14.229
Mike Nelson: Whatever paragraph looks good because it answers the question. And so, if you ask it, how do you feel about X?

196
00:21:14.580 --> 00:21:19.000
Mike Nelson: It goes out and finds somebody else's answer to that question.

197
00:21:19.000 --> 00:21:19.650
Klaus Mager: Hmm.

198
00:21:20.210 --> 00:21:21.769
Mike Nelson: Stacey over to you.

199
00:21:21.770 --> 00:21:23.049
Klaus Mager: Yeah, Stacy.

200
00:21:23.050 --> 00:21:33.850
Stacey Druss: Yeah, I just wanted to say for those of us who think that we need a certain degree of deconstructivist thinking, if that's a correct word.

201
00:21:34.390 --> 00:21:47.190
Stacey Druss: I just want to point out that AI can be helpful in its cotton candy like thinking, and what I mean by that is, I often use AI to help break down

202
00:21:48.230 --> 00:22:07.609
Stacey Druss: other people's conversations that don't make sense to me. So, for example, there was a really interesting thread in Ogm that had to do with it was Jack's thread, and I did something similar to what Kevin did, which was to feed in an entire call

203
00:22:07.920 --> 00:22:11.120
Stacey Druss: and to listen to it, back on a podcast

204
00:22:11.280 --> 00:22:15.719
Stacey Druss: and the fact that what it spit out to me

205
00:22:16.240 --> 00:22:21.789
Stacey Druss: and I'll use the term cotton candy, because maybe that's what it was.

206
00:22:21.900 --> 00:22:29.060
Stacey Druss: but that openness to me made perfect sense, and allowed for the space

207
00:22:29.350 --> 00:22:35.230
Stacey Druss: to put in my own ideas of where I think things could be shifted.

208
00:22:35.840 --> 00:22:42.730
Stacey Druss: which is a good thing, because, to my thinking, that may be removing some of the bias

209
00:22:42.960 --> 00:22:45.520
Stacey Druss: that's so inherent in our society.

210
00:22:45.810 --> 00:22:54.030
Stacey Druss: So I just wanted to point out that while I don't like the idea of AI creating.

211
00:22:54.130 --> 00:22:59.960
Stacey Druss: I do like the idea of AI evaluating over.

212
00:23:03.750 --> 00:23:05.459
Klaus Mager: Thanks. Still, yeah.

213
00:23:07.490 --> 00:23:08.375
Gil Friend • Sustainability OG • CxO Coach: Yeah.

214
00:23:10.250 --> 00:23:12.710
Stacey Druss: Helping to evaluate, helping.

215
00:23:12.710 --> 00:23:13.936
Gil Friend • Sustainability OG • CxO Coach: Hi, everybody!

216
00:23:14.680 --> 00:23:17.050
Gil Friend • Sustainability OG • CxO Coach: I love the phrase cotton candy

217
00:23:18.560 --> 00:23:21.069
Gil Friend • Sustainability OG • CxO Coach: hang on a second. Why can't I see anybody?

218
00:23:21.580 --> 00:23:26.870
Gil Friend • Sustainability OG • CxO Coach: I'm sorry I'm on pad, so I'm a little discombobulated here.

219
00:23:27.210 --> 00:23:29.726
Gil Friend • Sustainability OG • CxO Coach: Speaker view. Okay? Well, anyway.

220
00:23:30.630 --> 00:23:40.039
Gil Friend • Sustainability OG • CxO Coach: I love the phrase cotton candy of cognition, and you've heard me talk before about my strong opinions about the lack of cognitive

221
00:23:40.540 --> 00:23:44.359
Gil Friend • Sustainability OG • CxO Coach: lack of consciousness and caring in these creatures.

222
00:23:45.670 --> 00:23:49.279
Gil Friend • Sustainability OG • CxO Coach: Excuse me, but I'm finding them enormously useful.

223
00:23:49.710 --> 00:23:52.069
Gil Friend • Sustainability OG • CxO Coach: And, Doug, you said

224
00:23:52.670 --> 00:23:57.839
Gil Friend • Sustainability OG • CxO Coach: you said, if it crossed over 15 to 20% we discounted. Who is the we that you're referring to is that.

225
00:23:57.840 --> 00:24:04.569
Doug Breitbart: No, I I am my colleagues. We're all we've all developed sort of AI spidey sense.

226
00:24:04.570 --> 00:24:10.090
Gil Friend • Sustainability OG • CxO Coach: Which is good. So I'm I'm going to send you some stuff. I'm going to send you some test samples

227
00:24:10.794 --> 00:24:13.119
Gil Friend • Sustainability OG • CxO Coach: cause the stuff that I'm

228
00:24:14.780 --> 00:24:20.342
Gil Friend • Sustainability OG • CxO Coach: the stuff that I'm seeing, and I guess the stuff that I'm generating is is

229
00:24:22.700 --> 00:24:24.510
Gil Friend • Sustainability OG • CxO Coach: feels really useful to me.

230
00:24:26.271 --> 00:24:33.180
Gil Friend • Sustainability OG • CxO Coach: Passes the crap and simplicity test. I mean, I know that it's working a stochastic parrot.

231
00:24:33.320 --> 00:24:42.359
Gil Friend • Sustainability OG • CxO Coach: but with a high degree of skill, you know, to Stacy's point about breaking down conversations. I just did something yesterday where I put

232
00:24:45.910 --> 00:24:53.160
Gil Friend • Sustainability OG • CxO Coach: 5 times 50, 20. I put like a hundred hours, of coursework.

233
00:24:53.660 --> 00:25:00.660
Gil Friend • Sustainability OG • CxO Coach: Actually not the chore, not the audio. I put the decks for a hundred hours, of coursework into Google

234
00:25:00.920 --> 00:25:02.359
Gil Friend • Sustainability OG • CxO Coach: notebook Llm.

235
00:25:02.940 --> 00:25:17.000
Gil Friend • Sustainability OG • CxO Coach: And asked for the podcast thing that it spits out, which are, you know, which are typically 10 min long and typically, fairly clever and always the same voices and the same tone in and out. But anyway, this thing did a 50 min podcast

236
00:25:17.720 --> 00:25:20.289
Gil Friend • Sustainability OG • CxO Coach: that I thought was remarkable

237
00:25:20.860 --> 00:25:34.009
Gil Friend • Sustainability OG • CxO Coach: in its nuance structure. The 1st thing I did with with notebook Lm, when it 1st came out was I dropped in the declaration of leadership for sustainable business, which is a poster that I did

238
00:25:34.190 --> 00:25:36.809
Gil Friend • Sustainability OG • CxO Coach: 20 years ago. Trying to.

239
00:25:37.140 --> 00:25:41.090
Gil Friend • Sustainability OG • CxO Coach: It was my distillation of the essence of that game and

240
00:25:41.830 --> 00:25:45.259
Gil Friend • Sustainability OG • CxO Coach: it produced a podcast that was number one. Interesting

241
00:25:46.430 --> 00:25:54.279
Gil Friend • Sustainability OG • CxO Coach: number 2, pretty pretty true to the content. So that's the author's my judgment of that.

242
00:25:54.580 --> 00:26:00.500
Gil Friend • Sustainability OG • CxO Coach: and startling in inferences that it delivered that were not on the page.

243
00:26:02.920 --> 00:26:09.809
Gil Friend • Sustainability OG • CxO Coach: which, if I think about it, was also a stochastic parrot game, because it went into its vast resource of everything else, and found associated.

244
00:26:10.260 --> 00:26:12.830
Gil Friend • Sustainability OG • CxO Coach: But what it produced was actually useful.

245
00:26:13.640 --> 00:26:20.200
Gil Friend • Sustainability OG • CxO Coach: My judgment as author, as you know, could I give this to somebody and be happy with what it provoked for them. Yes, I would have

246
00:26:21.025 --> 00:26:27.409
Gil Friend • Sustainability OG • CxO Coach: and it it reminds me, Doug, of the early days of desktop publishing.

247
00:26:28.620 --> 00:26:33.439
Gil Friend • Sustainability OG • CxO Coach: you know, when all of a sudden we had, you know, everybody had this graphic capability in their hands.

248
00:26:33.770 --> 00:26:39.379
Gil Friend • Sustainability OG • CxO Coach: and no surprise. Most of what most people produced was crap.

249
00:26:40.390 --> 00:26:45.319
Gil Friend • Sustainability OG • CxO Coach: you know, like I can. Now I can make a flyer that has 15 fonts on it like yay.

250
00:26:46.360 --> 00:26:47.630
Gil Friend • Sustainability OG • CxO Coach: but I really shouldn't.

251
00:26:48.200 --> 00:26:51.030
Gil Friend • Sustainability OG • CxO Coach: And there was thought, because, you know.

252
00:26:51.030 --> 00:27:00.250
Gil Friend • Sustainability OG • CxO Coach: because that just doesn't work. And it takes actually some nuance and judgment and skill. And we thought that it would put graphic designers out of business, but in fact, it hasn't.

253
00:27:00.870 --> 00:27:15.710
Gil Friend • Sustainability OG • CxO Coach: and my favorite graphic designers are completely teched out and use all the whiz bang tools. They get their hands on to enhance their capability and design judgment, and so forth. So you have this. You have this kind of, I think there's 2 worlds happening. One of which

254
00:27:16.680 --> 00:27:22.050
Gil Friend • Sustainability OG • CxO Coach: is, you know, is, is people unskillfully using power tools.

255
00:27:23.570 --> 00:27:28.979
Gil Friend • Sustainability OG • CxO Coach: You know you don't. You don't. You don't put the table saw in the hands of your four-year-old.

256
00:27:30.250 --> 00:27:36.129
Gil Friend • Sustainability OG • CxO Coach: You know you don't hand the keys to your Aston Martin to your to your 15 year old.

257
00:27:36.520 --> 00:27:52.360
Gil Friend • Sustainability OG • CxO Coach: and there is skillful use of tools that becomes possible. I don't know if I shared the gene roddenberry story with you guys before, but so stop me if you've heard it. But apparently somebody came up to Roddenberry at a cocktail party and said, Mr. Roddenberry, you know

258
00:27:53.360 --> 00:27:57.189
Gil Friend • Sustainability OG • CxO Coach: I really enjoy Star Trek, but 98% of it is crap

259
00:27:57.990 --> 00:28:02.140
Gil Friend • Sustainability OG • CxO Coach: and Roddenberry, without missing a beat, said, Yeah, but 98% of everything is crap.

260
00:28:04.780 --> 00:28:07.219
Gil Friend • Sustainability OG • CxO Coach: So that's that's my story. On that.

261
00:28:07.660 --> 00:28:15.340
Doug Breitbart: Klaus, if I can just interject, I'm not in in sharing what I shared. It's not a condemnation of AI

262
00:28:16.260 --> 00:28:17.440
Doug Breitbart: as a tool.

263
00:28:17.740 --> 00:28:18.310
Gil Friend • Sustainability OG • CxO Coach: Yeah.

264
00:28:19.110 --> 00:28:22.820
Doug Breitbart: It's it's a condemnation of AI as a source.

265
00:28:23.280 --> 00:28:24.100
Gil Friend • Sustainability OG • CxO Coach: As a what.

266
00:28:24.100 --> 00:28:25.110
Doug Breitbart: As source.

267
00:28:25.110 --> 00:28:25.800
Gil Friend • Sustainability OG • CxO Coach: Yeah.

268
00:28:25.910 --> 00:28:27.939
Gil Friend • Sustainability OG • CxO Coach: But but I say to folks, dodge a second.

269
00:28:27.940 --> 00:28:28.590
Gil Friend • Sustainability OG • CxO Coach: Good.

270
00:28:28.590 --> 00:28:32.970
Gil Friend • Sustainability OG • CxO Coach: I'm with you. I say, this is, you know, this is this is a tool. It's not an oracle.

271
00:28:32.970 --> 00:28:33.670
Doug Breitbart: Right.

272
00:28:33.670 --> 00:28:42.249
Gil Friend • Sustainability OG • CxO Coach: It's not a source of truth. I have people, you know, we all see it. People say. Well, the AI said, as if that really matters, you know. It's you know.

273
00:28:42.620 --> 00:28:44.740
Gil Friend • Sustainability OG • CxO Coach: everybody's got an opinion, including an AI.

274
00:28:46.640 --> 00:28:51.950
Klaus Mager: Yeah, I I think I was just in that same in that same

275
00:28:53.304 --> 00:29:00.415
Klaus Mager: mode here. I was doing a presentation yesterday to this copy. It's a European based

276
00:29:01.010 --> 00:29:05.868
Klaus Mager: organization that does project work for the World Bank and and

277
00:29:07.019 --> 00:29:28.979
Klaus Mager: governments, you know, for regenerative investing. And there are multiple groups there. This one particular group has 3,000 members, mostly volunteers focused on the food system. And so they are working in Africa and in in Asia and Europe. And I had

278
00:29:29.410 --> 00:29:41.840
Klaus Mager: a meeting with one of their founders and ask them, give me into to represent to present food with thought. You know the the AI system that I've developed.

279
00:29:41.960 --> 00:29:52.439
Klaus Mager: and I asked them, give me a challenge, you know. Give me, you know, a problem you're working on and let me respond. Let let me respond through my AI system.

280
00:29:52.600 --> 00:30:14.990
Klaus Mager: and apparently I came through with flying colors on that it was a series where you had an iceberg model that transitioned into a phase, 2 into a presencing explanation. I did an llm podcast out of it.

281
00:30:15.020 --> 00:30:23.039
Klaus Mager: You know, one report generated this 30 min podcast that was, you know, very detailed and really quiet.

282
00:30:23.600 --> 00:30:40.450
Klaus Mager: quite impressive there in the way they framed this. So yesterday, we had a meeting with their team. They put the whole team together, and we thought I thought we my daughter and I. You know she's doing marketing and branding.

283
00:30:40.580 --> 00:30:47.559
Klaus Mager: So I thought we were just talking about how can we, you know, develop a pilot and contract this thing and so on.

284
00:30:47.990 --> 00:30:56.219
Klaus Mager: But we ran into this trust issue. You know. I mean they they. I run into this puzzle of the How are you programming this thing?

285
00:30:56.280 --> 00:31:19.230
Klaus Mager: So I had, I explained, the idea of curating your AI to be a vertical embedded in a database that is trustworthy, right that where you have vetted personally the information that goes into this thing they couldn't get beyond this, you know. How do you?

286
00:31:19.230 --> 00:31:37.189
Klaus Mager: The I mean, the obvious thing that you want to do is engage with this? AI ask it all kinds of questions. You know. How are you programmed? How do you think about this? And and just or ask it? The question that you know the answer to, you know, and then see what comes out of it.

287
00:31:37.623 --> 00:31:43.276
Klaus Mager: I can't disclose how I programmed it. I mean, that's my black box right?

288
00:31:43.790 --> 00:31:50.140
Klaus Mager: but it was yeah. So now I have to figure out how to follow up on this thing. But if I really crashed

289
00:31:50.370 --> 00:31:52.140
Klaus Mager: on the trust issue.

290
00:31:52.540 --> 00:32:20.370
Klaus Mager: you know. Why would we trust you to curate an AI that we should work with and and base our, you know our decision making on. That's a huge that's a huge challenge. But I truly think that the idea of of having a curated AI, not just the the base. But no matter what whether you work with Gemini or Openai, or whatever

291
00:32:21.340 --> 00:32:28.099
Klaus Mager: you need to frame this thing, you know, you need to put it into a box and and feed it.

292
00:32:28.210 --> 00:32:43.400
Klaus Mager: You know the the information you really wanted to work with when they asked me, What why does your AI know more about what is regenerative agriculture, and why should we trust it? I said, well, I mean it has consensus opinion.

293
00:32:43.510 --> 00:33:05.020
Klaus Mager: and then go. Well, what is consensus opinion. It should be hierarchical. Right? There should be a hierarchy in. I said, Yeah, maybe. But if you take the Hotel Institute and the Soil Health Institute and the extensions. And and you put all that together. There actually is agreement across the board on what constitutes soil health? Right?

294
00:33:05.270 --> 00:33:08.593
Klaus Mager: It it was. I mean, it's a it's a stock, you know.

295
00:33:08.870 --> 00:33:09.960
Doug Breitbart: So, so.

296
00:33:09.960 --> 00:33:21.830
Mike Nelson: Elon Musk showed what can be done to manipulate an AI and make spit out things about white genocide in South Africa, so knows that example. So the.

297
00:33:21.830 --> 00:33:23.990
Doug Breitbart: So so, Klaus, what if?

298
00:33:25.110 --> 00:33:29.449
Doug Breitbart: What if you you don't mention AI at all?

299
00:33:31.990 --> 00:33:33.870
Klaus Mager: Yeah, I don't know.

300
00:33:33.870 --> 00:33:39.489
Doug Breitbart: Provide you provide a consultancy. You provide an expertise service.

301
00:33:39.490 --> 00:33:40.300
Klaus Mager: Yeah.

302
00:33:40.300 --> 00:33:42.419
Doug Breitbart: But it's actually you.

303
00:33:43.520 --> 00:33:48.650
Klaus Mager: I wasn't able to get. That was my mistake. I should have said, Look, I'm I'm 40 years.

304
00:33:48.650 --> 00:33:49.050
Doug Breitbart: This.

305
00:33:49.050 --> 00:33:49.820
Klaus Mager: Yeah, that's fine.

306
00:33:49.820 --> 00:33:55.049
Doug Breitbart: It's all about who's driving. It's not about the vehicle.

307
00:33:55.050 --> 00:33:58.790
Gil Friend • Sustainability OG • CxO Coach: You can, Klaus, you can. Still, you can still, Klaus, you can still do that.

308
00:33:59.210 --> 00:34:03.019
Doug Breitbart: Yes, absolutely like you can pull it back and like just.

309
00:34:03.360 --> 00:34:07.100
Gil Friend • Sustainability OG • CxO Coach: And how many, how many people know what you've done already. Just pull it back, Rebrand. It.

310
00:34:07.220 --> 00:34:08.870
Klaus Mager: Yeah, yeah.

311
00:34:08.870 --> 00:34:11.829
Gil Friend • Sustainability OG • CxO Coach: And you and your army of assistants.

312
00:34:11.830 --> 00:34:17.400
Doug Breitbart: And and you've got this wonderful ability to use it internally

313
00:34:18.199 --> 00:34:29.560
Doug Breitbart: for very low horsepower. High quality, automated output of response to client questions, needs whatever, but they don't need to drive.

314
00:34:30.340 --> 00:34:32.279
Klaus Mager: Yeah, they just want the output.

315
00:34:33.340 --> 00:34:35.559
Doug Breitbart: It definitely was a learning experience.

316
00:34:38.080 --> 00:34:45.110
Doug Breitbart: And yeah, yeah, I understand in the, in the, in the Wall Street world, it's all AI, everything.

317
00:34:45.760 --> 00:34:52.740
Doug Breitbart: But you know, from a from a business entrepreneurial place

318
00:34:53.449 --> 00:34:59.139
Doug Breitbart: it's about, you know, meeting needs and delivering quality goods.

319
00:34:59.350 --> 00:34:59.730
Klaus Mager: Yeah.

320
00:34:59.730 --> 00:35:00.350
Mike Nelson: Even Dom.

321
00:35:00.350 --> 00:35:02.089
Doug Breitbart: Yeah. At the end of the day.

322
00:35:02.820 --> 00:35:07.049
Mike Nelson: Even Donald Trump has said that artificial intelligence is a terrible.

323
00:35:07.610 --> 00:35:14.246
Mike Nelson: terrible catchphrase, so I suggest that you call it cloned Klaus.

324
00:35:16.170 --> 00:35:17.670
Klaus Mager: Oh! And eat the meaning.

325
00:35:18.100 --> 00:35:19.680
Mike Nelson: I think Jesse's been waiting to say something.

326
00:35:19.680 --> 00:35:23.390
Gil Friend • Sustainability OG • CxO Coach: I've been thinking I've been thinking of this thing as an exoskeleton.

327
00:35:24.560 --> 00:35:27.323
Gil Friend • Sustainability OG • CxO Coach: That's how I use. That's how I use it. And

328
00:35:28.094 --> 00:35:33.919
Gil Friend • Sustainability OG • CxO Coach: and I. Somebody saw somebody post a piece yesterday with the bottom. It said, FM. AI

329
00:35:34.510 --> 00:35:39.330
Gil Friend • Sustainability OG • CxO Coach: formed mindfully with AI as their disclosure of co-authorship.

330
00:35:39.520 --> 00:35:44.219
Gil Friend • Sustainability OG • CxO Coach: But, Klaus, you know, Klaus, you're not. You're not peddling an AI. You're competing with Mckinsey.

331
00:35:44.900 --> 00:35:53.100
Gil Friend • Sustainability OG • CxO Coach: and you've got an army of postdocs and research assistants and versions of you and accumulated experience. And it is available through you.

332
00:35:53.780 --> 00:35:55.310
Gil Friend • Sustainability OG • CxO Coach: That sounds like an offer.

333
00:35:56.090 --> 00:35:58.970
Gil Friend • Sustainability OG • CxO Coach: Thank you. Yeah, I know that's good feedback. Yeah, yeah.

334
00:36:00.306 --> 00:36:00.879
Klaus Mager: Jesse.

335
00:36:02.390 --> 00:36:08.629
Jessie Upp DayBalancer.com: Thank you. I'd like to go back to Stacey's notion of bias.

336
00:36:09.080 --> 00:36:11.850
Jessie Upp DayBalancer.com: which I actually think stems from trust.

337
00:36:12.730 --> 00:36:18.969
Jessie Upp DayBalancer.com: and Mike, noting his and the AI using it for inferences.

338
00:36:19.640 --> 00:36:27.140
Jessie Upp DayBalancer.com: And we use AI and Day balancer to really define a problem space leveraging the the mom test. And

339
00:36:27.450 --> 00:36:29.679
Jessie Upp DayBalancer.com: we really don't have a lack of visions

340
00:36:30.130 --> 00:36:43.170
Jessie Upp DayBalancer.com: like everyone has a vision, and you can see it right. And what we don't like to do is disprove our hypotheses of how to manifest that or address these big, wicked problems.

341
00:36:44.610 --> 00:36:56.319
Jessie Upp DayBalancer.com: so we match people to with their target market to really ask those deeper questions of their of their customers. You know of their the people that they want to serve so. And they find out that the youth

342
00:36:56.570 --> 00:37:02.190
Jessie Upp DayBalancer.com: crime problem is really about an after-school programming in a specific neighborhood.

343
00:37:03.030 --> 00:37:06.574
Jessie Upp DayBalancer.com: And so yeah, using AI for

344
00:37:07.590 --> 00:37:17.520
Jessie Upp DayBalancer.com: for getting to the problem space and defining a very clear space to act on. And instead of you know, we can get into analysis paralysis using AI to just

345
00:37:18.064 --> 00:37:23.830
Jessie Upp DayBalancer.com: stay in the moral theater part. So getting to that actionable problem is really key.

346
00:37:24.580 --> 00:37:31.150
Jessie Upp DayBalancer.com: But yeah, I love what Stacey is talking about with bias, because and how that I see that as stemming from trust.

347
00:37:32.780 --> 00:37:34.010
Klaus Mager: Thanks. Yeah.

348
00:37:34.480 --> 00:37:35.740
Klaus Mager: Thanks. Jesse.

349
00:37:35.980 --> 00:37:37.110
Klaus Mager: Hi ken.

350
00:37:37.550 --> 00:37:38.460
Ken Homer • SF Bay Area: Good morning!

351
00:37:38.810 --> 00:37:44.730
Klaus Mager: Good morning, Kevin. Let's hear from you. You have so much going on in your life here.

352
00:37:45.700 --> 00:37:48.846
Kevin Jones: You? Yeah, we are.

353
00:37:50.840 --> 00:37:57.120
Kevin Jones: in working on this conference. In Chicago

354
00:37:57.560 --> 00:38:03.300
Kevin Jones: Neighborhood Economics end of September 1st of October, and we've been noticed

355
00:38:03.440 --> 00:38:08.969
Kevin Jones: by several coalitions of hospitals doing the work we do

356
00:38:09.080 --> 00:38:13.200
Kevin Jones: at much greater scale than we had, because we got involved

357
00:38:13.670 --> 00:38:18.990
Kevin Jones: with the Macarthur Foundation, which is based there. But they're doing local and Chicago trust, and

358
00:38:19.190 --> 00:38:22.943
Kevin Jones: everybody's really opening up to us. And

359
00:38:24.700 --> 00:38:33.620
Kevin Jones: So these hospitals work on community health. But they don't really understand. You know how financial innovation can get their money out on the street

360
00:38:33.930 --> 00:38:40.940
Kevin Jones: lower than the you know, Cdfis, are these wonderful things that don't work community development financing institutions. They become

361
00:38:41.280 --> 00:38:46.239
Kevin Jones: a lot like banks, but they used to be community development finance institutions. But

362
00:38:46.520 --> 00:38:56.250
Kevin Jones: after 2,008 they swallowed all the clever risk taking ones. So now they're rigid and and don't do much. And so all the creativity is down below

363
00:38:56.550 --> 00:39:11.820
Kevin Jones: the collateral that they demand working in. We work in neighborhoods where people die 10 years younger, actually in one neighborhood. In Chicago they die 20 years younger than the loop is 88, and we work in neighborhoods where people die at 58.

364
00:39:12.402 --> 00:39:21.170
Kevin Jones: So it's a no. Anyway, it's 2020 years and we're having to like.

365
00:39:22.750 --> 00:39:33.340
Kevin Jones: I mean, just personally, it's like, Oh, this is where we could get an actual big viable business. Oh, this is my last time to do it. I'm hoping the young people step up.

366
00:39:33.560 --> 00:39:38.520
Kevin Jones: But you know, it's just. I'm immersed with the fact that

367
00:39:39.250 --> 00:39:43.850
Kevin Jones: finally figured out what this business should be when I'm ready to hand it to somebody younger.

368
00:39:43.990 --> 00:39:45.920
Kevin Jones: And none of those folks are right

369
00:39:46.160 --> 00:39:56.300
Kevin Jones: are are really stepping up. So it's we're gonna make some money, and who knows what the future is? You know it's gonna be fine with me to go back to working on a book

370
00:39:56.570 --> 00:40:01.289
Kevin Jones: if this business doesn't survive. But I know what the model looks like. So we're looking to, maybe

371
00:40:02.330 --> 00:40:09.620
Kevin Jones: working with this black woman that I've worked with for a few years, Stephanie Sweptson 20 to try to find some young

372
00:40:10.310 --> 00:40:25.539
Kevin Jones: Mba type. The space I work when is typically I scout on the edge until you can hire an Mba and Mbas are not. You don't want them to be creative. You want them to do complex, repetitive tasks when there's a taxonomy

373
00:40:25.680 --> 00:40:31.899
Kevin Jones: and their structure, and they they work really well in structure, but they don't work well in unformed situations.

374
00:40:32.110 --> 00:40:35.040
Kevin Jones: So it's time to find a young, you know.

375
00:40:35.810 --> 00:40:39.090
Kevin Jones: Mba of color to build the business that could be here.

376
00:40:39.260 --> 00:40:55.620
Kevin Jones: or it might go away. I'm just having to live in this liminal space. I'm sorry I'm we're finally moving into an apartment post to lead end of next month, because we're still no, don't know what Fema is gonna do for paying our house or not paying for our house. So we're

377
00:40:56.160 --> 00:41:01.020
Kevin Jones: we. I've been in a liminal state, and next week I will live somewhere.

378
00:41:01.510 --> 00:41:06.470
Kevin Jones: and we through this weird pricing. We have an 11 month lease because

379
00:41:06.840 --> 00:41:13.649
Kevin Jones: they're really weird on their pricing. And 11 month was really cheap, and a 12 month was like $5,000 more. So it's like.

380
00:41:13.650 --> 00:41:14.260
Gil Friend • Sustainability OG • CxO Coach: Hmm.

381
00:41:14.410 --> 00:41:19.179
Kevin Jones: We? We manipulated their inefficient pricing, and found the little slot.

382
00:41:20.530 --> 00:41:26.809
Gil Friend • Sustainability OG • CxO Coach: And I discovered I wanna don't want to live on a farm anymore. I want to live walkable to a cafe and restaurants.

383
00:41:26.950 --> 00:41:29.379
Kevin Jones: And easy, flat walking spaces.

384
00:41:30.050 --> 00:41:31.310
Kevin Jones: And so

385
00:41:31.510 --> 00:41:37.029
Kevin Jones: so, my! My 15 years on a farm when I loved it. But you know, whoever took it away, and

386
00:41:39.180 --> 00:41:41.719
Kevin Jones: being in a place where I can walk to a store

387
00:41:42.010 --> 00:41:44.520
Kevin Jones: and a cafe in a restaurant is better. So

388
00:41:45.850 --> 00:41:50.729
Kevin Jones: yeah, it's weird to have finally figured out what the business model is, and realize you're not the guy to do it.

389
00:41:51.320 --> 00:41:53.959
Kevin Jones: So you know, I don't know.

390
00:41:53.960 --> 00:41:56.349
Klaus Mager: How's the recovery effort in Asheville going.

391
00:41:57.320 --> 00:42:06.299
Kevin Jones: Oh, the money they promised isn't coming, that's you know it's

392
00:42:06.490 --> 00:42:10.228
Kevin Jones: and nobody knows where it is. And and you know it's it's

393
00:42:10.990 --> 00:42:14.679
Kevin Jones: how much this the State is doing really good things and

394
00:42:14.800 --> 00:42:18.020
Kevin Jones: everything we relied on from the Federal Government.

395
00:42:19.590 --> 00:42:25.880
Kevin Jones: You can't. There's not even somebody to tell you an answer to where the money they promised might be.

396
00:42:26.420 --> 00:42:33.782
Kevin Jones: It's just a you know, and Fema folks are now doing immigration. So finding somebody answers, the phone is

397
00:42:34.930 --> 00:42:44.660
Kevin Jones: you know it's it's we will be devastated for years, and you know the the our, our our State does as good as they can.

398
00:42:45.880 --> 00:42:49.860
Kevin Jones: and the federal thing is, is is in an uncertain state.

399
00:42:50.490 --> 00:42:57.190
Kevin Jones: So we're getting lots more floods because the land was scoured. And there's no good, you know. Bioremediation at scale.

400
00:42:57.330 --> 00:42:57.910
Kevin Jones: Oh.

401
00:42:58.730 --> 00:43:10.942
Kevin Jones: and but Riverlink is getting some money, you know. There's some things happening, but it's it's basically piecemeal, not going well. People are miserable. People are moving away from

402
00:43:11.640 --> 00:43:14.880
Kevin Jones: specifically, Swan and ow, who were deeply involved.

403
00:43:15.160 --> 00:43:20.420
Kevin Jones: Because it's just so fucking sad. And I I'm not going back this one at all. It's

404
00:43:21.070 --> 00:43:23.959
Kevin Jones: the devastation and sadness

405
00:43:24.160 --> 00:43:28.700
Kevin Jones: in the trauma that's in the land that you can see. It's just too much. I'm getting away.

406
00:43:29.080 --> 00:43:31.269
Kevin Jones: So I'm going to the city, and

407
00:43:31.560 --> 00:43:47.269
Kevin Jones: I was really involved in my community. And just you know, people can't bear it. The woman who did the best relief work of death. Trigg is in the south of France for 2 weeks, and hope she might be able to engage some when she comes back, that she's got

408
00:43:48.220 --> 00:44:11.380
Kevin Jones: more firm compassion than anybody, and she's given up for a while. So people are giving up. We don't have a grocery store. We don't have a post office. Our restaurants are gone. There's no, you know. Austin says you need a place where people meet up occasionally randomly, to govern a watershed or a community. We don't. We've lost all those places where people gather

409
00:44:11.660 --> 00:44:12.790
Kevin Jones: mostly.

410
00:44:13.700 --> 00:44:16.500
Kevin Jones: And so, you know, it's it's a

411
00:44:16.640 --> 00:44:20.029
Kevin Jones: we're a low status neighborhood that will be

412
00:44:21.060 --> 00:44:24.330
Kevin Jones: increasingly devastated in its social fabric.

413
00:44:25.210 --> 00:44:28.010
Klaus Mager: Hmm, boy, that's tough.

414
00:44:28.260 --> 00:44:32.029
Kevin Jones: Yeah, I just I I can't deal with it much, you know, just

415
00:44:32.870 --> 00:44:35.630
Kevin Jones: even the the folks who were

416
00:44:35.900 --> 00:44:40.300
Kevin Jones: real seriously compassionate long time workers are saying, you know, we

417
00:44:45.800 --> 00:44:50.180
Kevin Jones: the the sadness is coming up at throat level, you know. It's just

418
00:44:50.360 --> 00:44:55.930
Kevin Jones: about to make folks grind in the sadness. So that's all I'll say, and please don't ask me again.

419
00:44:55.930 --> 00:45:04.830
Mike Nelson: I know you don't have any data. But what percentage of the population in these most impacted areas have left town and given up.

420
00:45:07.100 --> 00:45:15.119
Kevin Jones: I know folks who were deeply involved who've left is the interesting thing. Folks who were standing tall during recovery

421
00:45:15.530 --> 00:45:26.879
Kevin Jones: are walking away, you know the the mutual aid groups are broken, the all the groups that were paid a little bit higher than mutual aid are also broke.

422
00:45:27.330 --> 00:45:29.960
Kevin Jones: The voluntary mutual aid groups shut down.

423
00:45:30.170 --> 00:45:31.900
Kevin Jones: And now the ones that got

424
00:45:32.020 --> 00:45:35.049
Kevin Jones: money to do that and work in the middle

425
00:45:35.380 --> 00:45:37.319
Kevin Jones: can't deal with the job anymore.

426
00:45:38.670 --> 00:45:39.280
Klaus Mager: Hmm.

427
00:45:39.540 --> 00:45:49.389
Klaus Mager: I mean just saying, this is just one spot in the country, and there's so many other places now that I have that have had similar levels of destruction. I mean, it's really shocking.

428
00:45:49.390 --> 00:45:56.469
Kevin Jones: Yeah, we have serious workout going on with some groups trying to do circular economy stuff. And you know.

429
00:45:56.570 --> 00:46:01.349
Kevin Jones: I'm gonna let somebody else be hopeful about what to rebuild

430
00:46:01.680 --> 00:46:06.910
Kevin Jones: in that space. And I'm I'm not gonna I I can't pay attention to it anymore. It costs too much.

431
00:46:08.220 --> 00:46:11.609
Klaus Mager: Hmm, thanks, Kevin.

432
00:46:11.820 --> 00:46:14.840
Klaus Mager: Kalia, how are you doing?

433
00:46:15.930 --> 00:46:21.730
Klaus Mager: So? That's where that is, are you? Are you there? Talia?

434
00:46:25.960 --> 00:46:26.940
Klaus Mager: Nope.

435
00:46:27.110 --> 00:46:28.409
Mike Nelson: Must have stepped away.

436
00:46:28.670 --> 00:46:34.110
Klaus Mager: Yeah, okay, and how are you doing? You wanna do a check in.

437
00:46:34.110 --> 00:46:39.949
Ken Homer • SF Bay Area: Sure. Kevin, I'm just moved by your point.

438
00:46:40.200 --> 00:46:43.169
Ken Homer • SF Bay Area: and I really feel that pain and and just

439
00:46:44.150 --> 00:46:48.470
Ken Homer • SF Bay Area: tragic doesn't even begin to cover it, you know. Just horrible

440
00:46:51.200 --> 00:46:58.220
Ken Homer • SF Bay Area: After 3 months of trying almost every day, we finally got an appointment at the Spanish Consulate for our visas.

441
00:46:58.340 --> 00:47:05.279
Ken Homer • SF Bay Area: It's coming up in September, and then learned this week from somebody who got their appointment last week. They were kind enough to put up a

442
00:47:05.520 --> 00:47:30.689
Ken Homer • SF Bay Area: long document on one of the forums of what they learned. So I think we're in pretty good shape. We should be able to get approved, but it's taken about 3 months. So if all goes well, we're pulling up stakes here December, January timeframe, and heading off to Spain to Valencia, where we will live within walking distance of grocery stores and restaurants and cafes. We were in Valencia last spring in April.

443
00:47:31.130 --> 00:47:34.957
Ken Homer • SF Bay Area: Really loved it. I'm very surprised because I'm not a

444
00:47:36.110 --> 00:47:42.320
Ken Homer • SF Bay Area: I'm not a city person. But the city is clean, it's green. There's lovely parks

445
00:47:42.520 --> 00:48:00.259
Ken Homer • SF Bay Area: really great use of tax dollars. Every day I saw groups of 2 and 3 people pushing carts with barrels and dustpans and brooms, and they were cleaning up the litter. The only place I saw litter was in the old city where the tourists go because the tourists just drop shit without thinking about it. But the Spaniards are very clean

446
00:48:00.630 --> 00:48:12.380
Ken Homer • SF Bay Area: in apparently in the nineties. They were kind of down at the heels, and they did a lot of urban planning, and they they expanded the roads and put in dedicated bike lanes with, you know, barriers. And so there's bike lanes on every single major street.

447
00:48:12.410 --> 00:48:32.970
Ken Homer • SF Bay Area: lots of people on bikes, lots of people on scooters, the public transit you can get anywhere you need to go in the city without having to walk more than about 10 or 15 min to go from some place to another. As long as you tag on and within, you know, if you get on a bus and then transfer to a tram as you do that within an hour, there's no transfers. Just automatically. The computer knows it as one trip.

448
00:48:33.190 --> 00:48:45.960
Ken Homer • SF Bay Area: and to recharge the card that we got was €10 for no, it's €4 for 10 trips. So it's about 40 cents to travel around the city. Just it felt so civilized.

449
00:48:46.080 --> 00:48:50.629
Ken Homer • SF Bay Area: And then I noticed that the the drivers are really courteous, like, you know.

450
00:48:50.860 --> 00:49:09.790
Ken Homer • SF Bay Area: don't run red lights. They actually stop when their light turns yellow they stop, and we have a friend who lives there. And we were driving with them and found out why there's traffic cams at every intersection, and if you run a light you get a ticket in the mail and you get 3 of them. They suspend your license. So people really obey the traffic laws.

451
00:49:10.060 --> 00:49:24.770
Ken Homer • SF Bay Area: We were also there during the blackout, when the whole peninsula was blacked out, and all the headlines in the papers are saying, Spain's in chaos. There was no chaos. Civilians got out of their cars and directed traffic at the intersections, buses. Let other cars go.

452
00:49:24.910 --> 00:49:32.760
Ken Homer • SF Bay Area: restaurants were saying, we have no refrigeration. Come, drink our beer before it gets warm, you know, and I was talking to this

453
00:49:33.080 --> 00:49:42.609
Ken Homer • SF Bay Area: young woman, probably in her early twenties. Later on at night, right before the power came on her at a restaurant, that that there was no power but they had gas stoves so they could serve

454
00:49:43.100 --> 00:50:06.109
Ken Homer • SF Bay Area: food, and she said, I got off the train like 10 min before the power went out, and I was trying to get to my friend's house, and the power went out, and all I had was €8 in my pocket, and the cab driver said, No, no, Problema, no Problema, you know. And he said, just here's my phone number. Pay me when the power comes back on. And he drove her across the city, and I'm like.

455
00:50:06.680 --> 00:50:11.080
Ken Homer • SF Bay Area: It was so uplifting to be around this kind of of

456
00:50:11.320 --> 00:50:19.080
Ken Homer • SF Bay Area: friendliness and this kind of of cooperation. And and so we're really looking forward to to getting over there, because

457
00:50:19.190 --> 00:50:22.139
Ken Homer • SF Bay Area: after 35 years in Marin, as much as I love the place.

458
00:50:22.480 --> 00:50:30.700
Ken Homer • SF Bay Area: people are horribly aggressive drivers out here. They turn their backs on people. It's not the same place that that we moved to.

459
00:50:31.040 --> 00:50:40.360
Ken Homer • SF Bay Area: So many trees have been cut down, so much development's gone on, and you know it's a it's a hyperactive place, and

460
00:50:40.980 --> 00:50:55.200
Ken Homer • SF Bay Area: the worst drivers in the world are the ones in the Teslas. You know. The the newer your car, the more expensive the car, the more of an asshole you are when you drive is my experience. So we'll be able to live without a car over there, and we'll be able to live about

461
00:50:55.510 --> 00:50:57.700
Ken Homer • SF Bay Area: oof between

462
00:50:57.810 --> 00:51:12.549
Ken Homer • SF Bay Area: half and 2 thirds of the cost of living. 2 thirds would be like really living well. So it's going to cost about half of what it lives here which will help our retirement savings go a long way. So we're pretty excited, but it's a huge amount of work. And it's been

463
00:51:12.850 --> 00:51:26.779
Ken Homer • SF Bay Area: really emotional going through. You know, all these boxes that I've had stored and pulling out things and saying, Okay, I'm not going to bring this with me, and that's going to go. So that's really brought up a lot of a lot of stuff. And

464
00:51:26.960 --> 00:51:33.309
Ken Homer • SF Bay Area: so it's it's daunting and exciting, and and lovely and and scary, all at the same time.

465
00:51:34.180 --> 00:51:35.659
Mike Nelson: What's what's the city?

466
00:51:35.660 --> 00:51:36.430
Ken Homer • SF Bay Area: Valencia.

467
00:51:36.760 --> 00:51:46.029
Mike Nelson: Valencia. Okay, I didn't catch that. We have very good friends who were all set to make the same kind of move. They're about 10 years older than you.

468
00:51:46.400 --> 00:51:49.400
Mike Nelson: But then they found out that

469
00:51:50.390 --> 00:51:57.359
Mike Nelson: they they knew they needed to have health insurance, and they knew that Medicare doesn't cover them over there.

470
00:51:58.380 --> 00:52:03.380
Mike Nelson: and they found it because the husband had had prostate cancer

471
00:52:04.170 --> 00:52:10.990
Mike Nelson: pre-existing condition. Nobody would insure them, for no any kind of reasonable price.

472
00:52:12.200 --> 00:52:16.041
Ken Homer • SF Bay Area: That's I'm really sorry to hear that we worked with a

473
00:52:16.770 --> 00:52:42.699
Ken Homer • SF Bay Area: a woman who said, Yes, if you have pre-existing conditions, you know, disclose them, but you might pay higher premium. And so we've we've got a quote we've got, you know. It's we're not buying the insurance until right before our our appointment. It takes about 2 weeks to get the paperwork processed, because you have to pay for the whole year in advance, but you can delay it by a couple of months, and

474
00:52:42.980 --> 00:52:47.464
Ken Homer • SF Bay Area: so we know that we're covered. They've they've already accepted us, and

475
00:52:47.970 --> 00:53:06.120
Ken Homer • SF Bay Area: filling out the questionnaire was amazing like they do not check your Us. Health records. They depend. They rely on you to just be disclosing what's going on. And fortunately, whatever pre-existing conditions we both have are not serious. They're, you know, kind of regular old stuff, no cancers and everything like that. So.

476
00:53:06.120 --> 00:53:10.310
Mike Nelson: If you were not to disclose, and then something recurred.

477
00:53:10.570 --> 00:53:12.660
Mike Nelson: they would have the right to unplug.

478
00:53:12.660 --> 00:53:14.319
Ken Homer • SF Bay Area: They would, they would.

479
00:53:14.320 --> 00:53:16.000
Mike Nelson: Okay. Delight.

480
00:53:16.230 --> 00:53:16.860
Ken Homer • SF Bay Area: So.

481
00:53:17.040 --> 00:53:18.319
Gil Friend • Sustainability OG • CxO Coach: And how old are you guys.

482
00:53:19.206 --> 00:53:21.419
Ken Homer • SF Bay Area: My wife is 72. I'm 68.

483
00:53:21.420 --> 00:53:24.290
Gil Friend • Sustainability OG • CxO Coach: Okay? And so does Medicare. Do you any good at all?

484
00:53:24.290 --> 00:53:28.169
Ken Homer • SF Bay Area: Not at all. Medicare does not work outside the state. So actually.

485
00:53:28.170 --> 00:53:31.619
Gil Friend • Sustainability OG • CxO Coach: Where you'd have to. You'd have to come back to the States to get treatment kind of thing.

486
00:53:31.855 --> 00:53:35.150
Ken Homer • SF Bay Area: Yeah. But why would we do that? We could get great treatment over there.

487
00:53:35.150 --> 00:53:36.749
Gil Friend • Sustainability OG • CxO Coach: I understand. I understand. Yeah. So.

488
00:53:36.750 --> 00:53:42.309
Ken Homer • SF Bay Area: We're actually gonna cancel our medicare because we each pay $185 a month, and

489
00:53:42.530 --> 00:53:53.910
Ken Homer • SF Bay Area: that will just about cover the cost of insurance. I think it's about $2,000 a person per year. So you know, it's really reasonable compared to what we used to pay. I mean before I went on Medicare.

490
00:53:54.040 --> 00:54:02.203
Ken Homer • SF Bay Area: when I went on Medicare, my health insurance premiums dropped by $9,000 a year. Yeah, which is just freaking insane, you know. Yeah,

491
00:54:02.980 --> 00:54:32.450
Ken Homer • SF Bay Area: so yeah, we're once we get there, we'll cancel our medicare. That'll cover our health insurance over there. And the non-locrative visa means you can't work. It's interesting the way the law is written. It says you can't work in Spain, and you can't work remotely. But people who've been there once you've been there for a year, you re-up, and you're approved for 2 years, and people who've been approved for that 2 year period have done work remotely, and the Government's gone after them. They've gone to court, and they've won the right because the law is worded very

492
00:54:32.630 --> 00:54:50.889
Ken Homer • SF Bay Area: locally, so I should be able to work again after I've been there for a year. So, looking forward to a year off, of learning the language and the culture, and getting used to the place, and then I have a bunch of contacts in Europe. I've worked in Europe before, so I should be able to pick up some more income once we've been there for a year, and that'll also help.

493
00:54:51.350 --> 00:54:54.979
Mike Nelson: So you're not a retiree visa. Then.

494
00:54:54.980 --> 00:55:00.940
Ken Homer • SF Bay Area: It's called the non-lucrative visa. And it's for people who are retired. Yeah, I have to submit a letter saying, I will not work.

495
00:55:00.940 --> 00:55:01.610
Mike Nelson: Okay.

496
00:55:04.490 --> 00:55:06.939
Klaus Mager: Hmm! So this is permanent. Huh?

497
00:55:06.940 --> 00:55:35.410
Ken Homer • SF Bay Area: This is permanent. Yeah, we it's not. We started talking about this 3 years ago when we thought we'd go to Italy and then found out that Italy's tax structure would take about 32% of our social security which made it untenable. It's not due to the political atmosphere. It's simply economics, you know. I can't stay in the barrier. It's too expensive. However, given the political situation, it feels like we're actually fleeing the country, the police state is in full force and unfolding before our eyes, and like.

498
00:55:35.470 --> 00:55:38.530
Ken Homer • SF Bay Area: I think, most people were asleep about that, so

499
00:55:38.600 --> 00:55:41.309
Ken Homer • SF Bay Area: happy to be getting out and sad to be

500
00:55:41.430 --> 00:55:46.759
Ken Homer • SF Bay Area: having to leave because of that reason. That's not the reason leaving, but it's it's certainly added to it.

501
00:55:47.390 --> 00:55:50.170
Klaus Mager: Yeah, yeah.

502
00:55:50.170 --> 00:55:53.539
Mike Nelson: And which which passport do you or your wife have.

503
00:55:53.860 --> 00:55:54.780
Ken Homer • SF Bay Area: Us.

504
00:55:55.290 --> 00:55:58.490
Mike Nelson: You don't have any European passport.

505
00:55:59.620 --> 00:56:00.300
Ken Homer • SF Bay Area: Nope.

506
00:56:00.750 --> 00:56:13.750
Ken Homer • SF Bay Area: my, we're both, you know my family has been here for, like I don't know 5, 6 generations going back to the mid eighties, so I have no, and it's all English, Irish, Scottish, and German for me, and my wife has some

507
00:56:14.020 --> 00:56:28.939
Ken Homer • SF Bay Area: Polish and Romanian, and her great grandmother was from Romania so she could get a Romanian passport. But she was investigating, she said, they're just really shady in Romania. It's like, you know. You get this feeling of. Oh, I gotta take a shower after talking to these people, you know, like.

508
00:56:29.900 --> 00:56:31.710
Mike Nelson: I don't think we're gonna go that route.

509
00:56:31.710 --> 00:56:34.129
Mike Nelson: It may not be the personal brand you want.

510
00:56:34.130 --> 00:56:37.267
Ken Homer • SF Bay Area: No, no, lisa's not Serbian.

511
00:56:37.790 --> 00:56:40.460
Mike Nelson: Albanian.

512
00:56:40.460 --> 00:56:40.850
Ken Homer • SF Bay Area: Yeah.

513
00:56:41.540 --> 00:56:44.220
Klaus Mager: Hmm Jesse.

514
00:56:46.001 --> 00:56:49.050
Jessie Upp DayBalancer.com: Has anybody ken? Have you heard of Mondragon?

515
00:56:49.880 --> 00:56:55.069
Ken Homer • SF Bay Area: Okay, of course, yeah, I absolutely am so inspired by that. And.

516
00:56:55.210 --> 00:57:04.400
Jessie Upp DayBalancer.com: And positioning our our organization to to do that in a way and a different way. So I

517
00:57:05.860 --> 00:57:09.350
Jessie Upp DayBalancer.com: I would want to flee there and into that model.

518
00:57:09.350 --> 00:57:16.219
Jessie Upp DayBalancer.com: Yeah, so I'm I'm curious. What is the stopping us to create something like that here.

519
00:57:18.430 --> 00:57:19.499
Ken Homer • SF Bay Area: I know it's.

520
00:57:19.500 --> 00:57:25.530
Jessie Upp DayBalancer.com: Socioeconomic political structure, I know, but like

521
00:57:26.850 --> 00:57:35.670
Jessie Upp DayBalancer.com: under under cover, kind of like, I don't know. I I always look at possibilities and not what's not possible. So.

522
00:57:37.130 --> 00:57:43.144
Ken Homer • SF Bay Area: Yeah, yeah, I mean, it's just the way things are structured. Here is if you're not

523
00:57:43.860 --> 00:57:53.380
Ken Homer • SF Bay Area: maximizing shareholder value, then you can be sued for breach of fiduciary duty. You know it's all about extraction. There's a whole.

524
00:57:53.380 --> 00:58:03.199
Jessie Upp DayBalancer.com: Different models like Rei or Pcc. That have cooperative models that have worked so can't we scale that into a more?

525
00:58:03.400 --> 00:58:05.049
Jessie Upp DayBalancer.com: I don't know why not.

526
00:58:06.780 --> 00:58:09.580
Ken Homer • SF Bay Area: Barriers to entry is the economic phrase.

527
00:58:12.770 --> 00:58:13.530
Klaus Mager: Hmm.

528
00:58:13.530 --> 00:58:14.820
Mike Nelson: But there are some.

529
00:58:14.820 --> 00:58:15.430
Gil Friend • Sustainability OG • CxO Coach: Why? Why?

530
00:58:15.430 --> 00:58:18.789
Mike Nelson: Co. Ops, but they don't apply in a lot of places. That's the problem.

531
00:58:19.400 --> 00:58:23.700
Gil Friend • Sustainability OG • CxO Coach: Why not? Why can't we? Is a much better question, Jesse, than why isn't it happening.

532
00:58:23.700 --> 00:58:27.449
Jessie Upp DayBalancer.com: Yeah, well, like it, can't. We? Is really what I'm getting at, because I'm talking to.

533
00:58:27.450 --> 00:58:30.870
Gil Friend • Sustainability OG • CxO Coach: No, I mean no. What you're what you're trying to. What you're actually saying is, how could we.

534
00:58:30.870 --> 00:58:31.369
Jessie Upp DayBalancer.com: How could we.

535
00:58:31.370 --> 00:58:48.059
Gil Friend • Sustainability OG • CxO Coach: Not? Why can't we? But how could we? Yeah, exactly that. And you know, and it's happening. It's, you know, there, there's growth in the Esop Employee stock ownership plan sector. There's growth in the Co-OP sector. There's a surprising growth in in the Stewardship Trust sector.

536
00:58:48.060 --> 00:58:48.560
Jessie Upp DayBalancer.com: Yeah.

537
00:58:48.889 --> 00:59:00.430
Gil Friend • Sustainability OG • CxO Coach: There are. There are legal structures more advantageous for esops than for co-ops, but the law seems to be moving. There's money moving. There's a lot. There's a bunch of funds that have been built

538
00:59:00.730 --> 00:59:29.360
Gil Friend • Sustainability OG • CxO Coach: to support Co-OP and Esop, various kinds of employee ownership and trust development. We tried to start one a few years ago. We've laid that down. But there's other people making that effort. There's hundreds hundreds of millions of dollars, maybe billions of dollars of capital in motion on this, and it's not the normal game, but it doesn't have to be the normal game because you can. You can write corporate bylaws that charter a corporation to different purposes and purely maximization of financial return.

539
00:59:29.680 --> 00:59:33.539
Gil Friend • Sustainability OG • CxO Coach: The other thing, Ken, to your point about fiduciary duty.

540
00:59:33.860 --> 00:59:40.560
Gil Friend • Sustainability OG • CxO Coach: I've been touching on this in some of the speeches I've been giving lately, but fiduciary duty

541
00:59:40.730 --> 00:59:47.669
Gil Friend • Sustainability OG • CxO Coach: doesn't mean maximize return to shareholders. Fiduciary doesn't the word fiduciary doesn't have to do with money. It has to do with trust.

542
00:59:47.890 --> 00:59:53.920
Gil Friend • Sustainability OG • CxO Coach: and the and the statutory responsibility of a fiduciary is to attend to all that matters to the

543
00:59:54.110 --> 01:00:07.960
Gil Friend • Sustainability OG • CxO Coach: whatever. The counterparty term is Doug. You probably know what that term is, but like to take care of them, and and you're violating fiduciary duty if you don't attend to all relevant risks that concern them.

544
01:00:08.230 --> 01:00:09.660
Gil Friend • Sustainability OG • CxO Coach: Which is why the

545
01:00:09.770 --> 01:00:18.000
Gil Friend • Sustainability OG • CxO Coach: Texas and Florida proposed laws to instruct fiduciaries to violate fiduciary duty is really cuckoo stuff.

546
01:00:18.770 --> 01:00:31.830
Gil Friend • Sustainability OG • CxO Coach: And that's the norm. Yeah, that ken. That's the norm in the thinking that everybody is in. But the law, I think, allows for different moves. And certainly the money is moving in that direction. The economic benefits of employee ownership are strikingly clear.

547
01:00:32.010 --> 01:00:45.440
Gil Friend • Sustainability OG • CxO Coach: The deal structure is a complicated issue, because you no longer have just, you know, owners and investors, you have owners and investors and the larger employee pool of owners. So how you build the stack?

548
01:00:45.660 --> 01:00:48.090
Gil Friend • Sustainability OG • CxO Coach: It's not trivial, but it's doable

549
01:00:51.790 --> 01:00:52.400
Jessie Upp DayBalancer.com: Yeah. And

550
01:00:52.400 --> 01:01:09.039
Jessie Upp DayBalancer.com: I mean, Mitch just shared with me a new way of even creating establishing legalities. It's gonna take a long time. And there are people are going to actually have to work hard at it, and we might not see it even in our lifetime. But I do see.

551
01:01:09.040 --> 01:01:09.360
Gil Friend • Sustainability OG • CxO Coach: Like.

552
01:01:10.280 --> 01:01:27.649
Gil Friend • Sustainability OG • CxO Coach: I mean, people are working hard on it, and Montagon is a great case in point, because it's a proof that something is possible at scale. This is not just your neighborhood food Co-OP. This is, you know, what is it? Like? 80,000 employees in a multi-billion dollar corporation? That's significant economic force in Spain

553
01:01:28.310 --> 01:01:30.220
Gil Friend • Sustainability OG • CxO Coach: proves that something is possible.

554
01:01:30.400 --> 01:01:51.959
Jessie Upp DayBalancer.com: Yeah. And so if we start instead of isolating ourselves in our in our abilities, I think we're kind of conditioned to work on our own thing and and start connecting dots, I think, especially just visualizing the dots as they are. And what could be, I think, visualizing data in itself really does inspire.

555
01:01:51.960 --> 01:01:52.550
Gil Friend • Sustainability OG • CxO Coach: Yeah.

556
01:01:53.040 --> 01:01:58.829
Doug Breitbart: There are I, at least in the the world, that I'm traveling in these days.

557
01:01:59.430 --> 01:02:05.760
Doug Breitbart: There are folks very much doing that. There's sort of operating at a meta level.

558
01:02:06.540 --> 01:02:12.800
Doug Breitbart: Of individual initiatives. That I I. The the

559
01:02:12.910 --> 01:02:19.770
Doug Breitbart: metaphor I I invoke is is that it's it's a mosaic of efforts.

560
01:02:20.220 --> 01:02:22.839
Doug Breitbart: and each piece of the mosaic

561
01:02:23.110 --> 01:02:28.920
Doug Breitbart: is very focused and and energized and extended

562
01:02:29.320 --> 01:02:32.440
Doug Breitbart: in their piece of the mosaic

563
01:02:33.339 --> 01:02:38.500
Doug Breitbart: but a lot of those pieces do form, start to coalesce

564
01:02:38.640 --> 01:02:45.249
Doug Breitbart: an ecosystem, start to coalesce and network, start to coalesce an organism

565
01:02:46.340 --> 01:02:50.580
Doug Breitbart: that operates by principles and service to life

566
01:02:51.220 --> 01:02:54.299
Doug Breitbart: operates by principles and service to

567
01:02:54.880 --> 01:03:00.210
Doug Breitbart: resource and value flows rather than currency. Centric.

568
01:03:02.050 --> 01:03:11.750
Doug Breitbart: A lot of those folks are also practicing different and and transformative.

569
01:03:11.750 --> 01:03:13.100
Gil Friend • Sustainability OG • CxO Coach: It was moving forward.

570
01:03:13.100 --> 01:03:19.010
Doug Breitbart: Organizational approaches management decision making consent process

571
01:03:19.760 --> 01:03:26.030
Doug Breitbart: models and approaches that are not the norm. I as an attorney.

572
01:03:27.450 --> 01:03:29.819
Doug Breitbart: I practice unlaw.

573
01:03:30.020 --> 01:03:37.649
Doug Breitbart: which means that I start with what folks want to achieve and create, and how they want to work.

574
01:03:38.020 --> 01:03:44.270
Doug Breitbart: and then I help, modify, adapt, plug, and and and create

575
01:03:44.600 --> 01:03:48.539
Doug Breitbart: a mosaic orientation approach to how they

576
01:03:48.730 --> 01:03:53.479
Doug Breitbart: interface with the legal systems, requirements, regulations, and and all that.

577
01:03:53.710 --> 01:03:56.120
Doug Breitbart: and rather than the other way around.

578
01:03:56.420 --> 01:04:01.110
Doug Breitbart: And there is a lot of creative possibility and flexibility.

579
01:04:04.880 --> 01:04:08.720
Doug Breitbart: For the most part, the legal profession

580
01:04:11.220 --> 01:04:20.409
Doug Breitbart: doesn't know how to do that, because they've never actually sat on the side of the entrepreneur, or the cooperative or the collaborative.

581
01:04:20.510 --> 01:04:24.660
Doug Breitbart: so they don't understand what's needed or desired

582
01:04:25.040 --> 01:04:29.380
Doug Breitbart: as a practical operating rubber meets the road reality.

583
01:04:29.830 --> 01:04:45.889
Doug Breitbart: and so their their only palette is the post office of what what you do, for what situation, and it's always fitting the situation to the, to the practice and to the structure or or model.

584
01:04:47.000 --> 01:04:47.710
Doug Breitbart: And

585
01:04:50.650 --> 01:04:58.300
Doug Breitbart: that's not a good thing to have defining and controlling and imposed on the way people co-create together.

586
01:04:58.580 --> 01:05:13.349
Doug Breitbart: It's not fit for for use, and the principal reason is because the legal system is not in service to people co-creating and connecting and flowing together. It's created in service to defining

587
01:05:13.600 --> 01:05:27.330
Doug Breitbart: what is the penalty or consequence for breaching whatever the agreement or regulatory scheme is that's operating. So it's a penalty. System. It's not a generative creative system.

588
01:05:27.630 --> 01:05:36.430
Jessie Upp DayBalancer.com: Well, I love the unlaw. It's like unschooling notion I would. And if you wanted to talk about it later, I would love to.

589
01:05:36.430 --> 01:05:45.070
Doug Breitbart: You and I. You and I are destined. We we haven't figured out yet, but I am still headed your way in my heart so like. Yes.

590
01:05:45.070 --> 01:05:46.969
Doug Breitbart: thank you. I would do that. We have.

591
01:05:46.970 --> 01:06:03.498
Jessie Upp DayBalancer.com: I would love to map the Mondragon, the Mondragon partnership model for our cooperative vision. So, and using, you know, unlaw is just a beautiful prospect so. And we'd like to do it in a place based version. So by zip code. So we are mapping it

592
01:06:04.290 --> 01:06:07.019
Jessie Upp DayBalancer.com: place based. So thank you. I'm looking forward.

593
01:06:09.000 --> 01:06:20.075
Klaus Mager: I see an interesting shift in in sentiments, you know, in the community. Bent is attracting a lot of

594
01:06:22.100 --> 01:06:34.884
Klaus Mager: well off retirees now from California, from from Washington, and so on, because it's a quick place to retire. And so there's a lot of money floating in, but not just money, but talent, you know.

595
01:06:35.240 --> 01:06:53.920
Klaus Mager: So I I got called into a meeting with business Oregon, which is a state organization, a State agency, and that their mission is to direct the investment of the govern of the State government, not to build, to build, infrastructure, to do things, and

596
01:06:54.719 --> 01:07:02.589
Klaus Mager: so I said, well, let me just give you an example. And I did a gap analysis for the food system in the high desert

597
01:07:03.130 --> 01:07:27.339
Klaus Mager: and and developed a stack of here the top 5 investments that would really move the needle in the local food system in the farm to market food system. And here is the infrastructure that's missing. And here the investment points right? And so that resulted in a meeting with the Director of Edco, which is the economic development organization for Oregon and

598
01:07:27.350 --> 01:07:33.350
Klaus Mager: the director of Usda for World development. And so a couple of investors.

599
01:07:33.854 --> 01:07:41.409
Klaus Mager: So I got a call last week. And I and I met with a retired salesforce executive

600
01:07:41.950 --> 01:08:01.219
Klaus Mager: and the guy is really, you know, sort of a high powered character. And and he's basically saying, What do you need? Where do we start now? What are what are we gonna do here? And so there is. There is a recognition in in the

601
01:08:01.260 --> 01:08:11.600
Klaus Mager: sort of retired business community or or in in the support organizations that you know what we gotta do something here locally, because.

602
01:08:11.960 --> 01:08:22.883
Klaus Mager: you know you, you're looking in in my entire focus is on base of economy. That was my last newsletter base of economy economics theory, right? Which means that

603
01:08:23.880 --> 01:08:35.599
Klaus Mager: some 15% in the Us. Of the population lives paycheck to paycheck can't handle their $500 emergency and are getting increasingly squeezed.

604
01:08:35.720 --> 01:08:54.679
Klaus Mager: So when you look at not taking one trillion dollars out of the economy that is serving basically this base of economy, a base of pyramid economy that has serious impacts at the community level. We already see the local food bank getting swamped. And so

605
01:08:55.180 --> 01:09:00.800
Klaus Mager: the the challenge really is the opportunity right now really is

606
01:09:00.930 --> 01:09:25.879
Klaus Mager: that you have people who would otherwise see if they want to buy another boat, or you know what trip they're going on next. All of a sudden sort of shift their calendar and see, you know, where's the action? Where can I meaningfully engage here? And the the key issue, you know that's missing is a common vision.

607
01:09:26.310 --> 01:09:53.629
Klaus Mager: Now it's it's a it's a picture of what could be where you could go. And so I see this as and this is where AI can really kick in right? Because you can really use a well curated AI to create a very localized vision of of what is possible in this community based on the socioeconomic conditions that are around you.

608
01:09:53.710 --> 01:10:01.859
Klaus Mager: So I'm actually quite excited about this. I told him. You know he goes, what? What would be a good project, I said. Why don't we do a pilot here in bend

609
01:10:02.341 --> 01:10:26.220
Klaus Mager: and see and and showcase what could be done, you know, if you really engage, and you start at food, because that's where the pain point is and and where the pain point is almost instantly, you know, hitting us, because 2, 3 months down the road. These monies are gone. They cut off all the crayons to the nonprofits, right? School meals, meals on wheels.

610
01:10:26.220 --> 01:10:43.400
Jessie Upp DayBalancer.com: Clause. There is something going on in Bend already that is very cooperative and very. There's a whole movement already, so I'll connect you with that person there. So let's let. I don't want to reinvent wheels here. I want to like leverage. The bright spots that are already been

611
01:10:43.590 --> 01:10:45.569
Jessie Upp DayBalancer.com: are on its way, and.

612
01:10:45.570 --> 01:10:46.559
Klaus Mager: Absolutely. Yeah, thanks.

613
01:10:46.560 --> 01:10:48.120
Jessie Upp DayBalancer.com: Yeah. Awesome.

614
01:10:48.280 --> 01:10:51.630
Klaus Mager: Yeah. So so I think that's happening in every community.

615
01:10:51.630 --> 01:10:52.660
Jessie Upp DayBalancer.com: Think so.

616
01:10:52.660 --> 01:10:53.020
Klaus Mager: Perfect.

617
01:10:53.020 --> 01:11:12.690
Jessie Upp DayBalancer.com: Connect the communities because there are so many different efforts going on, and people would kind of still decentralized in their efforts. And then someone gets excited and they start their own version. And we have to have open door policy between all of these ideas. And so it's not like another login.

618
01:11:13.516 --> 01:11:14.250
Jessie Upp DayBalancer.com: you know.

619
01:11:14.250 --> 01:11:20.389
Klaus Mager: And the AI gives you an opportunity to collect best practice examples from around the country.

620
01:11:20.700 --> 01:11:43.200
Klaus Mager: But so when you, when you have a well curated. AI, if you are in any community, anywhere in the country and and you feed in, here's my condition. Here. Here is what we are, what we're living with the AI can say, well, these guys in this city did that, you know. That seems to be so. So when you, when you can bring together these best

621
01:11:43.803 --> 01:11:55.866
Klaus Mager: practice scenarios. And then there are some underlying commonalities, structures right building a local currency. There are certain things that

622
01:11:56.710 --> 01:12:21.739
Klaus Mager: that that anybody could use now if if if the information became available and you can use AI, you don't have not to build papers. And you know, Google documents. And all this stuff. You can have the AI actually inform you and talk you through it now. So that, I think, is is going to be a really powerful opportunity to to deploy.

623
01:12:31.900 --> 01:12:34.140
Klaus Mager: Now we're all quiet.

624
01:12:35.620 --> 01:12:37.410
Gil Friend • Sustainability OG • CxO Coach: It's okay. Quiet's okay.

625
01:13:00.870 --> 01:13:05.340
Jessie Upp DayBalancer.com: My mom 30 years ago, said.

626
01:13:06.900 --> 01:13:12.039
Jessie Upp DayBalancer.com: there will be one car version of a car, one version of of a house.

627
01:13:15.960 --> 01:13:19.980
Jessie Upp DayBalancer.com: And it's so weird because it kind of has come true.

628
01:13:21.190 --> 01:13:30.740
Jessie Upp DayBalancer.com: And I I almost feel like there's a sense that there is a a coming together.

629
01:13:31.620 --> 01:13:39.250
Jessie Upp DayBalancer.com: a converging property of both worlds.

630
01:13:40.800 --> 01:13:41.840
Jessie Upp DayBalancer.com: And

631
01:13:42.560 --> 01:13:50.120
Jessie Upp DayBalancer.com: it's it's it's an interesting thing to even look at in this. We are alive at this like change.

632
01:13:50.400 --> 01:13:52.640
Jessie Upp DayBalancer.com: and I feel so incredibly

633
01:13:54.280 --> 01:14:02.219
Jessie Upp DayBalancer.com: thankful that I'm in this transition. And I also, I'm like thinking, what is our what are our children going to do with this?

634
01:14:05.180 --> 01:14:07.780
Jessie Upp DayBalancer.com: We got to give them the right tools and

635
01:14:09.010 --> 01:14:12.359
Jessie Upp DayBalancer.com: and know how to use them properly. But

636
01:14:12.560 --> 01:14:18.160
Jessie Upp DayBalancer.com: what you know we have what 15 min left on the call, and I'm curious about

637
01:14:18.620 --> 01:14:22.300
Jessie Upp DayBalancer.com: our ability to focus and our ability to.

638
01:14:22.450 --> 01:14:30.120
Jessie Upp DayBalancer.com: you know, converge and diverge at the same time, and passing the baton on to our children, what what can we do?

639
01:14:33.210 --> 01:14:36.149
Jessie Upp DayBalancer.com: I think it's really going to have to come down to focusing

640
01:14:37.110 --> 01:14:42.899
Jessie Upp DayBalancer.com: and deciding how to work together versus in a decentralized fashion.

641
01:14:43.570 --> 01:14:49.430
Jessie Upp DayBalancer.com: I get on these calls for years. I listen to everyone's thing that they're working on.

642
01:14:50.010 --> 01:14:52.240
Jessie Upp DayBalancer.com: and I'm just confused.

643
01:14:52.925 --> 01:14:59.040
Jessie Upp DayBalancer.com: By. Why, we're not collaborating more effectively amongst this particular group.

644
01:15:01.150 --> 01:15:05.980
Jessie Upp DayBalancer.com: I'd like to challenge us to do that. It's not like we all have to work on the same thing.

645
01:15:06.990 --> 01:15:11.709
Jessie Upp DayBalancer.com: but we can generate a more collaborative approach

646
01:15:18.910 --> 01:15:23.140
Jessie Upp DayBalancer.com: just by even like sharing operational burden.

647
01:15:23.310 --> 01:15:27.049
Jessie Upp DayBalancer.com: because that seems like the biggest thing that has us.

648
01:15:27.240 --> 01:15:40.949
Jessie Upp DayBalancer.com: Our barriers to entry as you will can. Our own personal barriers to success is operational burden, and if we're all trying to do with the operations alone, the administrative costs, you know we could share some of that stuff.

649
01:15:42.970 --> 01:15:43.630
Klaus Mager: Hmm.

650
01:15:52.890 --> 01:15:55.300
Klaus Mager: Stacy, what place are you in right now?

651
01:15:59.230 --> 01:16:02.209
Stacey Druss: What place? What do you mean by the word place?

652
01:16:02.540 --> 01:16:05.569
Klaus Mager: From this conversation. Where did this put you.

653
01:16:13.390 --> 01:16:18.619
Stacey Druss: Honestly, I already have a membrane around me.

654
01:16:18.790 --> 01:16:27.700
Stacey Druss: Yeah, so it didn't put me anywhere. I'm I feel Jesse's frustration.

655
01:16:27.870 --> 01:16:32.410
Stacey Druss: I no longer let it affect me so. I'm kind of apathetic.

656
01:16:32.890 --> 01:16:33.300
Gil Friend • Sustainability OG • CxO Coach: Oh!

657
01:16:34.810 --> 01:16:35.500
Stacey Druss: Over.

658
01:16:36.940 --> 01:16:38.899
Stacey Druss: Thank you for asking, though.

659
01:16:47.940 --> 01:16:49.489
Gil Friend • Sustainability OG • CxO Coach: I liked the silence.

660
01:16:54.180 --> 01:16:58.849
Gil Friend • Sustainability OG • CxO Coach: And I'm reminded of Jerry's reminiscence reminiscences about Quaker meetings.

661
01:17:00.150 --> 01:17:04.300
Gil Friend • Sustainability OG • CxO Coach: But the silence sometimes goes on a long time until someone's moved to speak.

662
01:17:04.660 --> 01:17:08.950
Gil Friend • Sustainability OG • CxO Coach: So for me, it was very refreshing, because it's so rare

663
01:17:09.661 --> 01:17:13.349
Gil Friend • Sustainability OG • CxO Coach: in the online life that we share together.

664
01:17:14.930 --> 01:17:18.770
Gil Friend • Sustainability OG • CxO Coach: Jesse, I really appreciate what you said about

665
01:17:18.920 --> 01:17:23.709
Gil Friend • Sustainability OG • CxO Coach: the you know what you're feeling is the missed opportunities for collaboration among us.

666
01:17:27.310 --> 01:17:33.590
Gil Friend • Sustainability OG • CxO Coach: Let me say 2 things. I'm not drawn to what I think you're implying.

667
01:17:33.910 --> 01:17:37.139
Gil Friend • Sustainability OG • CxO Coach: because I'm full up on projects and don't need another project.

668
01:17:37.850 --> 01:17:58.029
Gil Friend • Sustainability OG • CxO Coach: and so don't want to take on a project for us to do together, particularly although I'm open to changing my mind if something amazing comes, you know, gets dropped on the table. But that's not what I'm looking for. On the one hand, on the other hand, I did an audit a few weeks ago of my online time, and it was ridiculous the amount of time I'm spending in Zoom Meetings of various kinds, and I've decided to prune them way down.

669
01:17:58.310 --> 01:18:00.130
Gil Friend • Sustainability OG • CxO Coach: And this is one that I'm keeping.

670
01:18:01.260 --> 01:18:06.539
Gil Friend • Sustainability OG • CxO Coach: So there's a kind of collaboration that this is that I really value, and that I'm committed to.

671
01:18:08.050 --> 01:18:17.159
Gil Friend • Sustainability OG • CxO Coach: This is one of 2, 2, or maybe 3 that are that are locked in, not to be, you know, not to be lost, and a lot of the others have gone away. So

672
01:18:18.380 --> 01:18:23.830
Gil Friend • Sustainability OG • CxO Coach: I feel that the sharing that we for me, the sharing that we do here is very collaborative and enriching.

673
01:18:24.120 --> 01:18:38.949
Gil Friend • Sustainability OG • CxO Coach: and you know I take notes, and I sometimes pull pieces of writing out of the things that we've talked about here. So I appreciate that. And I guess the 3rd thing, which is that maybe

674
01:18:39.120 --> 01:18:46.330
Gil Friend • Sustainability OG • CxO Coach: in in the 400 people that are on your platform. I don't know how many of them are Ogm people, but maybe we could all pop in there

675
01:18:46.550 --> 01:18:55.029
Gil Friend • Sustainability OG • CxO Coach: and do whatever profiling of needs and offers that you have. You know that you have receptor sites for

676
01:18:55.350 --> 01:18:57.490
Gil Friend • Sustainability OG • CxO Coach: and see if something emerges from that.

677
01:18:58.640 --> 01:19:00.900
Gil Friend • Sustainability OG • CxO Coach: and I'd I'd be willing to do that.

678
01:19:00.900 --> 01:19:06.930
Jessie Upp DayBalancer.com: I love that idea because we have quite a few on there. So let's definitely

679
01:19:07.460 --> 01:19:13.240
Jessie Upp DayBalancer.com: do that offline for sure, Gil, and also not doing the same project. I

680
01:19:13.750 --> 01:19:19.599
Jessie Upp DayBalancer.com: I live alone together with my. I'm getting married this Sunday. Been with my partner for 7 years.

681
01:19:19.600 --> 01:19:21.050
Gil Friend • Sustainability OG • CxO Coach: Congratulations.

682
01:19:21.050 --> 01:19:21.969
Gil Friend • Sustainability OG • CxO Coach: It's the rush.

683
01:19:23.640 --> 01:19:27.820
Jessie Upp DayBalancer.com: And we own our own homes, and we live apart together.

684
01:19:28.520 --> 01:19:35.990
Jessie Upp DayBalancer.com: I really see I live that. And I think that can be translated over to business

685
01:19:36.140 --> 01:19:42.000
Jessie Upp DayBalancer.com: and nonprofits where we're living. We're we're doing work alone together.

686
01:19:42.540 --> 01:19:43.080
Gil Friend • Sustainability OG • CxO Coach: Yeah.

687
01:19:43.080 --> 01:19:44.750
Jessie Upp DayBalancer.com: You have to be the same, but but it

688
01:19:44.750 --> 01:19:49.349
Jessie Upp DayBalancer.com: does need to have the same kind of operational excellence.

689
01:19:52.600 --> 01:20:05.350
Jessie Upp DayBalancer.com: and maybe some principles that that we all agree on. So that we continue to like, go back to that. And I think we can create. We have incredible brains here. I think we can create

690
01:20:05.480 --> 01:20:11.009
Jessie Upp DayBalancer.com: a small little Mondragon thing that ends up modeling something great.

691
01:20:11.620 --> 01:20:17.990
Gil Friend • Sustainability OG • CxO Coach: Jesse, I invite you, or maybe you and your pet AI to draft something very short

692
01:20:18.230 --> 01:20:21.740
Gil Friend • Sustainability OG • CxO Coach: about what working alone together might be.

693
01:20:22.830 --> 01:20:23.850
Jessie Upp DayBalancer.com: Hmm! I.

694
01:20:23.850 --> 01:20:38.879
Gil Friend • Sustainability OG • CxO Coach: I like the provocation of living alone together, working together. Yeah. So just spin it up a little bit more. Not a lot, not a manifesto like a paragraph. Okay, a sentence, 100 words. So something really tight that conveys the spirit of what you're carrying here.

695
01:20:40.120 --> 01:20:51.229
Mike Nelson: If if I can push back a little bit on Jesse, when when you say that we're not collaborating, I I find this to be a very collaborative space 5 min at a time.

696
01:20:51.460 --> 01:21:14.959
Mike Nelson: and I'm probably the one who abuses the wisdom of this crowd most, because I'm constantly saying, Hey, I'm doing a paper on this. Who are the 3 people I need to talk to? I think at the top of the hour I said, Hey, I'm going to Taipei and the Philippines, who knows something about the culture and the people? What is it that I have to really watch out for? If I

697
01:21:15.150 --> 01:21:17.339
Mike Nelson: want to have the full experience.

698
01:21:17.340 --> 01:21:17.990
Gil Friend • Sustainability OG • CxO Coach: My, my.

699
01:21:17.990 --> 01:21:25.380
Mike Nelson: It gets great feedback. The other thing that a true collaboration can do very effectively is.

700
01:21:25.870 --> 01:21:29.000
Mike Nelson: let people know when they're about to do something stupid.

701
01:21:29.250 --> 01:21:34.159
Mike Nelson: That's an incredibly source of feedback. And again.

702
01:21:34.160 --> 01:21:34.549
Gil Friend • Sustainability OG • CxO Coach: I mean.

703
01:21:34.550 --> 01:21:37.940
Mike Nelson: 5 min is often all it takes. Some of these check-ins.

704
01:21:37.940 --> 01:21:38.680
Gil Friend • Sustainability OG • CxO Coach: Yeah. No.

705
01:21:38.810 --> 01:21:47.859
Mike Nelson: Enabled me to say, Well, this is what I'm thinking, and I read this thing, which seems really good, and then somebody comes back and says, No.

706
01:21:47.860 --> 01:21:49.080
Gil Friend • Sustainability OG • CxO Coach: And Mike Mike.

707
01:21:49.080 --> 01:21:49.850
Mike Nelson: Year.

708
01:21:49.850 --> 01:21:56.940
Gil Friend • Sustainability OG • CxO Coach: You. You may think you're abusing this this space for me. You feed me every time, so thank you.

709
01:21:57.130 --> 01:22:20.070
Mike Nelson: Well, thank you, but I will continue to ask a few questions and get lots of great feedback. It's a great, a great form, but, as far as you know, getting everybody involved in one project, I think that's not what this group's for in my mind, speaking of creativity, it's Ken Homer, poem, Tom poem, time.

710
01:22:20.070 --> 01:22:20.770
Gil Friend • Sustainability OG • CxO Coach: Hmm.

711
01:22:21.090 --> 01:22:22.050
Klaus Mager: Yeah.

712
01:22:23.130 --> 01:22:25.479
Ken Homer • SF Bay Area: Or we should get somebody else to do it.

713
01:22:25.480 --> 01:22:30.830
Ken Homer • SF Bay Area: 5 min on the call, I mean, I'm happy to go. We're ready to end space to the folks.

714
01:22:30.830 --> 01:22:38.530
Doug Breitbart: I'd love to. I'd love to throw something in response to Jesse's call call to action. So

715
01:22:39.610 --> 01:22:41.729
Doug Breitbart: the challenge is I.

716
01:22:42.610 --> 01:22:45.690
Doug Breitbart: These are these are sort of the touch points.

717
01:22:45.930 --> 01:22:51.490
Doug Breitbart: The challenge to me is is the the lack

718
01:22:52.290 --> 01:22:56.230
Doug Breitbart: of a kind of universal interoperability.

719
01:22:58.900 --> 01:23:07.730
Doug Breitbart: You know it takes. It's taken several years for me as an individual

720
01:23:07.900 --> 01:23:20.020
Doug Breitbart: to get to apply, I'm add. So my executive function didn't kick into like 5 years ago. I'm coming up on 70. So like, I'm just beginning to be able to use tools that most normal mortals like

721
01:23:20.060 --> 01:23:44.639
Doug Breitbart: I've been using for decades to work with and coordinate with others, and each person has different aptitudinal dimensions. So one person is a gantt chart person, and that makes me like completely want to kill somebody, and I'm a gantt. You know, I'm a gantt, and they're a Kanban person. And like. So there's there's all of those technological

722
01:23:46.630 --> 01:23:55.500
Doug Breitbart: intangible diversities just between a group, you know people working together collaboratively on a thing.

723
01:23:56.410 --> 01:23:58.629
Doug Breitbart: and then you, then you have

724
01:23:59.410 --> 01:24:09.950
Doug Breitbart: varying degrees and levels of ego attachment to mine rather than transcendent of that

725
01:24:10.920 --> 01:24:21.769
Doug Breitbart: all for 1, 1 for all. Hey? I'm doing this, and I figured that out. And you're doing that. And you figure this out, you know you can learn from me, and I can learn from you, and we can, you know.

726
01:24:22.030 --> 01:24:29.980
Doug Breitbart: flow together to mutual benefit, and that sort of concatenates up into

727
01:24:30.220 --> 01:24:38.760
Doug Breitbart: different orgs, and different, you know, cooperatives working together, not

728
01:24:39.480 --> 01:24:43.759
Doug Breitbart: on the same thing, but being connected and flowing between.

729
01:24:44.720 --> 01:24:53.540
Doug Breitbart: and that that and and Stacey invoked the term membrane. And I think that's really, really on point, that

730
01:24:57.080 --> 01:25:05.559
Doug Breitbart: Circumstantially, people working together usually at the event horizon, that most of

731
01:25:05.830 --> 01:25:11.879
Doug Breitbart: that you're existing, that I'm existing that most of my clients and projects and partners are existing.

732
01:25:13.089 --> 01:25:16.320
Doug Breitbart: It's all we can do to keep doing us.

733
01:25:16.920 --> 01:25:27.699
Doug Breitbart: and that tends to form a membrane as boundary and limitation, based on time, based on resource, based on capacity

734
01:25:28.010 --> 01:25:39.660
Doug Breitbart: to do more, and making the membranes more porous, if not dissolving them all together

735
01:25:40.400 --> 01:25:42.900
Doug Breitbart: has a lot to do with ownership

736
01:25:43.060 --> 01:25:52.410
Doug Breitbart: and and transcending the ownership meme transcending the mind, and and

737
01:25:52.740 --> 01:25:57.909
Doug Breitbart: the most liberating and powerful thing in connection with that

738
01:25:58.990 --> 01:26:04.210
Doug Breitbart: that it took for me to lose that completely

739
01:26:04.310 --> 01:26:06.810
Doug Breitbart: with severing the quid pro quo

740
01:26:07.300 --> 01:26:15.120
Doug Breitbart: something for something. I don't offer my services on a transactional basis.

741
01:26:15.700 --> 01:26:20.890
Doug Breitbart: If somebody knocks and I can help, and it's in my spot, then I'm in service, too.

742
01:26:21.930 --> 01:26:40.460
Doug Breitbart: and how I meet my needs is my own business, my own inquiry, and I live based on an appreciation economy. So people that appreciate me whether it's being in the world or whether it's helping them directly with a thing, or whether it's whatever you know

743
01:26:40.890 --> 01:26:43.579
Doug Breitbart: it comes from them going, you know

744
01:26:43.860 --> 01:26:51.760
Doug Breitbart: I really value, appreciate you. Thank you for your help. And how can I reciprocate? That's not a transaction.

745
01:26:53.260 --> 01:26:55.540
Doug Breitbart: It's a whole different orientation.

746
01:26:55.680 --> 01:27:00.889
Doug Breitbart: And what it's what it did. Was it freed me of

747
01:27:01.260 --> 01:27:12.139
Doug Breitbart: ownership, and it freed me of scarcity and and fear, and worrying about being in service.

748
01:27:13.910 --> 01:27:17.370
Doug Breitbart: and and that transcending that

749
01:27:18.880 --> 01:27:21.940
Doug Breitbart: is not for the weak of heart and the common man

750
01:27:22.540 --> 01:27:27.499
Doug Breitbart: in the system we're living in. It is really really hard for people

751
01:27:27.930 --> 01:27:34.470
Doug Breitbart: to let go of the fear and the scarcity and the concern about, how am I, gonna

752
01:27:34.810 --> 01:27:36.310
Doug Breitbart: you know, survive?

753
01:27:37.630 --> 01:27:46.359
Doug Breitbart: And I think that's the biggest opera in preventing the kind of open flow that you're inviting.

754
01:27:47.160 --> 01:27:54.270
Doug Breitbart: But I'm in support of. I'm a card carrying believer, member of that, and and

755
01:27:55.370 --> 01:27:57.679
Doug Breitbart: I'm down. You can count me in.

756
01:28:00.110 --> 01:28:00.760
Jessie Upp DayBalancer.com: You talk.

757
01:28:00.990 --> 01:28:17.490
Klaus Mager: Thank you. I think we all have been on a journey. How long have we been doing this? I was there from the start. Gene actually connected me with this Jerry. And that's been about 6 years, I mean, how long have we been doing this?

758
01:28:18.240 --> 01:28:38.899
Klaus Mager: And and I think we've all been on a journey, I mean, I most so most certainly had an opportunity to go because of all the connections within. Ogm. So I'm like, you know, hugely thankful and just like gilt. You know, this is the one item that's on my on my calendar, you know. That's the one meeting I don't want to miss.

759
01:28:39.280 --> 01:28:43.580
Klaus Mager: Okay? Ken, yeah, I think we're ready for for you.

760
01:28:44.940 --> 01:28:48.689
Ken Homer • SF Bay Area: Hey? This is a poem called American Funeral, by Greg Kimura.

761
01:28:49.470 --> 01:28:53.050
Ken Homer • SF Bay Area: He sits in a raft in a river with no water

762
01:28:53.230 --> 01:29:02.680
Ken Homer • SF Bay Area: that winds through sandstone canyons and green valleys. Before passing through the gates of heaven, the old raft, a sunken coat of flesh

763
01:29:02.950 --> 01:29:09.830
Ken Homer • SF Bay Area: that once ripped up huge chunks of Stanford Stadium turf at left tackle class of 1949

764
01:29:09.990 --> 01:29:20.400
Ken Homer • SF Bay Area: that once built tuna fish sandwiches for church youth, groups that made sloppy, wet love to an appreciative life now lays boxed in the ground.

765
01:29:20.530 --> 01:29:23.390
Ken Homer • SF Bay Area: but he sits alone in a raft, waiting

766
01:29:23.830 --> 01:29:47.990
Ken Homer • SF Bay Area: waters that could have carried him down the river, lie locked inside Protestant bodies, maintaining an unfortunate sense of dignity, decorum, and strength. Oceans of roiling grief sit in the pews requiring release. But we have forgotten how to do this in the old days we knew how to prepare and anoint the old raft for its journey.

767
01:29:48.180 --> 01:29:53.099
Ken Homer • SF Bay Area: knew how to create the ritual that released the sacred storms that sent him on his way.

768
01:29:53.530 --> 01:30:10.460
Ken Homer • SF Bay Area: and as much as he needed our tears and as much as we needed to weep. But today our grief lies embedded in our bodies, and we carry them out into the world, where they come out later in ways not so elegant or beautiful or as necessary as tears.

769
01:30:10.570 --> 01:30:15.030
Ken Homer • SF Bay Area: and he sits in a raft in a river with no water.

770
01:30:15.770 --> 01:30:16.390
Klaus Mager: Hmm.

771
01:30:16.990 --> 01:30:17.590
Doug Breitbart: Hmm.

772
01:30:19.760 --> 01:30:22.017
Klaus Mager: Thank you. Everybody.

773
01:30:22.770 --> 01:30:23.150
Doug Breitbart: Thank you.

774
01:30:23.430 --> 01:30:31.192
Mike Nelson: And Klaus, thanks for rising to the occasion and providing the little bit of glue that makes one of these discussions work.

775
01:30:32.070 --> 01:30:34.270
Klaus Mager: Thank you. Alright!

776
01:30:34.270 --> 01:30:34.889
Jessie Upp DayBalancer.com: Thank you.

777
01:30:34.890 --> 01:30:35.470
Stacey Druss: Bye.

