WEBVTT

00:00:00.000 --> 00:00:03.000
Good. Um, let me turn on the recorder devices.

00:00:03.000 --> 00:00:08.000
This is the Open Global Mind weekly call for Thursday, September 4th, 2025.

00:00:08.000 --> 00:00:13.000
On the first 30 days of every month, we do a check-in call, where we have.

00:00:13.000 --> 00:00:20.000
Funky little check-in routine that I think most everybody… I think everybody who's here has done before, but I'll just repeat it briefly.

00:00:20.000 --> 00:00:28.000
I am not going to be a traffic cop during check-in. Everybody just sort of volunteers to step forward and check in only once, please, no comments back and forth.

00:00:28.000 --> 00:00:36.000
Uh, we have a moratorium on chat while we're checking in, so please don't use the chat, but you can save stuff in your chat, just don't hit enter.

00:00:36.000 --> 00:00:43.000
Um, and then once everybody's gone once, I'll step in and we'll go to usual sort of salon mode.

00:00:43.000 --> 00:00:55.000
And then, free-for-all in the chat is okay. Um, during check-in mode, we like pauses, so quiet moments are not awkward moments, they're moments like quicker meeting, where you're appreciating.

00:00:55.000 --> 00:01:00.000
The moment, or the people, or the setting, or whatever you'd like to appreciate.

00:01:00.000 --> 00:01:06.000
Uh, that works great. That's one of the reasons we developed this check-in mode, was to have some quiet.

00:01:06.000 --> 00:01:22.000
Even while we're busy, like, Zooming and all that. And, um… And don't empty your brain of everything that's on your mind. Try to be moderately brief so that we can get through check-ins and get to conversations, so…

00:01:22.000 --> 00:01:35.000
Check in on something sort of OGM-y that's in your head, that's, uh… that's with you, um… But don't tick off, like, the list of things you've banked for the week that you wanted to tell everybody at OGM about. That's a little…

00:01:35.000 --> 00:01:41.000
Usually that's a little too long. With that, I'm going to mute my mic.

00:01:41.000 --> 00:01:47.000
And whoever would like to, uh, can step in. And, uh, we'll be off and running.

00:01:47.000 --> 00:01:53.000
Rick, do you have a thought… thought? Or a question?

00:01:53.000 --> 00:02:06.000
Nope, I just heard some noise from your mic. Sean, I just explained the check-in routine, which I think you're familiar with, correct?

00:02:06.000 --> 00:02:15.000
Not hearing Sean yet, but we shall see. Um, alright, I will mute, and whoever would like to go first, take your time.

00:02:15.000 --> 00:02:45.000
And, uh, go first.

00:02:49.000 --> 00:02:54.000
Well, I'll go. People on this list know.

00:02:54.000 --> 00:03:02.000
Was in the heart of Helene in Suwanoa. Which was the part of the impact.

00:03:02.000 --> 00:03:08.000
And we gave up on FEMA and have moved to an apartment in the River Arts District.

00:03:08.000 --> 00:03:15.000
But, um… And my kids might be able to create what they want out of the.

00:03:15.000 --> 00:03:23.000
Land that's behind, but we can't think about it. But I met this morning with a woman who leads the.

00:03:23.000 --> 00:03:30.000
The outside, the safety net. Work. Uh, she got some funding, and they have.

00:03:30.000 --> 00:03:42.000
7 people that work with Suanova Cares. A lot of Latinos, 3 of them used to clean Airbnbs, but they were community leaders, and now they're paid to be.

00:03:42.000 --> 00:03:55.000
Sort of social workers in that space, and I… but it was great, because I wanted to know… so she finally had to give up and take a couple weeks in the south of France and get away from the sadness.

00:03:55.000 --> 00:04:02.000
Our devastation remains, and we're a low-status neighborhood, and they're not doing anything. And the county.

00:04:02.000 --> 00:04:08.000
And nothing is happening. And, um…

00:04:08.000 --> 00:04:14.000
So, but she went back to it, and so I wanted to meet with her and say, how are you doing this?

00:04:14.000 --> 00:04:17.000
She explained that's who she is, and it turns out that.

00:04:17.000 --> 00:04:26.000
There is some money to create a third place. And some of that is coming into here, and I can help her.

00:04:26.000 --> 00:04:30.000
Organize the capital around. You know, she has a nail salon, and there's.

00:04:30.000 --> 00:04:38.000
The renting a quick stop, and, you know, there is no place people gather. Eleanor Offeram said.

00:04:38.000 --> 00:04:45.000
If… watersheds can be managed 47% better by ranchers than by the government.

00:04:45.000 --> 00:04:55.000
If they have a place where they meet regularly and have informal conversations, and the… not treaties, but the… the…

00:04:55.000 --> 00:05:06.000
The relationships up and downstream are transparent. And we have nothing like that. There's no grocery store, it's gone, the post office is gone, the hardware store is gone, all the restaurants are gone. So.

00:05:06.000 --> 00:05:16.000
Creating that, and then trying to stop the land rush of folks, you know, we're the… before the flood, we were $100,000 less per house.

00:05:16.000 --> 00:05:27.000
And we were, uh, $300 less per rent. And so, um… Anyway, it's really neat to… there's a certain place I can be.

00:05:27.000 --> 00:05:32.000
Working with the people, working with the people with the problems, but if I'm down there, I'm really terrible.

00:05:32.000 --> 00:05:38.000
And can't stand the sadness. She can stand the sadness, and so it was really encouraging.

00:05:38.000 --> 00:05:48.000
That, you know, oh, there's a place for me to be able to look at someone else, because I, you know, it's… We lost a million bucks on the land and house, and so…

00:05:48.000 --> 00:05:57.000
It's hard to think about, but um… It's a way to think about it, and I'm going to work on a thing with my kids, and so…

00:05:57.000 --> 00:06:04.000
I'm really glad to not be immersed in that sad place. We're in the arts district, and the artists.

00:06:04.000 --> 00:06:11.000
Are determined to. Work in these live-work lofts and sell, and so they're…

00:06:11.000 --> 00:06:16.000
Coming back in the places that weren't totally flooded, and it's not sad.

00:06:16.000 --> 00:06:24.000
And with these trauma areas, you just… you know, some people can be around the sad for a long time and live with it, and I couldn't do it.

00:06:24.000 --> 00:06:35.000
So anyway, it's a little bit encouraging, even though, uh. It's a neglected, low-status area, and people have forgotten about Helene.

00:06:35.000 --> 00:06:46.000
But, you know, nobody relies on the federal government anymore, so… We have that, but there are ways to invest without the federal government, uh, through.

00:06:46.000 --> 00:06:59.000
Community investment funds in land, so we're looking to… It's just great to, you know, I can actually think about doing what I do without having to be down in where it's… it's just too sad to go.

00:06:59.000 --> 00:07:29.000
To where I used to live, because it. You know, gardens covered by sand dunes.

00:07:52.000 --> 00:08:00.000
Not to respond to Kevin, but, um… Kevin, hearing what you said reminds me of stories I've seen this week about New Orleans.

00:08:00.000 --> 00:08:08.000
Uh, and how… And how much has not been recovered.

00:08:08.000 --> 00:08:17.000
Since their devastation, what, 10 years ago now? 20. Cheaper. 20.

00:08:17.000 --> 00:08:18.000
Mm-hmm.

00:08:18.000 --> 00:08:25.000
20. Yeah. Low-status neighborhoods, after the emergency stuff. Leaves are still low status. You know, that's the thing. It's the low status that doesn't change.

00:08:25.000 --> 00:08:26.000
Um, we're trying to prevent conversation during this part of check-in.

00:08:26.000 --> 00:08:29.000
Yeah. So there's…

00:08:29.000 --> 00:08:30.000
Alright, but… But I appreciate this.

00:08:30.000 --> 00:08:31.000
Right, yeah, anyway, yeah. Low status remains.

00:08:31.000 --> 00:08:35.000
We're not… we're not… we're not conversing, we're just sharing observations.

00:08:35.000 --> 00:08:45.000
But, yeah. Um… A friend of mine from me, besides… well, I guess I'll say two things.

00:08:45.000 --> 00:08:52.000
At the national level, I'm really struck by the conversation of people who say.

00:08:52.000 --> 00:09:06.000
It's all over, nobody's doing anything. Quote, nobody's doing anything, it's a meme that I hear a lot. And in fact, there's lots of people doing lots of stuff, and various, you know, Heather Cox Richardson and others are chronicling that.

00:09:06.000 --> 00:09:15.000
Um, I'm… glad to see… glad to see the state's rights focus shifting to the blue states now, as Washington, Oregon.

00:09:15.000 --> 00:09:22.000
California, Illinois, and so forth are starting to mount. A different level of resistance.

00:09:22.000 --> 00:09:30.000
Um, in personal terms, it's been a… it's been a very body-focused week for me this week. I fell on Sunday and, quote, sustained a concussion.

00:09:30.000 --> 00:09:38.000
As they say. Yeah, and I'm okay. It was mild. Um, you know, no cracks in my head, no bleeds, etc.

00:09:38.000 --> 00:09:46.000
I learned that if you're over 65 and you fall, or if you're on auto… if you're on anticoagulants and you fall, you go to the ER, period, even if you feel fine.

00:09:46.000 --> 00:09:57.000
So, learned that one. But the protocol, there's a concussion is not a clinical diagnosis, it's a… it's a, you know, symptomatic diagnosis, and the deal is that you have to rest.

00:09:57.000 --> 00:10:00.000
Uh, and if you don't rest, your body will enforce the rest.

00:10:00.000 --> 00:10:11.000
Um, and the major advisory is to stay off screens. Uh, and mental stimulation, which screens for a vivid kind, because there's lots of sensory input, and man, that's hard to do!

00:10:11.000 --> 00:10:19.000
In this modern life. You know, so I've… I've done it a lot, and I'm much more… much less engaged, but it's hard…

00:10:19.000 --> 00:10:26.000
For me, it's hard to be completely unplugged. Um, I had a fairly busy day Tuesday, um…

00:10:26.000 --> 00:10:41.000
Lots of coaching, and coached a client on an acquisition, and coached a client on a career development, and coached a client on, um… product launch and new positioning for companies, like, you know, engaged on the calls, full-on, full presence.

00:10:41.000 --> 00:10:50.000
And then just wiped out afterwards. Just, like, wiped out. Yeah, you know, just have to sit down for a couple hours and close my eyes and not do anything, which is…

00:10:50.000 --> 00:10:56.000
I noticed that my normal recourse when I relax. Is to pick up this thing and scroll.

00:10:56.000 --> 00:11:07.000
It's like, nope, don't do that. So it's been very, very humbling and grounding, in a way, to just sort of be back in touch with the rhythms of the body and learn how that works, and um…

00:11:07.000 --> 00:11:14.000
Um… there was some conclusion about that. Um…

00:11:14.000 --> 00:11:19.000
Yeah, just, you know, running at a very different pace this week.

00:11:19.000 --> 00:11:36.000
So, that's… that's what I have to say for now.

00:11:36.000 --> 00:11:45.000
So I can, uh, I can jump in, go next. Um… I think many of you know that I'm not on these calls too much. I typically have a work.

00:11:45.000 --> 00:11:56.000
Meeting that, uh, canceled today to be able to join, and uh… I live in Washington, D.C, and it feels like…

00:11:56.000 --> 00:12:00.000
Um, there's some people paying attention to what is going on.

00:12:00.000 --> 00:12:04.000
Uh, in DC, but I also feel like since Elon has left.

00:12:04.000 --> 00:12:14.000
Sort of a side effect of him in not engaging is some of the attention that he… maybe… maybe some of the outrage that he drew.

00:12:14.000 --> 00:12:21.000
Is it's not there as much when they're just continues to be, you know, thing after thing after thing after thing, attacks.

00:12:21.000 --> 00:12:25.000
Um, what I would call a tax on the federal government.

00:12:25.000 --> 00:12:34.000
People that have given their lives, careers to… government service, whether those services are delivered.

00:12:34.000 --> 00:12:45.000
Uh, you know, to the levels that we all want is another story, but these people are… you know, putting their heart and soul into the missions of the government.

00:12:45.000 --> 00:12:53.000
You guys may not know that there's a government shutdown coming at the end of September, and most people think that the government will shut down.

00:12:53.000 --> 00:13:09.000
Uh, just because it's such a heightened political… environment. Um, there's a couple of options that could happen. One could be a partial shutdown, where they figure out budgets for certain agencies, or it could be a complete shutdown.

00:13:09.000 --> 00:13:17.000
Of course, even with a complete shutdown, people that are deemed, or positions, or roles, or missions that are deemed essential.

00:13:17.000 --> 00:13:22.000
Keep working, so then there's this whole process of figuring out who should get the label of essential.

00:13:22.000 --> 00:13:26.000
And then, what are those rest of the people, like, hey, you're not essential?

00:13:26.000 --> 00:13:36.000
Banks, um… So, our company does consulting for the federal government so that, uh, potentially will be an impact for us, but.

00:13:36.000 --> 00:13:46.000
But probably not, uh, for reasons I won't go into. Um, on a personal note, my daughter is entering her sophomore year at NYU.

00:13:46.000 --> 00:13:53.000
And so we dropped her off, uh, she is in film school, uh, which, on the one hand, is like, um.

00:13:53.000 --> 00:14:07.000
You know, top jobs that will be replaced by AI, although I'd say that in jest because… and she and I had talked about this, and I said the… The world needs storytellers, and whether you're using AI tools or…

00:14:07.000 --> 00:14:20.000
You know, holding a camera, or painting with a brush, you know, that there's still… there's still… room and needs for storytelling, and I think at some point, I think most of us think there'll be a…

00:14:20.000 --> 00:14:29.000
Um… what's the word? Appreciation for authentic art. I think even already we're getting so sick of.

00:14:29.000 --> 00:14:43.000
Ai-generated stuff, so I think, uh, I'm excited. I think she'll be at… if her current interests continue, she'll be a documentarist, uh, so that… that will be interesting. She's interested in all kinds of things.

00:14:43.000 --> 00:14:55.000
Um, interesting, as a film… school student, she watches very few movies, um, so she loves Broadway shows, she loves being in the theater, um, she watches.

00:14:55.000 --> 00:15:02.000
Some episode TV, um, but not a lot of long-form movies, which I think is kind of interesting.

00:15:02.000 --> 00:15:12.000
Um, so I'm dropping her off in New York City, we're there, uh, we're there, uh, periodically through the year, and just reminded the energy level of New York.

00:15:12.000 --> 00:15:20.000
Is just unmatched. The people mixing in all walks of life, all economic statuses commingled.

00:15:20.000 --> 00:15:32.000
Um, instructed me about DC. Which has been labeled as this crime-ridden city, which it's not. Uh, New York, uh, gets similar labels.

00:15:32.000 --> 00:15:45.000
And I think people that are outside these cities. Just hear the headlines, and they just buy the headlines, and that's just sort of been something I've been thinking about. Certainly, there are…

00:15:45.000 --> 00:15:56.000
Crime… high crime areas of every city, but there's also. Concentrations of artists and musicians and restaurants and food and creativity, so…

00:15:56.000 --> 00:16:01.000
Um, as with everything in life, it's a mixed… it's a mixed bag.

00:16:01.000 --> 00:16:08.000
Um… So yeah, I think for me, I just continue to try to…

00:16:08.000 --> 00:16:31.000
Limit sources, you know, feeds of information, try to be more selective, pick and choose the things that I want to ingest, and then try to reflect on them, and… and see what… try to… try to have clarity on my views of topics and things that are not just headline… headline-driven.

00:16:31.000 --> 00:17:00.000
Um… So yeah, I think I'll, uh, I'll wrap it up there.

00:17:00.000 --> 00:17:08.000
Yeah, maybe I… I'll follow. Um, I've been, um…

00:17:08.000 --> 00:17:14.000
So focused on the, uh, on the foot part of the economy.

00:17:14.000 --> 00:17:20.000
And, you know, pretty much on a meta level, because I've worked.

00:17:20.000 --> 00:17:29.000
I'm on the, uh… advisory team for federal policy for the Sierra Club, for example, now Farm Bill Policy, and…

00:17:29.000 --> 00:17:38.000
The citizen climate lobby, and uh… Um, the ALQA organization, so I've been, uh.

00:17:38.000 --> 00:17:52.000
Closely tracking, you know, what is happening policy-wise. And… and try to… to have some influence on this and provide, you know, some, some…

00:17:52.000 --> 00:18:02.000
Feedback that, um, hopefully is helpful, but… So from that position, I've stepped way back, because I'm just…

00:18:02.000 --> 00:18:08.000
Feeling, um, it's a complete waste of time. The Sarah Club.

00:18:08.000 --> 00:18:20.000
Team to Washington, lobby team, and you talk to. Members of Congress who just cashed a half-million dollar check from some lobbyist, and then the sales rep shows up, and.

00:18:20.000 --> 00:18:25.000
Have an opinion, you know what I mean? It's just… it's just, uh, hopeless.

00:18:25.000 --> 00:18:34.000
Um, but what really strikes me is… the… the destructiveness of this current administration.

00:18:34.000 --> 00:18:43.000
Um, because the food system is a massive contributor to environmental degradation.

00:18:43.000 --> 00:18:51.000
Um, not just… not just carbon emissions, but the… not the… pollution of water tables.

00:18:51.000 --> 00:18:57.000
Of watersheds, or chemicals, uh, overloading the natural environment. I mean, it's just a horror show.

00:18:57.000 --> 00:19:05.000
Um, and the scale of it is absolutely incredible, and the scale is increasing. I mean, they're doubling down on.

00:19:05.000 --> 00:19:10.000
On these practices that are so… that are so harmful to.

00:19:10.000 --> 00:19:19.000
The entire, uh, ecology, the, you know, the, uh… biode system.

00:19:19.000 --> 00:19:25.000
So, I've been working with AI now to build up an intelligence.

00:19:25.000 --> 00:19:35.000
That, uh, that can assist, you know, to, uh. To create a transition from.

00:19:35.000 --> 00:19:46.000
From this current industrial system. Into a more regenerative form of functioning.

00:19:46.000 --> 00:19:55.000
You know, generating food and calling and raising food. Um, and because of, you know, my background, um.

00:19:55.000 --> 00:20:02.000
I… and… and, you know, some… really training I got with Jean, working with Jean Bellingsher for the last…

00:20:02.000 --> 00:20:12.000
6 years or so, and I'm really thinking through… Uh, on… on what this all means from a systems perspective.

00:20:12.000 --> 00:20:18.000
You know, from the farmer to the consumer, and the entire.

00:20:18.000 --> 00:20:22.000
Supply chain in between. You know, the AI.

00:20:22.000 --> 00:20:29.000
That we have, you know, I'm not allowed to say training, but configured, was actually a funny thing.

00:20:29.000 --> 00:20:42.000
My AI objected to me, saying that I'm training it. No, no, you are… this is a configuration process, not a training process. Okay, fine, whatever, but…

00:20:42.000 --> 00:20:50.000
We… I mean, I have… you know, configured now 6 agents that.

00:20:50.000 --> 00:20:59.000
Starting this to farmers, that are going through… the moving… moving product from the farm.

00:20:59.000 --> 00:21:03.000
To the… to the market, and then the market and so on anyway.

00:21:03.000 --> 00:21:13.000
It's, uh, it's a… it's a total systems reconfiguration process. And it's very difficult to get traction, because the…

00:21:13.000 --> 00:21:20.000
The, uh, regenerative movement is so splendid, you know, you have so many groups everywhere doing something.

00:21:20.000 --> 00:21:29.000
And they're all doing good work, but… It's not scalable, it's self-contained, it doesn't share.

00:21:29.000 --> 00:21:36.000
You know, learnings in an organized fashion. So that's, you know, where I've been…

00:21:36.000 --> 00:21:48.000
Hoping to, to, to engage. Because the AI that… the way this thing can work is.

00:21:48.000 --> 00:21:58.000
That you don't need to have, like, a massive database. If we can get anybody who wants to work within the regenerative frame.

00:21:58.000 --> 00:22:10.000
To just use a few key words in their website, you know, in their, in their… materials, the AI will find you, right? So if we are working within, let's say.

00:22:10.000 --> 00:22:17.000
A bioregion. Let's say a community high desert of bends, or anywhere, really.

00:22:17.000 --> 00:22:25.000
Um, anyone who wants to participate just needs to, say, put some keywords out there.

00:22:25.000 --> 00:22:37.000
And the AI will find you, know what you're doing. So anyway, I'm… I finally got our first project here. It's a group called Aqua Regenerations.

00:22:37.000 --> 00:22:44.000
Um, I'm… I'm… Hopefully not violating any rules here, Jerry, but here is the…

00:22:44.000 --> 00:22:48.000
The group that we're working with, so we actually have our kickoff meeting later today.

00:22:48.000 --> 00:22:57.000
Um, they already… this is another scrappy startup. Um, they are highly ambitious in a way of, uh.

00:22:57.000 --> 00:23:03.000
Creating tools to assist small farmers, and they are headquartered in Kenya.

00:23:03.000 --> 00:23:10.000
They currently have 40 locations, uh. With groups of farmers signed up.

00:23:10.000 --> 00:23:19.000
And, uh, we decided to partner where I provide the back of house, uh, the intelligence system.

00:23:19.000 --> 00:23:25.000
Also my own skill set, really, because I need to guide them into.

00:23:25.000 --> 00:23:33.000
What type of data they need to source from these farmers and from the farm support, uh, supporting.

00:23:33.000 --> 00:23:46.000
Corpse, so that we can then work with this, but… Um, it's… it's a, you know, a generative system transformation. They are… they are appealing to the United Nations and to.

00:23:46.000 --> 00:23:55.000
I mean, corpse linked to the UN and others to, uh… get funding, so we are, you know, doing a joint funding launch.

00:23:55.000 --> 00:24:09.000
So we'll see where that goes, but… The… the challenge that I see, really, is that the industrial sector, where the money really sits, is doubling down and doing the same damn thing.

00:24:09.000 --> 00:24:16.000
Just with more emphasis. You know, did you see the same thing that you see in the energy sector?

00:24:16.000 --> 00:24:20.000
Where they're cutting out mint and solar and batteries and all.

00:24:20.000 --> 00:24:30.000
You see the same in food now. Where we are saying you need to stop taking… using these GMO seeds, you need to stop using all these chemicals to grow food.

00:24:30.000 --> 00:24:39.000
And they're doing the opposite and tapping down on it. So, I don't know, it seems to be…

00:24:39.000 --> 00:24:53.000
It seems to be, you know, a tough slug to convince people to… to join. I'm trying to get something launched here in my own backyard that I… in the high desert of Bend.

00:24:53.000 --> 00:25:04.000
Uh, and, you know, I'm… I'm connected now with some people who retired here. There's one guy who stepped up into our advisory team.

00:25:04.000 --> 00:25:16.000
Uh, he's a retired Salesforce executive, and it was pretty high up in Salesforce, and… You know, he has, you know, looked at what we're doing, and he wants to help us to launch.

00:25:16.000 --> 00:25:24.000
Uh, and get organized, so… The story resonates, you know, we have, um…

00:25:24.000 --> 00:25:30.000
Being able to… to, uh, to get…

00:25:30.000 --> 00:25:39.000
Now, folks interested in doing it, but the people who are on the ground and who are working, they intensely.

00:25:39.000 --> 00:25:44.000
On a day-to-day basis, have a very difficult time to see how they can integrate with us.

00:25:44.000 --> 00:25:59.000
Um, and how that would make sense. So, um, it's… I mean, it's extremely disturbing, you know, to watch this political process, because it's just so painful to, uh…

00:25:59.000 --> 00:26:06.000
To see the damage these guys are doing, you know, to, uh, on a civilizational level, uh.

00:26:06.000 --> 00:26:16.000
And how… how there is just no collective response. I mean, it's just…

00:26:16.000 --> 00:26:27.000
Scattered opinions and scattered efforts, community-based. Nothing that has… any chance of scaling so far?

00:26:27.000 --> 00:26:43.000
Yeah, so anyway, that's where I'm at.

00:26:43.000 --> 00:26:45.000
Yeah, I'd like… go ahead, Sean, go ahead.

00:26:45.000 --> 00:26:48.000
Oh, no, no, go ahead, go ahead.

00:26:48.000 --> 00:26:59.000
Um, there are two themes that I want to touch on. One was Kevin, about what's happening in Asheville in terms of the inequities.

00:26:59.000 --> 00:27:08.000
The systemic inequities that are baked into the system. And Klaus, you were talking a moment ago about the fact there, you know, within the.

00:27:08.000 --> 00:27:16.000
Regenerative movement. There's splintered. I don't think that splintering is unique to that movement, it's all over the place.

00:27:16.000 --> 00:27:21.000
And that's part of the problem of, uh, bringing people together.

00:27:21.000 --> 00:27:27.000
To take on the systemic psychopathy that we're living through, and the systemic prejudice.

00:27:27.000 --> 00:27:33.000
Against equity, um, you know, people have heard me talk about this before, about equity meta governance.

00:27:33.000 --> 00:27:40.000
As a way of thinking about how to bring people together over the process rather than the content.

00:27:40.000 --> 00:27:46.000
You know, so much content out there that, uh, we're not very good at handling the process of the content.

00:27:46.000 --> 00:27:51.000
Unless we've session on sense-making, the thing that came up for me.

00:27:51.000 --> 00:27:57.000
Was the notion of co-intelligence. And two nights ago, I decided to take the plunge.

00:27:57.000 --> 00:28:05.000
And, uh, spend $200 for one month. On Perplexity AI to see whether it's really worth.

00:28:05.000 --> 00:28:14.000
Getting access. To the additional resources that you might be able to do through it, because I'm fascinated about the whole issue of co-intelligence.

00:28:14.000 --> 00:28:19.000
And, um, you know, I remember a while back, Scott, if he's listening.

00:28:19.000 --> 00:28:24.000
Um, you know, looked at one of my questions and says, oh, it's too complex, and, you know, he sort of.

00:28:24.000 --> 00:28:32.000
Thought about it, whatever. And, you know, one of the things that I've, um… I've become really interested in is how.

00:28:32.000 --> 00:28:39.000
How we can actually… there is a sort of, um… I'm gonna exaggerate this for the sake of making a point.

00:28:39.000 --> 00:28:48.000
That we're actually living with the, um, the… the… the cult indoctrination of a KISS principle.

00:28:48.000 --> 00:28:56.000
And I've mentioned that the KSSS principle before, in terms of keeping sophistication, this side of simplicity, and we talked about this last time, Kraus.

00:28:56.000 --> 00:29:03.000
Although, I think the integral framework is incredibly useful, but I think literacy level, comprehension level, is adequate.

00:29:03.000 --> 00:29:08.000
If you want to go in the spiritual domain, absolutely, it's a useful framework for thinking about.

00:29:08.000 --> 00:29:14.000
Different levels of consciousness, but in terms of trying to bring people together.

00:29:14.000 --> 00:29:24.000
Um, I mean, I think that's the biggest challenge. Anyway, this is a bit of a pop query of comments here, because on Labor Day, I went to the Labor Day parade.

00:29:24.000 --> 00:29:35.000
And a friend of mine was actually carrying the flag. Of the Dems, and… you know, uh, Mark Kelly was supposed to be in the, you know, doing an event there.

00:29:35.000 --> 00:29:43.000
Uh, with them. And I joined him, I put my hand around him, he says, hey, where's Mark Kelly? He says, he's over there. And I said, okay.

00:29:43.000 --> 00:29:50.000
I went over and had a chat with him. Uh, which is a re… you know, just an opportunistic thing.

00:29:50.000 --> 00:29:58.000
And I spoke with him, and he put me in contact with his administrative assistants, and I said, I've got some ideas, are you open to them? He says, yeah, here's my administration.

00:29:58.000 --> 00:30:01.000
So anyway, I just got a text message back from the administrative.

00:30:01.000 --> 00:30:09.000
Assistant saying he's going to share what I, um… had worked on. And, um…

00:30:09.000 --> 00:30:20.000
So, you know, um, you know, people say I haven't been listening to the fact that people are saying the same things. I have been listening, actually, but… You don't know how deeply I've been listening.

00:30:20.000 --> 00:30:24.000
Or how I'm responding to it, because I haven't had a response to do it.

00:30:24.000 --> 00:30:29.000
So, uh, when… when we go, uh, open, I can share, uh.

00:30:29.000 --> 00:30:33.000
I did a deep dive using Perplexity, looking at this whole phenomena.

00:30:33.000 --> 00:30:41.000
Of, uh, this KISS indoctrination that we're… entrapped with, and it's a splintering reductionist framework.

00:30:41.000 --> 00:30:50.000
That makes it very difficult to deal with, uh, complexity. Um, and so it goes against the grain, and we have to have new learning methods.

00:30:50.000 --> 00:30:55.000
To be able to actually get people to collaborate across the divisions.

00:30:55.000 --> 00:31:02.000
And I think I mentioned I'm involved in… I've backed off of working with Indivisible because.

00:31:02.000 --> 00:31:12.000
They're suffering with the same problem. They're divided. They can't get their act together either, and they're not good at having conflict. They don't know how to have healthy disagreement.

00:31:12.000 --> 00:31:17.000
And some of the most successful change moves are the ones that actually.

00:31:17.000 --> 00:31:21.000
Work it out. The fact that there is huge differences within.

00:31:21.000 --> 00:31:28.000
The sort of progressive movement. You have to work it out, but people get so wrapped up in their little…

00:31:28.000 --> 00:31:36.000
Rabbit holes that they start, you know, um, squabbling amongst themselves in a way that doesn't advance the course. Anyway.

00:31:36.000 --> 00:31:43.000
So, um, I just wanted to chime in there with the two themes that Kevin and.

00:31:43.000 --> 00:32:01.000
Klaus alluded to and provide a different perspective to that. And on that note, I'm done speaking.

00:32:01.000 --> 00:32:07.000
I'm finding myself going deep on, um. On… on…

00:32:07.000 --> 00:32:14.000
Trying to really, really understand the… the micro…

00:32:14.000 --> 00:32:23.000
Level of cognitive. Interactions… intercognitive interactions twixt humans.

00:32:23.000 --> 00:32:28.000
Uh, as it relates to… conversation.

00:32:28.000 --> 00:32:38.000
Uh, and the elaboration of people's, uh, understandings and mental models during, um, conversational interactions.

00:32:38.000 --> 00:32:49.000
Um, and interleaving those appreci… growing appreciations with. An understanding of what the technical.

00:32:49.000 --> 00:32:57.000
Low-level technical architecture needs to be. Um, for an intercognitive, um, uh, framework.

00:32:57.000 --> 00:33:03.000
Or, uh, um… Yeah, like, capturing that.

00:33:03.000 --> 00:33:08.000
Traffic? Um, to support.

00:33:08.000 --> 00:33:15.000
Uh, both synchronous and asynchronous, uh… enhancement with machine support.

00:33:15.000 --> 00:33:23.000
Um… Yeah, I, uh, really love Kevin's remark about, uh.

00:33:23.000 --> 00:33:30.000
About the watersheds, um… being more manageable, uh, in effect.

00:33:30.000 --> 00:33:39.000
Um, the automatic, uh, self-organizing character of, uh, of watershed maintenance when people can communicate, uh.

00:33:39.000 --> 00:33:47.000
Uh, gracefully. And, uh, and I think that kind of…

00:33:47.000 --> 00:33:51.000
Um…

00:33:51.000 --> 00:33:56.000
That kind of… clean, self-organizing.

00:33:56.000 --> 00:34:03.000
Um, beauty. Ian, uh, uh…

00:34:03.000 --> 00:34:33.000
In intercognitive… in the intercognitive domain, uh, is… really where the great hope is for us.

00:35:53.000 --> 00:36:00.000
So maybe I'll, uh, I'll jump in. Um… It's been a while since I've done a check-in.

00:36:00.000 --> 00:36:07.000
It's probably been 2 or 3 months. I've, um…

00:36:07.000 --> 00:36:14.000
Recently lost my business partner. He, uh… He died, uh, about a month ago.

00:36:14.000 --> 00:36:18.000
Um, it's been a slow… process, he's.

00:36:18.000 --> 00:36:25.000
He was diagnosed with colon cancer. Stage 4, maybe about a year and a half, two years ago.

00:36:25.000 --> 00:36:33.000
Uh, so that's been a, um… a long road for him, for us, um, our community.

00:36:33.000 --> 00:36:39.000
And, um… come to, sort of.

00:36:39.000 --> 00:36:44.000
Realize that it's a… sort of a double-edged sword. You know that it's gonna happen.

00:36:44.000 --> 00:36:57.000
Um, so you, um, it kind of… slows you down, you don't want to rock the boat, you don't want to sort of start moving ahead without him.

00:36:57.000 --> 00:37:11.000
And then, at the same time, you're… you sort of feel this angst about, um… feeling, sort of… held back in some way. Uh, it's kind of… kind of a crazy thing, and so…

00:37:11.000 --> 00:37:19.000
There's this… all of a sudden, there's this sense of… um, sort of… release, um…

00:37:19.000 --> 00:37:25.000
And guilt, all at the same time. It's a very interesting, uh, sensations.

00:37:25.000 --> 00:37:32.000
Meanwhile, um. The projects have continued, uh.

00:37:32.000 --> 00:37:47.000
The… the work on… sort of our version of Neobooks. I've updated Jerry on that, has progressed, um, I'm pretty excited about.

00:37:47.000 --> 00:38:00.000
This idea of a neobook being not only a open. Platform, um… Where the content is open source and editable, and people can contribute to it, and so on and so forth.

00:38:00.000 --> 00:38:07.000
But that it be multimodal. Meaning, uh, that, uh, it's…

00:38:07.000 --> 00:38:12.000
Not just text, but audio. Memes, uh, video.

00:38:12.000 --> 00:38:19.000
Presentations. And that all three, all of those layers, um.

00:38:19.000 --> 00:38:26.000
Are actually related to one another, so the same… type of content in text, say a paragraph.

00:38:26.000 --> 00:38:32.000
Might be reduced to, uh, a meme. Or, uh, to a slide.

00:38:32.000 --> 00:38:40.000
Or 2, or, um, to audio. In the form of a… typically an audiobook.

00:38:40.000 --> 00:38:45.000
Or even a podcast component. And that all of these things are, um…

00:38:45.000 --> 00:38:55.000
You can go in and out of these layers. Um, as a consumer of it. And by consumer, I don't mean purchaser.

00:38:55.000 --> 00:39:02.000
But a user. Um, and uh… So we're mocking a lot of this stuff up.

00:39:02.000 --> 00:39:08.000
Both at the technical level. Um, and that the, um…

00:39:08.000 --> 00:39:16.000
At the content level. Uh, we're developing something we call, uh, a life fingerprint.

00:39:16.000 --> 00:39:24.000
Um, that tries to model. Um, what's happening in this content.

00:39:24.000 --> 00:39:32.000
From a life perspective. What… what layer of… complexity is… is acting and, um…

00:39:32.000 --> 00:39:38.000
Trying to get it down to a root level of definition.

00:39:38.000 --> 00:39:46.000
Uh, so that this content can actually be related, not simply by the words, cue terms, and so on and so forth.

00:39:46.000 --> 00:39:51.000
By the actual life flows that are happening within the content.

00:39:51.000 --> 00:40:01.000
Or being described within the content. So, um, that feels… powerful, really complex, really difficult, but, um…

00:40:01.000 --> 00:40:05.000
Feels like a good exploration and a good direction to go.

00:40:05.000 --> 00:40:11.000
Ken was part of some of this work early on. Um, and uh… and we've…

00:40:11.000 --> 00:40:21.000
Continue that work of understanding some of that, um… life functions and what these life functions do in context and so forth, so that's…

00:40:21.000 --> 00:40:31.000
That's one of the projects. Uh, the first… thing that we're developing as a neobook in this context. We're doing these two things in parallel.

00:40:31.000 --> 00:40:37.000
Is serving life. And serving life is, uh…

00:40:37.000 --> 00:40:43.000
The first neobook in this model. I know we have neobooks in.

00:40:43.000 --> 00:40:49.000
Um, the… another model of neobooks, which is just text.

00:40:49.000 --> 00:40:56.000
Um, but this model where we have the multiple layers and the interactions and so forth.

00:40:56.000 --> 00:41:06.000
Um, serving life, we hope to be the first book. So that piece of it is, um…

00:41:06.000 --> 00:41:12.000
Progressing well. We now have… Um, some new case studies, um.

00:41:12.000 --> 00:41:17.000
We've recently interviewed Kevin. Uh, for… for that.

00:41:17.000 --> 00:41:30.000
Hunter Lovins recently, um, we interviewed, um, Alan. Savory from the savory Institute, um, as well.

00:41:30.000 --> 00:41:39.000
Um, a number of others in the space that are. Folks that we believe are moving towards… excuse me.

00:41:39.000 --> 00:41:46.000
Moving towards this new… way of operating that recognizes that.

00:41:46.000 --> 00:41:54.000
What we do is serving life. Sorry.

00:41:54.000 --> 00:41:59.000
Um, and so… that model is, uh…

00:41:59.000 --> 00:42:04.000
It's progressing well, the book's starting to feel like a book.

00:42:04.000 --> 00:42:11.000
Uh, in a clear narrative, at least we think so. We've had… a few readers give us some really good feedback on it.

00:42:11.000 --> 00:42:17.000
Um, and uh… We're hopeful that we can wrap this up.

00:42:17.000 --> 00:42:27.000
Uh, by the end of the year. Uh, whether it will be in the form of an e-book at that point, we're not sure, but at the very least, we'll have the content ready.

00:42:27.000 --> 00:42:36.000
For it to integrate into it, and… And our vision is that anyone who's writing, who's seriously creating a book nowadays.

00:42:36.000 --> 00:42:45.000
Is going to be… doing memes. They're going to be doing presentations, they're going to be doing audio versions of it, and that all of these things.

00:42:45.000 --> 00:42:51.000
Have to exist anyway. And so, why not integrate them into one experience?

00:42:51.000 --> 00:43:02.000
That, uh, people can engage. Do deep dives down into the… not only the text, but the supporting data that's behind it.

00:43:02.000 --> 00:43:08.000
Um, and… and do superficial, just… float through the… through the memes.

00:43:08.000 --> 00:43:16.000
Or, uh, float through the presentations. And at any time, do a deep dive into the material below it.

00:43:16.000 --> 00:43:23.000
Uh, so that's… feels exciting to… to think of a new model of experiencing content.

00:43:23.000 --> 00:43:33.000
Producing content and having content be… Uh, but… available to folks that don't necessarily want to just read a book.

00:43:33.000 --> 00:43:40.000
Uh, traditionally, so… Much more to update, but I'll leave it at that, because that's a pretty long update as it is.

00:43:40.000 --> 00:44:08.000
Thank you.

00:44:08.000 --> 00:44:14.000
I think I'll go next, because… it kind of dovetails with what you…

00:44:14.000 --> 00:44:22.000
We're saying, Jose. So… Last week, we were talking about.

00:44:22.000 --> 00:44:28.000
Collective intelligence. And I've been thinking about the nature of collaboration for a couple of years.

00:44:28.000 --> 00:44:34.000
Because I think it's… I'm having a hard time finding great examples of it.

00:44:34.000 --> 00:44:39.000
Which says to me that I think it's more limited than we say.

00:44:39.000 --> 00:44:48.000
I've started to think of it as… Working separately, then coming together to share, and then working separately again.

00:44:48.000 --> 00:44:55.000
And I'm trying to find. Examples where… a group of… well…

00:44:55.000 --> 00:45:00.000
A group of people get together and actually collaborate in a sense where it's not.

00:45:00.000 --> 00:45:07.000
One or two working. And others being in the room.

00:45:07.000 --> 00:45:16.000
Um, and… I think what I've… I even looked at an electronic musician who.

00:45:16.000 --> 00:45:25.000
Has been in the game for 40 years. And he did a collaboration project. And the way it was done was that he would set up some.

00:45:25.000 --> 00:45:32.000
Tunes, send the digital file to the other person. They would modify it.

00:45:32.000 --> 00:45:37.000
Send it back to him. He would modify it, and they would go back and forth until they had a.

00:45:37.000 --> 00:45:46.000
A musical piece that they liked. And I… I think about things like Wikipedia, which is sort of at the opposite end. You have.

00:45:46.000 --> 00:45:53.000
It feels like a collaborative effort. And so it's just something I've been thinking about.

00:45:53.000 --> 00:46:00.000
A lot is, what is the… I think we throw around the word collaboration a lot.

00:46:00.000 --> 00:46:11.000
Without really being honest about. What the work entails, and I will leave this with the last.

00:46:11.000 --> 00:46:18.000
It's very different from being on a team. Because I think just being on a team doesn't mean that you're…

00:46:18.000 --> 00:46:27.000
Collaborating, in my sense of it. It's… it's more that… The genesis of the idea and the actual work is something that.

00:46:27.000 --> 00:46:34.000
Is two minds as one, sort of, and I've experienced it, but only.

00:46:34.000 --> 00:46:40.000
In fleeting moments where. My brain and someone else's brain are…

00:46:40.000 --> 00:46:51.000
Are in… we both get it. And we're finishing each other's senses… sentences and things like that, but… It seems to me to be a rare thing that we keep seeking.

00:46:51.000 --> 00:46:58.000
We, meaning… I just see collaboration as a skill that…

00:46:58.000 --> 00:47:03.000
People seem to want to develop. And yet, maybe…

00:47:03.000 --> 00:47:10.000
It's not what we think it is, and so… We're trying to create something that might not.

00:47:10.000 --> 00:47:40.000
Actually be a way that people work together.

00:49:07.000 --> 00:49:11.000
I love our sharing of our… projects and obsessions and.

00:49:11.000 --> 00:49:20.000
Scary life events, like concussions and flooding. And all these other sorts of things. Thank you for all for showing up wholeheartedly.

00:49:20.000 --> 00:49:26.000
You may hear it in my voice, but April and I have been down with a bug since about the 22nd.

00:49:26.000 --> 00:49:33.000
Of August, so it's been a while. And this feels like a familiar bug. April came back from a trip and basically.

00:49:33.000 --> 00:49:37.000
Brought it home, and I nursed her for a couple days, and then I came down with it.

00:49:37.000 --> 00:49:42.000
And for me, the day I came down with it, I put a marker two weeks later in my calendar, which is still next week.

00:49:42.000 --> 00:49:49.000
That said, is my bug gone? Because, in my experience, this is 2 weeks of coughing miserably.

00:49:49.000 --> 00:50:04.000
Parking up phlegm. Uh, in this case, like, my right eye has all tier depth, so apparently there's a bacterial infection that's accompanying this, that's… moves from eye to eye or something, and… I don't know what, but it's like a couple very uncomfortable nights, but we can work, we can do stuff.

00:50:04.000 --> 00:50:12.000
Luckily, we don't have any performances that we have to miss because we're sick or anything like that, so it's all good, but… But we've been feeling kind of low.

00:50:12.000 --> 00:50:20.000
Um, Hank Kuhn, who's not here today, but who is a frequenter of OGM, and I have had a couple calls around UpKeto.

00:50:20.000 --> 00:50:28.000
Uh, which got mentioned somewhere, I don't remember… where it showed up, but Hank was like, I love this, like, up-Keto idea, let's talk. So we've had a couple of separate calls.

00:50:28.000 --> 00:50:37.000
Uh, Up Keto is a neologism. Uh, it is a concatenation of upward spiral or uplift, and Aikido, which is my sport.

00:50:37.000 --> 00:50:47.000
And, uh, we've talked about Aikido, uh. A few times in OGM, but Up Keto is just meant to be a practice. At this point, it's a thought experiment. Like.

00:50:47.000 --> 00:50:53.000
What would a practice be like if your intention was to improve everything you touch?

00:50:53.000 --> 00:51:05.000
To help upward spiral happen all over the time. With Aikido principles, meaning not coming in and bludgeoning things, but blending with sensing the energies, blending with, and then seeing what improvement went.

00:51:05.000 --> 00:51:10.000
And improve is the best word I've been able to find for it so far, but it's a really touchy word.

00:51:10.000 --> 00:51:15.000
Because what I think might be an improvement of the situation might piss everybody off.

00:51:15.000 --> 00:51:21.000
Uh, et cetera, et cetera. And then there are knock-on effects and so forth. So you've got to be thoughtful about this, but.

00:51:21.000 --> 00:51:28.000
But putting a… cracking a joke or listening to the cashier at the store and cracking a joke and putting a smile on their face.

00:51:28.000 --> 00:51:36.000
Is of keto. Um, free hugs is up keto, and kind of non-controversial, because people can choose to walk up and hug you or not.

00:51:36.000 --> 00:51:43.000
Whatever, but… but this notion that you might walk around and try to make everything better than you touch, I like a lot.

00:51:43.000 --> 00:51:51.000
And so, um, there's a baby… there's a fledgling website at UpKeto.com, but we started talking, and then I sat down with Claude.

00:51:51.000 --> 00:51:55.000
Not my friend Claude, but rather the new alien intelligence Claude.

00:51:55.000 --> 00:52:02.000
And froze some of these things to Claude, and Claude was, like, wonderful about this, and OMG, holy hell.

00:52:02.000 --> 00:52:09.000
You know, folded and asked a couple different questions, grew the whole thing, and I'm like, oh, this is really pretty good. I like this a ton.

00:52:09.000 --> 00:52:21.000
So expect to see some of that at some point. Uh, and so Hank and I, I created a private group on LinkedIn, if anybody wants to talk about UpKeto, when we released the hounds.

00:52:21.000 --> 00:52:26.000
Of chat at the end of, uh, the check-in, I will post that link in the chat.

00:52:26.000 --> 00:52:38.000
Um, so that we can sort of figure this thing out and formulate it, and propagate it, and do whatever… whatever… whatever it wants to be, I'm really interested in helping it become, as long as it's not evil.

00:52:38.000 --> 00:52:44.000
Uh, because I think the general concept… then it… maybe it needs a secret handshake.

00:52:44.000 --> 00:52:49.000
Or a little pin or something that you, you know, you wear. I don't know.

00:52:49.000 --> 00:52:55.000
So that you know that, oh, this isn't a keto practitioner, they should be careful, they're a master of the dark arts of up keto.

00:52:55.000 --> 00:53:01.000
Um, I think things like this ought also be, like, fun, and slightly conspiratorial is okay.

00:53:01.000 --> 00:53:07.000
And then I realized also in the framing of UpKeto that there are some principles of UpKeto.

00:53:07.000 --> 00:53:13.000
And that they overlapped heavily, heavily, heavily with my principles of design from trust.

00:53:13.000 --> 00:53:19.000
That I've been formulating Design from Trust for a while, but lately I've been focusing on writing out.

00:53:19.000 --> 00:53:25.000
And we'll soon be posting. Um, my method of posting is so fucking slow, because.

00:53:25.000 --> 00:53:35.000
I… I write out the tendrils of an octopus of an idea, and then I need to finish all the tendrils before I post the main idea, because you're gonna go out to all the different little tendrils.

00:53:35.000 --> 00:53:45.000
And it gets complicated, and it winds up a little hard to finish, but… Um, I'll post a link to the Principles of Design from Trust, which start with the very simple, assume good faith.

00:53:45.000 --> 00:53:56.000
Or good intent, whichever word you prefer. But assume good faith is, like, the grounding principle of design from trust, and it's a nice principle for Akito as well. And there's a bunch of others.

00:53:56.000 --> 00:54:03.000
In particular, in my brain, there's a thought of inspirations. For the principles of Design from Trust.

00:54:03.000 --> 00:54:07.000
Which points to a… I think at this point, very beautiful.

00:54:07.000 --> 00:54:14.000
Curated collection of other prints, other useful groups of principles from other groups around the world.

00:54:14.000 --> 00:54:31.000
That are awesome, that are just wonderful. So I've been borrowing from some of those, and… And figuring out, like, what this might look like, but… anybody who's interested, uh, join the group or get in touch, or whatever, but it's been really fun to think about these things, because I'm trying.

00:54:31.000 --> 00:54:36.000
Last thought. I'm trying really hard to figure out. Positive things to be and do.

00:54:36.000 --> 00:54:49.000
At this particular moment of multiple crises. I'm trying to figure out a bunch of ways to walk into the world, like, that might attract people to go, yeah, yeah, yeah, I want to build, I want to do, I want to improve.

00:54:49.000 --> 00:55:19.000
And this is just… this is one of them. So, with that, I am… Today, so far. Complete.

00:56:59.000 --> 00:57:11.000
So I found myself in a space of emptying out. We have our appointment at the Spanish Consulate a week and a half from.

00:57:11.000 --> 00:57:16.000
No? Um, been going through the house, downsizing, selling stuff off.

00:57:16.000 --> 00:57:27.000
Going through my life, going through my memories, um… And I know that there's a new adventure coming, but right now, it's about…

00:57:27.000 --> 00:57:32.000
Letting things go. Um, and it's painful.

00:57:32.000 --> 00:57:37.000
And, um… And it feels somehow appropriate to the…

00:57:37.000 --> 00:57:47.000
Times in which I live, that so much is passing. Trying to honor things that, um, have been a part of my life, both the good and the bad, and the ugly.

00:57:47.000 --> 00:57:57.000
So, um… I'm just in a… in a very interesting place that I'm not used to being in.

00:57:57.000 --> 00:58:04.000
When I took my coaching course 25 years ago. Um.

00:58:04.000 --> 00:58:14.000
I was that… If you know the Zen story about the professor who went to meet the Zen master, and the professor's talking and talking, and the Zen master's pouring the tea into the cup until it's overflowing.

00:58:14.000 --> 00:58:19.000
If you need to empty your mind out, and the first thing I was assigned after being given a bunch of books was.

00:58:19.000 --> 00:58:26.000
Mediafast, you need to just let yourself settle. So I'm in that space right now of letting things settle.

00:58:26.000 --> 00:58:35.000
Again. And not trying to take new things in, but to just honor what's gone before, and release it with grace.

00:58:35.000 --> 00:58:46.000
Um, which is not easy. Has a lot of poignancy. I've been in Marin County for 35 years, and I'm looking at leaving here in the next.

00:58:46.000 --> 00:58:52.000
Between 3 and 6 months, and it's becoming very real. Someone came and bought all my CDs this.

00:58:52.000 --> 00:59:03.000
This past week. 980 CDs gone from my living room. It's like… It's naked in here, you know, and I have someone come in to look at my book collection, and…

00:59:03.000 --> 00:59:11.000
So it's getting really very real. Um, because we're not going to bring a lot of stuff with us. We're bringing, you know, cookware.

00:59:11.000 --> 00:59:15.000
Got in my cast iron pans and my pots and my knives.

00:59:15.000 --> 00:59:20.000
Um, clothing and artwork, and everything else has gone by the wayside.

00:59:20.000 --> 00:59:32.000
Um, so… I was not a Zen practitioner, I was a Vipassana practitioner, but my life is becoming very Zen of how do I just release this, and…

00:59:32.000 --> 00:59:36.000
Live a simpler way. Which also feels appropriate, too.

00:59:36.000 --> 00:59:46.000
Moving into the last phase of my life, the third act, you know, this is… This is it, this is the last hurrah, you know, moving new culture, new country, new language, new people.

00:59:46.000 --> 00:59:52.000
Um. And I find that's giving me a strange detachment to what's going on.

00:59:52.000 --> 00:59:57.000
In this country right now, because I am… completely and totally outraged.

00:59:57.000 --> 01:00:03.000
Um, and completely and totally… Devastated?

01:00:03.000 --> 01:00:08.000
Like, how the hell did this happen? And where?

01:00:08.000 --> 01:00:13.000
Is the collective response that says. Fuck no!

01:00:13.000 --> 01:00:22.000
Not seeing it. Um, and if I were not leaving, I'd be a lot more involved, but I am leaving, and so it's like, okay, I don't have the.

01:00:22.000 --> 01:00:27.000
Bandwidth right now to be too involved in that. And I… I feel some guilt about that.

01:00:27.000 --> 01:00:37.000
You know, um, I love this country. Of everything that I was gifted, I'm aware of how much of it came on the backs of.

01:00:37.000 --> 01:00:45.000
Exploitation of both land and people elsewhere. But, you know, um… I've had a really great life here, as has…

01:00:45.000 --> 01:00:55.000
You know, so many people that I know, and… That seems to be dissolving, and maybe that's what's needed, you know? Civilization, as Gandhi said, is a great idea. I'm not seeing it.

01:00:55.000 --> 01:01:08.000
Um, we're not being very civil here these days. And, um… I'm very concerned about what's going to happen, and I want to be far away, uh, as things continue to slide.

01:01:08.000 --> 01:01:12.000
More and more increasingly… accelerated downhill.

01:01:12.000 --> 01:01:16.000
Um, so it's just a whole lot of shit going on.

01:01:16.000 --> 01:01:22.000
Uh, at multiple levels. And…

01:01:22.000 --> 01:01:28.000
I'm glad I have my practices, you know, to create the space to hold this, and not be overwhelmed by it.

01:01:28.000 --> 01:01:32.000
Um, and I'm glad I have people in my life to talk to.

01:01:32.000 --> 01:01:44.000
So that I don't get, uh… too overwhelmed by it, but I am overwhelmed by it, you know? It's… it's… there's only so much I can let in, and handle before I have to say.

01:01:44.000 --> 01:01:53.000
Enough. And the emptying out feels like part of that process of, in order to be able to.

01:01:53.000 --> 01:01:57.000
Hold what's going on in the world, I have to queer out a bunch of shit from my life.

01:01:57.000 --> 01:02:04.000
Uh, physically and internally. So, that's what's…

01:02:04.000 --> 01:02:21.000
Going on with me these days.

01:02:21.000 --> 01:02:28.000
If I can jump in here, I've, uh… Sincerely apologize for coming in late.

01:02:28.000 --> 01:02:39.000
Um, from a few things that have been said. Uh, I feel like I missed. One of the main things I would have liked to have heard, which was Kevin talking about watersheds.

01:02:39.000 --> 01:02:47.000
But what Ken just said. Reminded me… About a year ago, I was out in North Carolina. I live in Oregon.

01:02:47.000 --> 01:02:54.000
Very rarely get to North Carolina. But since I was there, with a little bit of time to spare.

01:02:54.000 --> 01:02:59.000
I looked up Kevin and reached out to him and asked him if I could.

01:02:59.000 --> 01:03:08.000
To meet him in person. He and I had a really nice… chat on the banks of the Sundanoa River.

01:03:08.000 --> 01:03:14.000
On his property. And, uh, what sticks in my mind.

01:03:14.000 --> 01:03:21.000
Was Kevin mentioned, the concept of retreat. Kind of like, um…

01:03:21.000 --> 01:03:35.000
Prompting me a little bit, like, hey, is this a… is this a topic that you and I should pick up on, and… bring to OGM, given our shared interest in watersheds and water and hydrology and whatnot.

01:03:35.000 --> 01:03:42.000
But, um, Ken, what you just said… strikes me, you know, like, so often.

01:03:42.000 --> 01:03:49.000
We look at the world around us, and we… we noticed the changes that everyone else needs to make.

01:03:49.000 --> 01:04:01.000
Um, but this letting go. That you're doing… Seems to me like it's exactly what we all need to be doing. Uh, maybe not literally, like, the same way.

01:04:01.000 --> 01:04:13.000
But I think… I think this purging and letting go. And you're doing it at a very, very complete level, you know, it sounds like, and I think that's wonderful. Like, I see that as being…

01:04:13.000 --> 01:04:19.000
Like, uh… like, almost what's necessary for rebirth.

01:04:19.000 --> 01:04:23.000
Because we can… we can conceptually say, like, we're being reborn or whatever, you know?

01:04:23.000 --> 01:04:31.000
But if we're staying in the same domicile with all the same… you know, trappings and belongings, and friends, and…

01:04:31.000 --> 01:04:37.000
And everything else, um. You know, we're really not giving up anything, right? Like, we're just…

01:04:37.000 --> 01:04:44.000
We're just holding on to what we have. And, as John Mayer says, waiting for the world to change.

01:04:44.000 --> 01:04:48.000
So, I just want to applaud, you know, like, what I hear.

01:04:48.000 --> 01:04:54.000
What I hear you saying… Including the stepping into the…

01:04:54.000 --> 01:05:04.000
You know, the void, or the vortex, or whatever that comes with that, right? Like… Yeah, like, if you're gonna… If you're gonna truly…

01:05:04.000 --> 01:05:13.000
Let go, and release, and… and… you know, whether you call it a Zen practice, right, like, whatever label you put on it, right? Like.

01:05:13.000 --> 01:05:23.000
I think… I think you're doing… I think you're doing… and I'll just extend that to… I feel like each person that I've heard talk, like Josue, and.

01:05:23.000 --> 01:05:29.000
Uh, I came on when Klaus was in the middle of his deal, so I don't know that I heard it all.

01:05:29.000 --> 01:05:33.000
But then, Jerry, what he said, I feel like every single person.

01:05:33.000 --> 01:05:46.000
That has spoken this morning, has spoken to me, in a way, of… Like, everything you've said has resonated with a piece of what I'm personally doing and going through and working through.

01:05:46.000 --> 01:05:55.000
Um… and so I guess I just want to say, like, we're doing it, you know? Like, each of us, in our own way, we're doing what we need to do.

01:05:55.000 --> 01:06:04.000
And maybe… maybe the number one ingredient that… that… That needs to accompany all that is the…

01:06:04.000 --> 01:06:15.000
Okay-ness with it, right? Like, the. The letting go… so that… so that we can see, like, you know, on the panarchy curve, this is the…

01:06:15.000 --> 01:06:24.000
This is the collapse, or the deconstruction, or the… whatever you want to call it, that has to proceed reconstruction. Like, you can't… you can't…

01:06:24.000 --> 01:06:31.000
Reconstruct… and hold everything… everything that we were already…

01:06:31.000 --> 01:06:41.000
You know, all our norms or whatever, we can't hold all those constant and reconstruct, you know? It's like… Reconstruction has to arise from some degree of.

01:06:41.000 --> 01:06:48.000
Disruption and dissolution, and… Anyway, so I just, like, feeling super grateful for…

01:06:48.000 --> 01:06:58.000
For calling in when I did, and yeah, regretful that I missed part of what was said here, but, um… Yeah, just thanks… thanks for everybody, and…

01:06:58.000 --> 01:07:28.000
I say can, you know, like, more power to you, man. I think you're doing a great thing.

01:08:04.000 --> 01:08:11.000
I can give a real quick report from Washington, D.C. I really apologize for.

01:08:11.000 --> 01:08:22.000
Being late, I was in a meeting on. The future of data policy, global… And it seemed important, and it was. Um…

01:08:22.000 --> 01:08:32.000
I won't spend much time on the political. Um, you've all been reading both the news and the analysis of the news.

01:08:32.000 --> 01:08:38.000
A lot of the posts I see. Are trying to decide whether this is…

01:08:38.000 --> 01:08:47.000
The end of democracy, or just another… Donald Trump and family con job. Um, but anyway.

01:08:47.000 --> 01:08:55.000
I won't go there. It is causing a great deal of depression. A lot of people staying up late at night, or.

01:08:55.000 --> 01:09:05.000
Waking up in the middle of the night, and… trying to make sense of it, or perhaps figure out what they should do. Uh, on my own side, um.

01:09:05.000 --> 01:09:15.000
I just got back from Manila and Taipei, had a. Very eventful and absolutely fascinating opportunity there to meet some new people.

01:09:15.000 --> 01:09:20.000
Um. If anybody has heard of the HIRA.

01:09:20.000 --> 01:09:33.000
Network. H-y-r-a. And I think their website is HIRATECH, H-Y-R-A-T-E-C-K.

01:09:33.000 --> 01:09:46.000
They're based in Vietnam and Dubai. And uh… they string together a lot of buzzwords. Initially, I was incredibly skeptical, because it was blockchain enabling edge computing for AI.

01:09:46.000 --> 01:09:55.000
You know? But they're doing something with that, and they have a vision, and they have some smart people involved. So, uh…

01:09:55.000 --> 01:10:00.000
Be interested in anybody's, uh… take on that.

01:10:00.000 --> 01:10:07.000
On the personal side, I've been dealing with some strange symptoms lately, and.

01:10:07.000 --> 01:10:21.000
Met with a neurologist and a neurosurgeon. And, um… This is one of these gray zones where you really can't figure out what's going on. I also learned I had Lyme disease.

01:10:21.000 --> 01:10:32.000
Either a month ago or 10 years ago. Uh, which can cause neurological issues. But, uh, anyway, we're doing some tests, and we're trying to struggle through that.

01:10:32.000 --> 01:10:42.000
Uh, I'm a… Firm believer in medical science. I just don't like to have to use it.

01:10:42.000 --> 01:10:50.000
And when the numbers are like, well, we could do this, and there's an 80% chance, and oh, we don't really know what's causing this.

01:10:50.000 --> 01:10:58.000
I get skeptical, and I get anxious, so that's sort of where I'm at. I will keep you informed maybe in a month.

01:10:58.000 --> 01:11:12.000
Uh, if we learn more. Uh, I'm also headed to the northern… to the Dolomites in northern Italy in about 10 days, and very much looking forward to spending a week with my wife and four of our.

01:11:12.000 --> 01:11:20.000
Best friends, hiking among… some of the most beautiful, uh, scenery in Italy, which, of course.

01:11:20.000 --> 01:11:29.000
Says it a lot. And I have a quick stop in Zurich and might see my… the family that my…

01:11:29.000 --> 01:11:37.000
Mothers, grandfather left behind when he… left, uh, central Switzerland to come to Minnesota.

01:11:37.000 --> 01:11:44.000
Anyway, that's where I'm at, and uh… We live in interesting times.

01:11:44.000 --> 01:11:55.000
And thanks for all the things that people are posting on the list. It's, uh… It's quite a grab bag.

01:11:55.000 --> 01:12:05.000
Mike, thank you. Uh, I think that concludes the check-in round. Uh, Doug and Stacy said in the chat that they are good to go.

01:12:05.000 --> 01:12:09.000
I think we've heard from everybody, so I'm going to release the hounds.

01:12:09.000 --> 01:12:17.000
And see what we'd like to talk about. I will put in links, uh… to… oh, that's right, Scott, my apologies.

01:12:17.000 --> 01:12:19.000
Where's Scott? There's Scott. Um… Did you check in?

01:12:19.000 --> 01:12:24.000
I'm right here. Yes, I did. I talked about collaboration.

01:12:24.000 --> 01:12:26.000
I thought you did. That's right, good. That collaboration may not be the thing we think it is.

01:12:26.000 --> 01:12:31.000
Yes, I'm all covered, thank you. Correct, yes.

01:12:31.000 --> 01:12:37.000
Thank you, and I'd love to talk more about that. Um, I had a brief question for Klaus.

01:12:37.000 --> 01:12:42.000
Uh, which was, um, I created recently in my brain two thoughts, um.

01:12:42.000 --> 01:12:51.000
Basically, things that RFK might fix. At HHS and things that RFK is fucking up at HHS. And…

01:12:51.000 --> 01:12:56.000
The list of things that he's fucking up include vaccines, research, medical research data, there's a whole mess of them.

01:12:56.000 --> 01:13:02.000
But things he might fix are things that I think we would broadly agree with him on.

01:13:02.000 --> 01:13:12.000
About, you know, microplastics and the water supply, endocrine disruptors. Food dyes, whatever, whatever, and I'm one… and I'm wondering, Klaus, is there a way for even Sierra Club.

01:13:12.000 --> 01:13:17.000
To pick a couple of the things that are on the not-the-naughty list, but the good list.

01:13:17.000 --> 01:13:26.000
And just push hard to make those things happen. Just make sure the hell that the food… the food system doesn't resist as much, and that some of these things get done, because.

01:13:26.000 --> 01:13:38.000
Some of what I've been reading is that. Um, there's very effective resistance by a lot of the big food companies to some of the efforts that RFK is trying to, you know, push through, so they're getting watered down, which is how.

01:13:38.000 --> 01:13:50.000
This stuff often… all too often works, but I'm wondering if you break down… some of that stuff is, like, on… on… The progressive agenda as well.

01:13:50.000 --> 01:13:59.000
Well, I was, uh, uh… one of the voices in the Sarah Club promoting Kennedy in the hope that, um.

01:13:59.000 --> 01:14:05.000
His ideas would… take hold, and uh…

01:14:05.000 --> 01:14:15.000
Um, and there are, you know, quite a few, uh, still hoping for that to happen, and… Uh, and lobbying in this, but…

01:14:15.000 --> 01:14:21.000
I'm increasingly pessimistic. It seems like the industry is totally dominating the conversation.

01:14:21.000 --> 01:14:22.000
Mm-hmm.

01:14:22.000 --> 01:14:32.000
Um, so this, this whole idea of, um. Reducing the amount of highly processed foods, particularly towards children.

01:14:32.000 --> 01:14:41.000
Um, which, you know, would have had impacts on. The agricultural system, right? Because as you're reducing.

01:14:41.000 --> 01:14:47.000
Highly processed foods, that means you're reducing high fructose corn syrup, and.

01:14:47.000 --> 01:14:55.000
Uh, now, uh… corn, uh, uh, based, uh, uh, processed foods and so on.

01:14:55.000 --> 01:15:03.000
Uh, yeah, I know the pushback is… is fierce, and the voices of Sierra Club and others.

01:15:03.000 --> 01:15:10.000
Of being dragged out here. I don't see it happening. Uh, I think this entire RFK.

01:15:10.000 --> 01:15:18.000
Phenomena is, uh… is, uh, turning into a pile of, uh, you-know-what.

01:15:18.000 --> 01:15:25.000
Alas. Yeah, thanks, Laz. That's too bad. Um, Sean, please?

01:15:25.000 --> 01:15:26.000
Can I jump in? Because I need to leave quickly and just have a quick statement.

01:15:26.000 --> 01:15:29.000
Yeah…

01:15:29.000 --> 01:15:30.000
Go for it, Kevin, if you don't mind.

01:15:30.000 --> 01:15:50.000
Yeah, uh, Plex is a good thing. I'm willing to help keep it going if other people want to do that. You know, I just see it… Back in my days as a community weekly newspaper editor, and the people from South Fulton would reach out to Miss Irma Estes, and she would say, their cousins motored in from Memphis, etc.

01:15:50.000 --> 01:16:08.000
And so I'm willing to help, you know, just, uh… do that, and also add that I would, you know, when people say things on this list, I may reach out to you to say, please say more about that, you know, like Scott, say more about collaboration or something.

01:16:08.000 --> 01:16:12.000
So I would add to what Pete did, but I don't want to do it myself.

01:16:12.000 --> 01:16:15.000
But I want to be part of doing it, because it's something I.

01:16:15.000 --> 01:16:17.000
Like to do. So…

01:16:17.000 --> 01:16:22.000
That sounds awesome, Kevin. I think that's energy Pete would welcome. He's been looking for people to sort of help collect and.

01:16:22.000 --> 01:16:32.000
Yeah, he wants… I can't make it into a Plex thing, but I could… I could reach out to folks and just do a, you know, twice-a-month community news from the.

01:16:32.000 --> 01:16:37.000
Open, uh, gambling mind, or whatever we are. From my gun, yep. Okay.

01:16:37.000 --> 01:16:43.000
From Lake Wobegon. Yep. And all the children are above average.

01:16:43.000 --> 01:16:44.000
Yep.

01:16:44.000 --> 01:16:46.000
Um, no, back to you, Smurp.

01:16:46.000 --> 01:16:55.000
Hello there. Um, I would just… Just like to comment on the, uh, on the delicious, um…

01:16:55.000 --> 01:17:01.000
Complexity slash plate that, uh, human beings in general, and us in this group are, uh, suffering.

01:17:01.000 --> 01:17:15.000
Of, uh, of, um, uh, this business about. Identifying when we're talking about the same thing, and when we're talking about different things, and how to even manage to.

01:17:15.000 --> 01:17:24.000
To distinguish those phenomena. Every single word that Jose said earlier.

01:17:24.000 --> 01:17:34.000
Um, I could have said or have been sane for. A decade, and uh… and so I say a decade because, uh, because.

01:17:34.000 --> 01:17:54.000
I'd been gearing up to, uh, to do, um, uh, to… start capturing the real-time sort of video aspect of our inter… of interactions for a long time, but then finally managed to start implementing some.

01:17:54.000 --> 01:18:00.000
Hyper… so-called hype… I'm calling it hyper-video. Is the way I refer to that.

01:18:00.000 --> 01:18:06.000
Um, that, uh, capability suite that, uh, that Jose was identifying.

01:18:06.000 --> 01:18:12.000
Um, in effect, capturing our interactions all the way from the real time.

01:18:12.000 --> 01:18:23.000
Um, down through the extractions of, uh, of… of the verbiage, uh, down through, and I think maybe, maybe…

01:18:23.000 --> 01:18:31.000
I'm going a little farther than is typical here, down to the conceptual.

01:18:31.000 --> 01:18:42.000
As a semantic extraction. So, in other words, into a machine-understandable representation that's ontology-based.

01:18:42.000 --> 01:18:48.000
Okay? So that's the span as far as I'm concerned, is all the way from, um, uh.

01:18:48.000 --> 01:19:02.000
Real-time interaction capture. Um, down through the full… down through the explicit conceptual that is graphable, extractable, navigable, summarizable, etc.

01:19:02.000 --> 01:19:09.000
Um, in a deep machine-supported way. Um, and so… so yeah, I…

01:19:09.000 --> 01:19:20.000
Jose, oh my god, let's make… let's make beautiful, uh, uh, nerd music together, uh, because I… We shouldn't be… we shouldn't be in separate.

01:19:20.000 --> 01:19:24.000
Um, silos here. If, uh, if we're doing the same work.

01:19:24.000 --> 01:19:32.000
Um, let's figure out how to make some magic together. And I'd really love to take up, uh, Scott's point about, uh.

01:19:32.000 --> 01:19:37.000
About, uh, what is collaboration? Is it really what we think it is?

01:19:37.000 --> 01:19:45.000
We need to get so deep. So much deeper about, uh, about, um, the micro…

01:19:45.000 --> 01:19:49.000
Microcognitive. Interactions.

01:19:49.000 --> 01:19:55.000
That… that constitute. Um, the integration of our mental models.

01:19:55.000 --> 01:20:03.000
Because really, that's what… that's what this is all about. It is about how our.

01:20:03.000 --> 01:20:08.000
How our individual understandings. Are informed.

01:20:08.000 --> 01:20:17.000
By… by… by our onboarding of others' insights, and.

01:20:17.000 --> 01:20:25.000
And how we can manage to. Um, in the… in the limit and in the large, um.

01:20:25.000 --> 01:20:38.000
Aggregate those understandings as a superposition across all minds. Of, um, into what I would refer to as the merged mental model.

01:20:38.000 --> 01:20:45.000
Uh, and so that… that's, that's the work that I'm deeply trying to do, is… is… is make that repository.

01:20:45.000 --> 01:20:52.000
So that… so that… We're migrating from, ultimately, from natural language.

01:20:52.000 --> 01:21:00.000
As this, uh, um, loose and floppy, uh, interaction modality, uh, into a.

01:21:00.000 --> 01:21:06.000
In effect, a shared address space. Interaction.

01:21:06.000 --> 01:21:14.000
On the merged mental model, and I know that's just… Sounds ludicrously abstract, but… but that's…

01:21:14.000 --> 01:21:21.000
That's what humanity is straining for. Even if it doesn't know that.

01:21:21.000 --> 01:21:23.000
Okay, uh, over.

01:21:23.000 --> 01:21:31.000
Yeah, Sean, thank you. And I think you and Jose both know that Marc Antoine Perrin is a fellow traveler on your journeys.

01:21:31.000 --> 01:21:36.000
And I'm now going to reflect and say that it feels to me like the three of you.

01:21:36.000 --> 01:21:43.000
This is gonna sound worse than I mean it. The three of you have been working very hard for a very long time to manually do.

01:21:43.000 --> 01:21:48.000
What training in LLM actually does now.

01:21:48.000 --> 01:21:49.000
Yes and no. Yes and no. I…

01:21:49.000 --> 01:21:55.000
The token… the unknowable token vector space that's inside of an LM and gives us back.

01:21:55.000 --> 01:21:59.000
This weird magic of, oh my god, pull thoughts and blah blah.

01:21:59.000 --> 01:22:04.000
Is doing a lot of what the three of you have been researching and figuring out.

01:22:04.000 --> 01:22:10.000
Marc Antoine and Jack Park and I are working very, very closely together, trying to go super deep and establish a, uh.

01:22:10.000 --> 01:22:14.000
Cool.

01:22:14.000 --> 01:22:24.000
A ground for that kind of intercognitive exchange that is deep and solid, like a.

01:22:24.000 --> 01:22:37.000
A granite upon which such modeling can occur. Um, but, uh, but for clarity, I would distinguish, Jerry, between LLM.

01:22:37.000 --> 01:22:49.000
Um, and LCM, where LCM is, uh, is the, uh, um… is terminology that, uh, I… I'm hearing come out of Meta.

01:22:49.000 --> 01:22:58.000
Um, and what they're… one of the things they're trying to do is, uh, is move to a cons… a modeling.

01:22:58.000 --> 01:23:04.000
Um, a large modeling foundation, as opposed to a large language foundation.

01:23:04.000 --> 01:23:13.000
Because of the… of the ambiguities and the kind of the rough statistical quality of LLM approaches.

01:23:13.000 --> 01:23:20.000
Where instead, I would… I would suggest that… that that's not really… that language is the interchange modality.

01:23:20.000 --> 01:23:31.000
But concepts are what we really want to interconnect. And so we need to be so strict with ourselves about distinguishing between those different modalities.

01:23:31.000 --> 01:23:36.000
Um, and we have very little time left in this call, and I love… I love this particular thread.

01:23:36.000 --> 01:23:42.000
But I'm unclear on that, and would like to learn more. So, let's bounce to… we've got Gil Scott Rick.

01:23:42.000 --> 01:23:44.000
And maybe a poem.

01:23:44.000 --> 01:23:54.000
Yeah, let me try to be compact. Sean, it doesn't sound ludicrous, but I've got other things to say about it, which I'll come back to in a minute. I want to stir 3 or 4 other pots.

01:23:54.000 --> 01:24:01.000
That people have set boiling on the stove. Jerry, I'm intrigued by your problem with Improve.

01:24:01.000 --> 01:24:16.000
As being maybe too directive, but I wonder how else a human being can orient in that. Like, better is the same thing as improve, and… And it's all subjective, and, you know, there's always the possibility that one person's better as somebody else is worse, and so there you go.

01:24:16.000 --> 01:24:31.000
Which, of course, brings us to the RFK Jr. Thing, and the challenge of… of dancing with people where you agree on some things and disagree on some things, and we're in a moment in our culture where it seems to be all or nothing, black or white. If somebody's wrong on something, they're wrong on everything.

01:24:31.000 --> 01:24:39.000
But yesterday, we heard Marjorie Taylor Greene saying she's prepared to stand up in Congress and read the stuff that the Epstein victims have gathered.

01:24:39.000 --> 01:24:47.000
Into the public record. So, you know. The strange thing about United Fronts is that you don't have to agree on everything.

01:24:47.000 --> 01:24:50.000
We're in a topsy-turvy world, is all I can tell.

01:24:50.000 --> 01:24:57.000
Yeah, and um, um… what's her name? Blanking my name, um…

01:24:57.000 --> 01:25:04.000
Bernice Reagan, one of the founders of Sweet Honey and the Rock, was in the Freedom Singers in the early 1960s, and the Civil Rights Movement.

01:25:04.000 --> 01:25:11.000
Notably said at a conference in California back 30-some-odd years ago. He said, if you're in a coalition.

01:25:11.000 --> 01:25:16.000
And you're not deeply uncomfortable all the time. Your coalition's not big enough.

01:25:16.000 --> 01:25:21.000
And I think that's a challenge for us to consider now, because we're in a cultural moment that goes the other way.

01:25:21.000 --> 01:25:29.000
Scott, collaboration really resonated for me, the notion of collaboration as a skill.

01:25:29.000 --> 01:25:37.000
To develop. And a culture to develop, and ways of speaking and listening and being.

01:25:37.000 --> 01:25:41.000
That enable that, uh, is rich territory, and I hope we come back to that at some point.

01:25:41.000 --> 01:25:57.000
And, um, um… Sean and Joe say the hyper video, when I think about… I'm trying to write a book or two, and I keep on reminding myself, what if it's not a book? Book is, like, in quotes all the time, because that's one part of the…

01:25:57.000 --> 01:26:11.000
Artifact web that we're putting together here. I'm concerned, though. About the notion of… trying to get it all machine understandable, because I suspect there are things that the machines cannot and will never understand.

01:26:11.000 --> 01:26:26.000
And I think that's very important territory. And I'm not… I'm not drawn to trying to cram that into machine-understandable form. I'm trying… I'm concerned with finding ways that we can enrich that dimension of human.

01:26:26.000 --> 01:26:33.000
Being in the world of AIs and emerging alien intelligence and so forth. And so that's a mystery.

01:26:33.000 --> 01:26:41.000
For me that, uh, that's really juicy. And I suspect you guys are oriented to that. Now, Jerry, who is the third fellow traveler you mentioned?

01:26:41.000 --> 01:26:42.000
Marc-antoine Perron.

01:26:42.000 --> 01:26:53.000
Oh, okay, okay, great. Anyhow, I'm not prepared to dive into this project with you, but I'm very interested in staying aware of what you're up to.

01:26:53.000 --> 01:26:54.000
Brilliant. Brilliant, brilliant, brilliant. Um, Scott?

01:26:54.000 --> 01:27:00.000
Thank you all.

01:27:00.000 --> 01:27:03.000
They are muted.

01:27:03.000 --> 01:27:09.000
Very quickly, I also agree with Gil that the nature of improve doesn't bother me much.

01:27:09.000 --> 01:27:14.000
Um, I think if you're… open to feedback, you do your best, and…

01:27:14.000 --> 01:27:21.000
We're all searching for what better is. Um, so I'm good with that. Um, Ken.

01:27:21.000 --> 01:27:30.000
I made a… had a realization years ago that after leaving school, the only clean break we get is taking a new job.

01:27:30.000 --> 01:27:38.000
And I realized that I missed it. It was the semester break, it was the end, it was the new books, it was… you know what?

01:27:38.000 --> 01:27:43.000
However that went. It's done. And now I'm…

01:27:43.000 --> 01:27:53.000
And I… I missed it, because I was always working, and I never had that… that break, you know, when you work someplace for a decade, it's just the same. So…

01:27:53.000 --> 01:27:55.000
That's enough for me.

01:27:55.000 --> 01:28:12.000
Scott, thank you. And, um, if I may say, I think your question about is collaboration a thing, might be next Thursday's call topic. It sounds like a really nice thing to dive into, so… If you want to say… if you wouldn't mind sending me a message with a little bit, just a couple paragraphs on what you mean by your question.

01:28:12.000 --> 01:28:17.000
So that I aim toward what you mean, not toward what I'm thinking you mean.

01:28:17.000 --> 01:28:20.000
That would be great. Um, Rick, please.

01:28:20.000 --> 01:28:31.000
Yeah, I'm glad the scene of the… collaboration is ricocheting, because I think it's one of those things that's… it's quite complex, and we… we need to be much better at it.

01:28:31.000 --> 01:28:36.000
And to, uh, highlight a point that Gil was talking about, having a coalition big enough so you can have.

01:28:36.000 --> 01:28:46.000
More healthy disagreements, because that's where the greatest learning happens. I'll put in a point of view of difference here, which we won't have time to discuss.

01:28:46.000 --> 01:28:51.000
But, uh, when I heard Jose talking about, um, content curation.

01:28:51.000 --> 01:29:02.000
I'm actually more interested in process curation. And for that reason, I'm not interested in neobooks. I'm interested in neo-learning, which is more dynamic from my perspective, learning.

01:29:02.000 --> 01:29:07.000
And thinking about how we can use platforms for that, so it's much more agile.

01:29:07.000 --> 01:29:18.000
Uh, everything you said, I agree with. The elements of it, but… take it to the process level, because if we can't get our process sorted out, we can't do our collaboration. All the content and collaborations.

01:29:18.000 --> 01:29:29.000
Is useless unless we know how to do the process. So, um, just to demonstrate that I do listen to people about their criticisms about my compound, uh.

01:29:29.000 --> 01:29:34.000
Philosophical questions. I put a link in there, uh, for people who are curious.

01:29:34.000 --> 01:29:41.000
To understand compound philosophical questions, and the reasons why we have to shift to slow thinking to deal with complexity.

01:29:41.000 --> 01:29:48.000
And lastly, I go to a group, which some of you may know about, it's called CHO out of Belgium, which is a change management.

01:29:48.000 --> 01:29:53.000
Change agent group, and their focus is on collaboration. I'll put the link in there.

01:29:53.000 --> 01:30:04.000
Their meeting is on, uh, Friday mornings at, uh. I think it's 9… 8.45, uh, Eastern Time. I'll put the link in there as well, if people would like to.

01:30:04.000 --> 01:30:15.000
Learn from a European perspective about their thinking about, uh, collaboration, and that's what they're… Um, it's an interesting group, anyway, I'll put that link in as well.

01:30:15.000 --> 01:30:19.000
Thank you, Rick. Stacy, you're going to have the penultimate word.

01:30:19.000 --> 01:30:28.000
You know, real quick, because I was triggered by Marjorie Taylor Green, who I obviously would not want to be as a, you know, sit down to dinner with her, or be near her.

01:30:28.000 --> 01:30:34.000
That being said, I want to just highlight the importance. She really is a true believer, and I just want to.

01:30:34.000 --> 01:30:42.000
Highlight how important it is to deal with people that are true to their beliefs, whether or not we like them or not.

01:30:42.000 --> 01:30:49.000
To know that what we say is what they're gonna stand by, which is not what we have with most of the politicians.

01:30:49.000 --> 01:30:53.000
So I just want to, once again. Reiterate that, even in dealing with.

01:30:53.000 --> 01:30:57.000
Who we deal with in our lives. Over.

01:30:57.000 --> 01:31:06.000
Thank you very much, and… and… There's something about people being really authentic and true to their core, even if we hate what they're saying, that's important, and…

01:31:06.000 --> 01:31:11.000
We shouldn't just ignore or wander away from. So, thank you.

01:31:11.000 --> 01:31:14.000
Sir Ken.

01:31:14.000 --> 01:31:26.000
This poem is called Game by Maxine Koeman. Before he died, Archduke Ferdinand… Archduke Franz Ferdinand gunned down in Sarajevo to jumpstart World War I.

01:31:26.000 --> 01:31:34.000
Bragged that he had shot 3,000 stags, and the miscellaneous foxes, geese, wolves, and boars.

01:31:34.000 --> 01:31:42.000
Driven toward him by beaters. Staught men, he ordered to flush the creatures from their cover into his sights, a tradition.

01:31:42.000 --> 01:31:49.000
Of the British aristocracy, carried on. Further aped by rich Americans, from Teddy R. To Ernest H.

01:31:49.000 --> 01:31:56.000
Something Supreme Court Justice Antonin Scalia, Padgison of a Sicilian immigrant.

01:31:56.000 --> 01:32:06.000
Indulged in years later, when he had scores of farm-raised birds beaten from their cages and scared up for him to shoot down, which brought him an inner joy.

01:32:06.000 --> 01:32:11.000
What happened to him when he was a boy?

01:32:11.000 --> 01:32:16.000
God damn. Well, Ken, please, again?

01:32:16.000 --> 01:32:26.000
That's, like, wow. That's just, like, a layup poem, somehow. It's like… Completely non-obvious, but it's like, OMG, they went right to the heart of something important, so…

01:32:26.000 --> 01:32:29.000
Wow.

01:32:29.000 --> 01:32:39.000
Game, Maxine Kuhman. Before he died, Archduke Franz Ferdinand gunned down in Sarajevo to jumpstart World War I.

01:32:39.000 --> 01:32:44.000
Bragged that he had shot 3,000 stags and a miscellany of foxes.

01:32:44.000 --> 01:32:58.000
Geese, wolves, and boars. Driven toward him by beaters. Stout men, he ordered to flush creatures from their cover into his sights, a tradition of the British aristocracy, carried on.

01:32:58.000 --> 01:33:06.000
Further aped by rich Americans from Teddy R. To Ernest H. Something Supreme Court Justice Antonin Scalia.

01:33:06.000 --> 01:33:21.000
Pudgy son of Sicilian immigrants indulged in years later. When he had scores of farm-raised birds beaten from their cages and scared up for him to shoot down, which brought him an inner joy.

01:33:21.000 --> 01:33:31.000
What happened to him when he was a boy?

01:33:31.000 --> 01:33:32.000
Just awesome. Thank you. Sobering.

01:33:32.000 --> 01:33:34.000
Thank you.

01:33:34.000 --> 01:33:35.000
Thank you all. I think we've done it.

01:33:35.000 --> 01:33:36.000
Again, the author's name again?

01:33:36.000 --> 01:33:41.000
Maxine Kuman, uh, K-U-M-I-N.

01:33:41.000 --> 01:33:42.000
Thank you.

01:33:42.000 --> 01:33:49.000
Yeah, K-U-M-I-N, Maxine Koeman. And he will, as usual, post the poem to the OGM list so you can have it later.

01:33:49.000 --> 01:33:56.000
I think we have a nice topic for next Thursday. And, um, thank you for all showing up so beautifully.

01:33:56.000 --> 01:34:01.000
The ladies of OGM were underrepresented today, which makes me sad, but um… So it was, and…

01:34:01.000 --> 01:34:13.000
There we

