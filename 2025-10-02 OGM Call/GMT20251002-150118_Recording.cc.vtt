WEBVTT

00:00:04.000 --> 00:00:08.000
How to become funny? Are there any such people? I don't know.

00:00:08.000 --> 00:00:13.000
If there are, then maybe an AI could be. Engineered to do that. We'll work on that, Jerry.

00:00:13.000 --> 00:00:20.000
Excellent. Uh, you have tripped into the OGM weekly call for October 2nd, 2025.

00:00:20.000 --> 00:00:24.000
Alex was wondering if AI might be able to coach him to be a funnier person.

00:00:24.000 --> 00:00:27.000
Because he's normally very analytic,

00:00:27.000 --> 00:00:32.000
And, uh, that got us going on some fun stuff.

00:00:32.000 --> 00:00:41.000
So we'll wait a little bit until more people show up before we're diving into our topics for the day, but how is everybody?

00:00:41.000 --> 00:00:43.000
Surviving the Apocalypse?

00:00:43.000 --> 00:00:50.000
Good.

00:00:50.000 --> 00:00:52.000
Oh, if…

00:00:52.000 --> 00:00:53.000
Of course, it is a funny interjection, or is this a serious interjection?

00:00:53.000 --> 00:00:57.000
Can I explain something about the apocalypse? Because I believe it's supposed to… Which is…

00:00:57.000 --> 00:00:59.000
This is funny, actually, but only because it happened, not because I thought it up.

00:00:59.000 --> 00:01:01.000
See? It's working already.

00:01:01.000 --> 00:01:09.000
Um, my wife sent me… We have some… gold in a certain bank place, or whatever. Anyway.

00:01:09.000 --> 00:01:13.000
So, my wife sent me a text. Look at the value of gold, it's gone up too!

00:01:13.000 --> 00:01:19.000
Whatever, you know. So I… I replied, I said, oh my god, we're about to have a war.

00:01:19.000 --> 00:01:24.000
That's why the gold price shot up. And she said, she goes back, no.

00:01:24.000 --> 00:01:32.000
We're about to spend a lot. I'm gonna spend it…

00:01:32.000 --> 00:01:33.000
That's good, though, see? See? That worked.

00:01:33.000 --> 00:01:35.000
I'm analytical versus funny, you know, I went to the…

00:01:35.000 --> 00:01:42.000
And two different ways of seeing what happens when the price of your asset spikes.

00:01:42.000 --> 00:01:43.000
Oh my god, the world is coming to the end? Oh my god, we need to spend this.

00:01:43.000 --> 00:01:47.000
Exactly.

00:01:47.000 --> 00:01:52.000
I like it. Hi, Stacy!

00:01:52.000 --> 00:01:55.000
I'm just going to unseen just how people are feeling this morning.

00:01:55.000 --> 00:02:04.000
I see your dog is chewing on the pillow or something behind you. The pillow is wobbling.

00:02:04.000 --> 00:02:05.000
Oh, no!

00:02:05.000 --> 00:02:09.000
Um, yes, and he's now wearing a diaper. And I… and I look like this, so put it all together.

00:02:09.000 --> 00:02:12.000
Man, okay, so you just checked in really quick there, wasn't…

00:02:12.000 --> 00:02:16.000
Yeah, there we go. Um…

00:02:16.000 --> 00:02:19.000
Cool.

00:02:19.000 --> 00:02:25.000
As I said in the invite, uh, sent late last night,

00:02:25.000 --> 00:02:31.000
Today is a check-in call, but I'm also really interested in, uh, looking at OGM a bit.

00:02:31.000 --> 00:02:39.000
And I'm hoping more people join us on the call to do so, because I'd love some… a variety of opinions about what's up.

00:02:39.000 --> 00:02:41.000
But would love…

00:02:41.000 --> 00:02:45.000
Um, just feedback right now on what, uh…

00:02:45.000 --> 00:02:49.000
But let's just jump in the middle of this thing.

00:02:49.000 --> 00:02:51.000
what's… what's…

00:02:51.000 --> 00:02:55.000
working and not working about OGM calls and…

00:02:55.000 --> 00:03:01.000
lists and things like that.

00:03:01.000 --> 00:03:03.000
Can you just repeat what you said in the letter? Because I didn't see it.

00:03:03.000 --> 00:03:10.000
Yeah, um, so I just… I basically said that today's a check-in call, given our normal rhythms, the first Thursday of the month.

00:03:10.000 --> 00:03:18.000
but also, we're overdue for feedback on OGM itself, and there's been… I've been getting some emails from different people saying, hey,

00:03:18.000 --> 00:03:21.000
What about this, what about that? Then I'd love to just…

00:03:21.000 --> 00:03:26.000
open that up and, uh, you know, talk about it as a… as a group.

00:03:26.000 --> 00:03:28.000
as us. Uh, John.

00:03:28.000 --> 00:03:31.000
Yeah, good morning. So,

00:03:31.000 --> 00:03:32.000
Um, I…

00:03:32.000 --> 00:03:33.000
Thank you.

00:03:33.000 --> 00:03:36.000
am aware of these Thursday morning calls.

00:03:36.000 --> 00:03:42.000
I'm aware that there are some other calls that occur, uh, but I have no idea, like,

00:03:42.000 --> 00:03:48.000
when they are, or where the map is that tells me, like, what those are.

00:03:48.000 --> 00:03:52.000
That type of thing. I'm, um, aware of Plex now.

00:03:52.000 --> 00:03:57.000
And I'm part of the team that's stepping in and helping

00:03:57.000 --> 00:04:04.000
I'm failing in my responsibility coming out of the gate, but I'm committed, and I'm, um…

00:04:04.000 --> 00:04:11.000
Becoming aware of what Plex is and the community that it serves.

00:04:11.000 --> 00:04:17.000
Beyond that, I have zero understanding of, like, um…

00:04:17.000 --> 00:04:23.000
the whatever CSC matter most, um…

00:04:23.000 --> 00:04:31.000
you know, whether there are Slack channels, whether they're… I know that there are these other forms of communication,

00:04:31.000 --> 00:04:35.000
But I think as my comment suggests, I have… I have no…

00:04:35.000 --> 00:04:39.000
kind of conception of what they are, how they interrelate.

00:04:39.000 --> 00:04:42.000
And so, as a…

00:04:42.000 --> 00:04:47.000
emerging, uh, Plex contributor,

00:04:47.000 --> 00:04:56.000
that wants to serve the community by having what I post there be relevant to things, other things that are going on.

00:04:56.000 --> 00:04:59.000
I have this kind of low-level…

00:04:59.000 --> 00:05:06.000
anxiety that… that, like, I don't know what's going on, and so, like, am I really…

00:05:06.000 --> 00:05:09.000
am I really, like, well…

00:05:09.000 --> 00:05:13.000
qualified, or positioned or whatever to add value.

00:05:13.000 --> 00:05:17.000
you know, like, as a commentator on the community,

00:05:17.000 --> 00:05:20.000
Anyway, so that's my comment.

00:05:20.000 --> 00:05:21.000
Okay.

00:05:21.000 --> 00:05:31.000
Totally, John. So I can… I can put you at ease, because a lot of what you just described is sort of has gone away or is going away. You appear to be

00:05:31.000 --> 00:05:40.000
On the two things that are sort of in the… standing in the middle of OGM, which is the OGM mailing list on the Google group,

00:05:40.000 --> 00:05:41.000
Yeah.

00:05:41.000 --> 00:05:42.000
I'm sure you're on that, because I see that on that periodically. And these Thursday calls.

00:05:42.000 --> 00:05:45.000
There used to be 3-4 other standing calls a week,

00:05:45.000 --> 00:05:53.000
And, I don't know, 6, 7 months ago, I stepped out of them because I realized that those calls were spinning me up, and I was losing, like, half a day.

00:05:53.000 --> 00:06:01.000
Uh, on each one, and I needed to refocus my time. And I don't know that any of those calls have survived.

00:06:01.000 --> 00:06:13.000
Klaus is our Neobooks still meeting? I know that… I know that, um, Eric Rangel had sort of led some of them, but I don't know that they're still up. Do you know that they're still going?

00:06:13.000 --> 00:06:21.000
No, Jose was, uh, talking about, uh, starting a group, but then… Nothing happened that I'm aware of.

00:06:21.000 --> 00:06:24.000
Okay, um, and uh…

00:06:24.000 --> 00:06:31.000
the freezer's brain call hasn't… hasn't reconstituted in any way, so there were a couple other calls, and there was a wiki page up

00:06:31.000 --> 00:06:37.000
Uh, which I can share with you, which I should actually change now, because those calls don't exist anymore.

00:06:37.000 --> 00:06:45.000
And then, um, Pete has very kindly hosted the Mattermost server for us, Mattermost is the Slack open source alternative.

00:06:45.000 --> 00:06:49.000
or competitor, or something like that. And Pete very kindly was hosting a…

00:06:49.000 --> 00:06:52.000
matter, most instance for us and for several other

00:06:52.000 --> 00:06:54.000
communities that are kind of neighbors of ours.

00:06:54.000 --> 00:06:59.000
And the traffic has been really low on that, so he's deprecating that right about now.

00:06:59.000 --> 00:07:02.000
Pete, I don't know what your schedule is, or if you want to talk about that.

00:07:02.000 --> 00:07:07.000
But, uh, we're… we're kind of… we won't have that channel, and I'll add,

00:07:07.000 --> 00:07:15.000
that he also had stood up a discourse channel, not Discord, it's sort of a pain in the social media business that

00:07:15.000 --> 00:07:21.000
These platforms are so similarly named and relatively different from each other, but Pete had also stood up a discourse

00:07:21.000 --> 00:07:27.000
forum, uh, which we used for a while, and then that also tapered off, so that got archived.

00:07:27.000 --> 00:07:30.000
a year, year and a half ago, uh, some time back.

00:07:30.000 --> 00:07:32.000
Uh, but I don't know, Pete, if you want to, uh…

00:07:32.000 --> 00:07:34.000
Talk about those.

00:07:34.000 --> 00:07:45.000
Yeah, maybe I'll jump in a bit. I don't have to go over a lot of it, although I'm happy to answer questions. Um, John, I… a good heuristic

00:07:45.000 --> 00:07:48.000
And kind of the way that I thought of plaques,

00:07:48.000 --> 00:08:01.000
Back in the day, um, is you can just start talking about what you know, um, and hope that people will correct you when you get it wrong, or add when you've got it incomplete, or something like that.

00:08:01.000 --> 00:08:04.000
So, you don't have to feel super, um…

00:08:04.000 --> 00:08:11.000
defensive or, you know, self-whatever, um, about not knowing things, because if you just start talking,

00:08:11.000 --> 00:08:15.000
you know, uh, if the community is strong enough

00:08:15.000 --> 00:08:20.000
Um, you'll get plenty of people going, you know, hey, that's not right, or do you know about this?

00:08:20.000 --> 00:08:26.000
I have to say, I… as Jerry said, we used to have many more

00:08:26.000 --> 00:08:32.000
conversations going on, um, and we now have many fewer, it's more diffuse.

00:08:32.000 --> 00:08:43.000
Um… I… I… I know of a signal group that calls itself an OGM signal group. I think most people don't know about it, and it's not…

00:08:43.000 --> 00:08:47.000
meant to be a general, like, everybody from OGM should be there, so…

00:08:47.000 --> 00:08:52.000
Um, uh, Fellowship of the Link, uh, is another thing that…

00:08:52.000 --> 00:09:00.000
is kind of hanging on. I haven't been to calls for a long time, and I don't think we've been successful at doing them every time, um, but they still go on a little bit.

00:09:00.000 --> 00:09:08.000
Uh, it was yesterday that I posted in that group, hey, by the way, Mattermost is going away, we should reconvene someplace, and I suggested

00:09:08.000 --> 00:09:16.000
signal matrix, or Discord, and got two answers within 24 hours saying, yeah, signal or Discord is fine.

00:09:16.000 --> 00:09:21.000
Um, massive wiki, uh, is rehoming itself on…

00:09:21.000 --> 00:09:23.000
Um, on Matrix.

00:09:23.000 --> 00:09:27.000
Um… uh, there's…

00:09:27.000 --> 00:09:35.000
So… so maybe another way to say it is there are refugees in different places, um, and…

00:09:35.000 --> 00:09:42.000
Uh, somebody like John could go… go around and, you know, kind of ask, you know, hey, where are you hanging out?

00:09:42.000 --> 00:09:48.000
Uh, and then post that in something like the plaques or the list, uh, and kind of help

00:09:48.000 --> 00:09:55.000
As we, you know, diffuse a little bit, um, to stay in touch a little bit better than we could otherwise.

00:09:55.000 --> 00:10:01.000
the big replacements, I think, for Mattermost are Discord,

00:10:01.000 --> 00:10:04.000
And, uh, signal, and…

00:10:04.000 --> 00:10:07.000
matrix, each of them has their…

00:10:07.000 --> 00:10:11.000
pluses and minuses, um, and none of them…

00:10:11.000 --> 00:10:14.000
We're in a weird place now where…

00:10:14.000 --> 00:10:16.000
Um, matter most…

00:10:16.000 --> 00:10:25.000
is technically kind of the best that we could do, um, and we're not using it, so we're not going to use it. We don't… we don't get to use it, because I'm going to shut it down.

00:10:25.000 --> 00:10:29.000
Um, uh, every other thing is more…

00:10:29.000 --> 00:10:40.000
you know, either more commercial or more distributed, less, like, more decentralized, smaller. Um, and that's the way of the world right now. It's just the way it is.

00:10:40.000 --> 00:10:42.000
Thank you.

00:10:42.000 --> 00:10:54.000
Thanks, Pete. Also, I should say that, John, the fact that you didn't know where to look or whatever, it means I was… I… we were communicating badly. We, uh, you know, should have done more of that. We should have more of these.

00:10:54.000 --> 00:10:58.000
looking at ourselves calls anyway, so I'm glad we're doing… having this conversation.

00:10:58.000 --> 00:10:59.000
Rick, please. Oh, go ahead, John.

00:10:59.000 --> 00:11:07.000
Yeah, I… that may be true, Jerry, but, like, I also recognize from some of the conversations I've had with members here, like, I'm…

00:11:07.000 --> 00:11:09.000
I'm really, really new.

00:11:09.000 --> 00:11:11.000
And it seems like most…

00:11:11.000 --> 00:11:13.000
people that are in this group,

00:11:13.000 --> 00:11:18.000
are kind of long-term, like, they've been around a long time, so there's kind of this…

00:11:18.000 --> 00:11:21.000
like this institutional…

00:11:21.000 --> 00:11:27.000
you know, things that seem obvious to most of the community, because… because of the longevity of it.

00:11:27.000 --> 00:11:30.000
And so, it may just be a thing that, like,

00:11:30.000 --> 00:11:32.000
newbies…

00:11:32.000 --> 00:11:36.000
you know, are in the dark, but only because…

00:11:36.000 --> 00:11:40.000
It's a longer-term…

00:11:40.000 --> 00:11:44.000
community than that, right? Like, it's not really built for brand new people.

00:11:44.000 --> 00:11:52.000
Sort of yes and no, and that last thing you said I want to pick up. You're feeling kind of OG to me, John, so I don't know how newbie you are anymore.

00:11:52.000 --> 00:11:53.000
Oh, okay.

00:11:53.000 --> 00:11:56.000
Uh, the bloom is off the rose, so to speak.

00:11:56.000 --> 00:11:58.000
Um, but…

00:11:58.000 --> 00:12:12.000
I think not signposting well is what makes some communities unwelcoming, or hard to get into, or… and you don't really want to have a community where it's clear there's an OG, and they have their secrets and their secret handshakes and whatever else.

00:12:12.000 --> 00:12:13.000
Yeah.

00:12:13.000 --> 00:12:17.000
And you're just gonna have to figure them out somehow. That's not… that's not the thing we want to do or have.

00:12:17.000 --> 00:12:18.000
Yeah. Well, and that's my rate…

00:12:18.000 --> 00:12:20.000
Uh, so… so you're kind of gently… you're gently pointing these things out.

00:12:20.000 --> 00:12:25.000
That's my main reason for speaking up, right, is just… yeah, because sometimes that new…

00:12:25.000 --> 00:12:33.000
new view is, oh, you know, like, to the people that have been around a while, it's a little bit like, oh, I didn't know it looked like that, you know?

00:12:33.000 --> 00:12:39.000
Exactly. And just to… before you go to Rick, to point out what Pete was just describing with all the different platforms,

00:12:39.000 --> 00:12:46.000
We're at a moment where we should discuss, do we want our shift platforms, add a platform, do something like that.

00:12:46.000 --> 00:12:51.000
Uh, what might we want to do, and what are the factors to blend into that kind of a decision?

00:12:51.000 --> 00:12:53.000
Rick.

00:12:53.000 --> 00:12:56.000
Yeah, maybe I could just share a perspective, because I…

00:12:56.000 --> 00:13:01.000
I go between different groups, so I don't have the group that I go to.

00:13:01.000 --> 00:13:04.000
So I've studied how groups evolve over time.

00:13:04.000 --> 00:13:07.000
And I'll tell you a story that…

00:13:07.000 --> 00:13:11.000
brings up to question, does this group want to grow or not?

00:13:11.000 --> 00:13:15.000
I think it's a critical question. If he doesn't want to grow, that's fine.

00:13:15.000 --> 00:13:26.000
Uh, you know, it's for the group to decide that for a lot. But to John's point, I think… and I've witnessed this in other groups, that some groups don't do a very good of onboarding people. I mean, doing a deliberate onboarding, engaging,

00:13:26.000 --> 00:13:29.000
Having a buddy system or something like that,

00:13:29.000 --> 00:13:37.000
So that people, no matter how well community, there is still an inside-out dynamic, even though if you don't see it, if you're on the inside, so…

00:13:37.000 --> 00:13:40.000
I think John's point is very valid.

00:13:40.000 --> 00:13:45.000
Um, so I think the critical question, do you want to grow or not? If you don't, that's fine. If you do, then

00:13:45.000 --> 00:13:50.000
Obviously, the fact that this, uh, this community has gone through its biorhythms,

00:13:50.000 --> 00:13:54.000
of being more expansive is now contracting.

00:13:54.000 --> 00:13:58.000
It has to decide, does it want to do that? And I'll just tell you a brief story that…

00:13:58.000 --> 00:14:02.000
highlights some of this. I belong to EXO, I go to the mastermind groups.

00:14:02.000 --> 00:14:06.000
Um, and they had an AI group that was affiliated.

00:14:06.000 --> 00:14:11.000
They had a fallout. It was interesting. I couldn't understand it. Why would they have a fallout, you know? I mean…

00:14:11.000 --> 00:14:14.000
And so the AI group went off in a different direction.

00:14:14.000 --> 00:14:18.000
Then it morphed and changed with new leadership. It's now expanding.

00:14:18.000 --> 00:14:24.000
And it's now doing something I've seen other groups, and this group's experience it too, where you get a spin-off group.

00:14:24.000 --> 00:14:28.000
So, the suspendoff group from this AI group that's interested

00:14:28.000 --> 00:14:33.000
in, uh, they started off focusing on, uh, human flourishing, and I said, we have to have

00:14:33.000 --> 00:14:39.000
human and planetary fur. Are you going to expand it to that? If you are, then I'd be interested in that group.

00:14:39.000 --> 00:14:44.000
So it's a fledgling group. And to me, this speaks to sort of, like, the mycelium

00:14:44.000 --> 00:14:48.000
nature of these things. What are the inhibitory and, uh…

00:14:48.000 --> 00:14:51.000
Um, pro-growth strategies.

00:14:51.000 --> 00:14:54.000
And until you answer the question, do you want to grow or not?

00:14:54.000 --> 00:14:59.000
then, you know, it's difficult to make any concrete suggestions about expansion.

00:14:59.000 --> 00:15:05.000
I'll give you one reference, Jory, which a group that I used to belong to, but left because I didn't find it.

00:15:05.000 --> 00:15:09.000
It was a men's group called METL, which I know you've presented at.

00:15:09.000 --> 00:15:13.000
But what's interesting about that group is they're very effective

00:15:13.000 --> 00:15:21.000
at having… they must… at the time, they must have had 50 different groups clustering infinities, crypto, this, this, this, this, and this.

00:15:21.000 --> 00:15:28.000
And, um, I left the group because it was apolitical, and I had other issues with it, but it was an incredible experience.

00:15:28.000 --> 00:15:34.000
to see how a group that purports to be apolitical when it wasn't,

00:15:34.000 --> 00:15:37.000
Which was the part of the irony.

00:15:37.000 --> 00:15:41.000
Um, would have these different, you know, groups, breast groups, whatever.

00:15:41.000 --> 00:15:48.000
So the critical question, do you want to grow or not? Or are you quite happy as it is? And maybe once a week on Thursday is all that's needed?

00:15:48.000 --> 00:15:50.000
So, I'm not vested in any way,

00:15:50.000 --> 00:15:55.000
Uh, it's, you know, I pop in because I get a few new ideas, go away and think about it.

00:15:55.000 --> 00:15:59.000
So, you know, I think you have to decide, Jerry, whether you want to

00:15:59.000 --> 00:16:01.000
create something that's more…

00:16:01.000 --> 00:16:13.000
self-organizing, self-generating, self-governing, if you want to have spin-off affinity groups, because people have this niche that they want to follow for a period of time, and whatever.

00:16:13.000 --> 00:16:18.000
So, uh, I think that's the question the group needs to ask itself.

00:16:18.000 --> 00:16:25.000
Thanks, Rick. Um, that's really useful. And yes, the metal thing I spoke at once, I was invited to speak, and I came in,

00:16:25.000 --> 00:16:32.000
And I… the group's dynamic wasn't something I particularly liked. I think they meet Saturday mornings or something like that for several hours, and they've got kind of a programmatic approach to it.

00:16:32.000 --> 00:16:35.000
Oh, yeah.

00:16:35.000 --> 00:16:40.000
But you reminded me of a really good… one of Malcolm Gladwell's better articles is called The Cellular Church.

00:16:40.000 --> 00:16:47.000
And I just put a link to it in the chat, um, somebody tell me if that is an open link or not. I think it is.

00:16:47.000 --> 00:16:52.000
And he talks about the Saddleback Church, where Rick Warren was a pastor.

00:16:52.000 --> 00:16:55.000
Mm-hmm. Right.

00:16:55.000 --> 00:16:56.000
Because…

00:16:56.000 --> 00:17:01.000
And how… and how giant the church became because they had… the quilting group, the downhill bikers,

00:17:01.000 --> 00:17:02.000
Yeah, exactly.

00:17:02.000 --> 00:17:03.000
you know, they basically created little cells where everybody had a common interest,

00:17:03.000 --> 00:17:07.000
And they… once a year, they would get together in a local football stadium.

00:17:07.000 --> 00:17:13.000
Because there were so many of them, they couldn't all fit in the church they had. So it was really pretty interesting.

00:17:13.000 --> 00:17:18.000
And I think the question about, do we want to grow is a really nice question for the group. I don't think it's for me.

00:17:18.000 --> 00:17:32.000
And funny you mention onboarding and all that. Early in OGM, 2020, 2021, we had a bunch of meetings and conversations about onboarding, who wants to be involved in onboarding, also outreach, who wants to bridge to other communities.

00:17:32.000 --> 00:17:42.000
then those didn't turn into any resources that we wound up finishing or whatever. The efforts kind of petered out.

00:17:42.000 --> 00:17:49.000
it's kind of a characteristic of OG, and I'm gonna overgeneralize here, that we have lovely salons, but we don't get a lot of things done.

00:17:49.000 --> 00:17:53.000
There are other communities that create bodies of work,

00:17:53.000 --> 00:17:59.000
Whether it's wiki pages or pattern languages, or code, or something else.

00:17:59.000 --> 00:18:03.000
Um, we've not, and we have kind of a hardy, true…

00:18:03.000 --> 00:18:08.000
Um, here, uh, which is, like, well represented right now, right here.

00:18:08.000 --> 00:18:17.000
Uh, and maybe this is a salon for us, and maybe we want to keep it going, maybe we don't. I don't… I'm open to all suggestions.

00:18:17.000 --> 00:18:21.000
I'm not focused on growth, growth, growth.

00:18:21.000 --> 00:18:29.000
I find if… it's very funny, I find if these calls went larger than one screen worth of Zoom gallery,

00:18:29.000 --> 00:18:32.000
I would probably have a harder time in them,

00:18:32.000 --> 00:18:37.000
And enjoy them a little less, because I like, I really like… so that takes us up to…

00:18:37.000 --> 00:18:44.000
whatever… whatever size is it 64 now that you can sort of max out on a reasonable screen on Zoom?

00:18:44.000 --> 00:18:54.000
Maybe that's the size, I don't know. But, um, I really like seeing everybody's faces and being able to see expressions, and if somebody's, like, leaning back in the corner or whatever else, that's… that makes it very, um,

00:18:54.000 --> 00:18:56.000
convivial to me.

00:18:56.000 --> 00:19:03.000
And then, last thing, Rick, the group that's split and all that, was that the OpenXO community? Is that the group you were talking about, or is that someone else?

00:19:03.000 --> 00:19:07.000
No, you see, uh, it was the EXO community.

00:19:07.000 --> 00:19:08.000
Oh, okay.

00:19:08.000 --> 00:19:12.000
Um, but they… they had an AI subgroup that independently just ran,

00:19:12.000 --> 00:19:19.000
And there was a fallout between the leadership between the two groups. Interestingly leadership, the AI outgroup

00:19:19.000 --> 00:19:23.000
uh, moved on, and it's now got new leadership, and it's getting a second win.

00:19:23.000 --> 00:19:26.000
They're coming to your point of what you just said,

00:19:26.000 --> 00:19:31.000
I agree with you, you want to have intimacy groups, but if you design it in such a way that you have

00:19:31.000 --> 00:19:37.000
Subgroups, or you break into groups, or whatever, you… you can… but it's a question of whether you want to do that, or whether the interest… I mean,

00:19:37.000 --> 00:19:38.000
Well, the last… yeah.

00:19:38.000 --> 00:19:40.000
To me, the issue is,

00:19:40.000 --> 00:19:45.000
Can people follow their passion and connect with people who fail passionate about

00:19:45.000 --> 00:19:47.000
the areas that they're interested in.

00:19:47.000 --> 00:19:50.000
So, you're creating affinity groups.

00:19:50.000 --> 00:19:57.000
And, you know, that… you know, to be honest, I don't think the design of this group as it is now is designed for that purpose.

00:19:57.000 --> 00:20:01.000
And that's fine for what it's doing now, but if it wanted to be able to…

00:20:01.000 --> 00:20:07.000
uh, you know, have, uh, these mycelium spin-offs or whatever, then you would have to…

00:20:07.000 --> 00:20:09.000
I think have a different design.

00:20:09.000 --> 00:20:10.000
But that's up to you guys, I mean…

00:20:10.000 --> 00:20:20.000
Um, actually… actually, Rick, the groups that… in answering John's question about what about those other meetings, when I said that there were other groups that I stepped out of,

00:20:20.000 --> 00:20:21.000
Um, yeah, that's good.

00:20:21.000 --> 00:20:24.000
Those were, in fact, little mycelial rhizomal spin-outs, exactly like you're saying.

00:20:24.000 --> 00:20:27.000
And…

00:20:27.000 --> 00:20:28.000
Right.

00:20:28.000 --> 00:20:29.000
Yeah, yeah, exactly. And my question is, do you want to rekindle it? Or, I mean, maybe the wrong metaphor.

00:20:29.000 --> 00:20:31.000
But, uh, do you want to re-nurture it?

00:20:31.000 --> 00:20:37.000
Kindling is fine. Uh, good, we've got a bunch of people who'd love to chip in. John, back to you.

00:20:37.000 --> 00:20:42.000
Yeah, just one sentence, a companion, I think, to Rick's question is… is…

00:20:42.000 --> 00:20:48.000
a super important question. Do you want to grow? But I think the companion question is, in what ways, you know, in what?

00:20:48.000 --> 00:20:52.000
In what manner, in what dimensions, what directions?

00:20:52.000 --> 00:20:56.000
Um, because as you said, growth…

00:20:56.000 --> 00:21:01.000
growth itself is a little bit of a ridiculous goal if it doesn't have a…

00:21:01.000 --> 00:21:06.000
you know, some… something more of a guiding intention to it, I think.

00:21:06.000 --> 00:21:11.000
Yep. Thanks, John. Alex?

00:21:11.000 --> 00:21:18.000
Um, my contribution to this is as follows. I feel very different from you guys, okay?

00:21:18.000 --> 00:21:28.000
But that's why I like being here. I don't believe I'm on the, say, political affiliation as you guys. I don't believe I'm on any topic, literally. I listen to you guys, and I think.

00:21:28.000 --> 00:21:35.000
I don't agree with that. But that's what I value. Because otherwise, I'm not going to listen to anybody.

00:21:35.000 --> 00:21:44.000
Doesn't agree with me. And sadly, I haven't found a group of people who totally agree with me, if they did, would… wouldn't exist.

00:21:44.000 --> 00:21:50.000
But the point is that I value the diversity of views.

00:21:50.000 --> 00:21:54.000
Now, I do get frustrated sometimes. I think, oh, we should expand more on this or that.

00:21:54.000 --> 00:21:57.000
But as you say, we can form subgroups, we can do all sorts of things.

00:21:57.000 --> 00:22:04.000
Beyond that. But, um, there's a limit how many groups you can join any one week.

00:22:04.000 --> 00:22:08.000
And I find this the most… all-encompassing, kind of.

00:22:08.000 --> 00:22:11.000
Divergent views kind of group.

00:22:11.000 --> 00:22:19.000
Um, thanks very much. That's super interesting. Maybe you need to start your own movement. Maybe you're unique in your cluster of perspectives, and uh…

00:22:19.000 --> 00:22:23.000
A bunch of people would show up for you.

00:22:23.000 --> 00:22:27.000
Yes, they would, but then they'd be my people, my ideas.

00:22:27.000 --> 00:22:31.000
Sorry, not my ideas, but my, sort of, you know, you form your own, kind of, thinking, whatever.

00:22:31.000 --> 00:22:35.000
Great.

00:22:35.000 --> 00:22:36.000
Love that.

00:22:36.000 --> 00:22:39.000
That's what I'm fighting against. That's what I'm finding. I'm not right at everything.

00:22:39.000 --> 00:22:40.000
Love that. Thanks, Alex. Uh, Pete.

00:22:40.000 --> 00:22:46.000
You know.

00:22:46.000 --> 00:22:51.000
I kind of suggested to John a heuristic for

00:22:51.000 --> 00:22:57.000
for finding out more, um, you know, publish what you know and see who complains or adds.

00:22:57.000 --> 00:23:05.000
Um, I… thinking about it, I also wanted to share another one for individuals, more than somebody publishing.

00:23:05.000 --> 00:23:10.000
Um, uh, I feel like I'm… there… there are still…

00:23:10.000 --> 00:23:15.000
OGM-adjacent groups that are… that continue to form.

00:23:15.000 --> 00:23:17.000
Um, it's not…

00:23:17.000 --> 00:23:25.000
it's still going on. Um, and the way I know about some of those is because I'm in touch with

00:23:25.000 --> 00:23:27.000
the person starting that group.

00:23:27.000 --> 00:23:35.000
So, uh, another heuristic is to ask the people that you find interesting, hey, where are you hanging out?

00:23:35.000 --> 00:23:40.000
Um, are you doing some stuff about, you know, XYZ topic?

00:23:40.000 --> 00:23:50.000
Um, do you know somebody who is? And, uh, within the OGM community, there's a bunch of people who are continually doing things, um, or…

00:23:50.000 --> 00:23:55.000
willing to do things with you if, you know, if you said,

00:23:55.000 --> 00:24:01.000
hey, I need to, you know, I'm interested in working on this topic.

00:24:01.000 --> 00:24:05.000
and, you know, could we join up and do something together? Could we start some calls?

00:24:05.000 --> 00:24:11.000
Um, that's… all of that is totally within the bounds of, kind of, what OGM

00:24:11.000 --> 00:24:18.000
has been doing, and is continuing to do even now. You know, I've… there's a couple subgroups that I've joined in the past

00:24:18.000 --> 00:24:37.000
month, you know. Um, they're not for everybody, um, but they're, you know, it's happening. Um, I was going to… I'm gonna find a link on the OGM wiki about, you know, how to start a group or something like that. There's a page on that, and I'll put that in the chat.

00:24:37.000 --> 00:24:40.000
Um, thanks, Pete.

00:24:40.000 --> 00:24:44.000
Stacy, please.

00:24:44.000 --> 00:24:46.000
You are muted.

00:24:46.000 --> 00:24:51.000
Yep, yep, yep.

00:24:51.000 --> 00:24:57.000
Let's see if I can describe this properly. Um, towards the idea of growth.

00:24:57.000 --> 00:25:03.000
I'm thinking of the inner growth. And I'm thinking that at this point, with the people I know at OGM.

00:25:03.000 --> 00:25:10.000
I really do feel like I'm one degree of separation away from anybody I'm ever gonna need to know or want to know.

00:25:10.000 --> 00:25:15.000
That's really how I… and my personal life, too, just in general.

00:25:15.000 --> 00:25:25.000
I look at every one of us as a page. On my own page. The most valuable thing that's happened in this group for me, Pete, it's your archive.

00:25:25.000 --> 00:25:32.000
That archive was very valuable, and I think it's important to this conversation.

00:25:32.000 --> 00:25:38.000
When I went into that archive, I was able to find something that I wrote that's a part of my page.

00:25:38.000 --> 00:25:44.000
I was able to bring it to somebody. Who's in a totally different community.

00:25:44.000 --> 00:25:50.000
But is connected to people in this community. I see somebody right here that.

00:25:50.000 --> 00:25:59.000
That he's connected to. Um, I've spoken to him in other places. Like, there's, like, just, we're all connected in so many different places.

00:25:59.000 --> 00:26:06.000
But in this case, I'm the page. That I carried to make those connections.

00:26:06.000 --> 00:26:10.000
I'm wondering if there's a way that when we have a call.

00:26:10.000 --> 00:26:19.000
It could be archived in that same way. So that we could add those pieces to our pages, because to me.

00:26:19.000 --> 00:26:27.000
It's the members that are important. And it's the members that go to the different places and make up those different groups.

00:26:27.000 --> 00:26:35.000
And, um… what else did I want to add? I think I'll stop for now, but um…

00:26:35.000 --> 00:26:42.000
Oh, I just want to say. Because there's so many different stories.

00:26:42.000 --> 00:26:49.000
And every piece of information is part of a story, but… Jerry might need more pieces of that story.

00:26:49.000 --> 00:26:54.000
And maybe I don't want to give Klaus as many of those pieces, because it'll confuse things.

00:26:54.000 --> 00:27:03.000
What I've been doing, because I want people like Sean to see the whole story, so that when he's building, he'll know what my needs are.

00:27:03.000 --> 00:27:09.000
I've just been saying everything, all the time, and it's been really hard for me to do that.

00:27:09.000 --> 00:27:14.000
So I'll put things on the OGM mailing list. I don't know who's reading it.

00:27:14.000 --> 00:27:23.000
I am pretty sure that anybody in this call. Will kind of see it. And if they don't, I know they're gonna hear it from me personally.

00:27:23.000 --> 00:27:28.000
So I've kind of, you know, I'm working my odds. Good chance they're gonna get that information.

00:27:28.000 --> 00:27:34.000
Whoever else sees it, I don't know, I don't care. As far as the Plex goes.

00:27:34.000 --> 00:27:42.000
I have no clue who reads it. Do we know? I mean, do you… Are you, like, measuring who actually reads it?

00:27:42.000 --> 00:27:48.000
Because if I have a question. I'll go first to the OGM mailing list.

00:27:48.000 --> 00:27:54.000
And then maybe I'll put it in the Plex, because honestly, I have no idea who the audience is.

00:27:54.000 --> 00:28:03.000
Ogm mailing lists have a little bit of an idea. And it's worth it. And, uh, again, I think there's something to… somebody mentioned earlier about.

00:28:03.000 --> 00:28:11.000
Many different interests. I think it's kind of good that there's a place where it starts, where it's, um…

00:28:11.000 --> 00:28:19.000
Not so diffuse and diverse. Because not all the pages need to go into the all of the books.

00:28:19.000 --> 00:28:21.000
Okay, now I'm done. Over.

00:28:21.000 --> 00:28:25.000
Um, Stacy, thank you. Uh, Pete, do you wanna…

00:28:25.000 --> 00:28:28.000
addressed a little bit that went to you?

00:28:28.000 --> 00:28:30.000
Uh…

00:28:30.000 --> 00:28:36.000
I… Stacy had an interesting question about who reads the plaques. Um, I…

00:28:36.000 --> 00:28:42.000
I know a little bit, and I actually kind of purposely don't…

00:28:42.000 --> 00:28:46.000
try to analyze that or count, you know, count reads or anything like that.

00:28:46.000 --> 00:28:49.000
Because I think it's… I don't know.

00:28:49.000 --> 00:28:53.000
Um, I like that people can…

00:28:53.000 --> 00:28:56.000
you know, read in private, oddly enough.

00:28:56.000 --> 00:29:01.000
I don't know. Um, so there's a… there's a missing function there where it would be nice to

00:29:01.000 --> 00:29:05.000
to have a better idea of, you know, who's in the audience, and…

00:29:05.000 --> 00:29:08.000
And, um…

00:29:08.000 --> 00:29:18.000
Uh, if the audience should be expanded, could be expanded, something like that, I don't know. I… I'm not super interested in that kind of functionality.

00:29:18.000 --> 00:29:19.000
Thanks, Pete. Please go ahead, Stason.

00:29:19.000 --> 00:29:28.000
Can I just say something? Can I just jump in? It's not about… it's not about to… like, an audience so that I could sell them something, it's like.

00:29:28.000 --> 00:29:29.000
Right.

00:29:29.000 --> 00:29:34.000
Who am I telling it to? You know, I'm not gonna come to this group and say, listen, there's a women's poetry circle.

00:29:34.000 --> 00:29:37.000
Tomorrow, you know, this isn't the group I'm going to announce it to.

00:29:37.000 --> 00:29:39.000
So it's just about knowing where to bring the message.

00:29:39.000 --> 00:29:49.000
Yeah, I completely understand, and I've, for better or for worse, by the way, I'm not publishing Plex anymore, Kevin is.

00:29:49.000 --> 00:29:56.000
Uh, and he's gonna make his own decisions. His idea, his conception, as far as I understand, is actually to

00:29:56.000 --> 00:30:00.000
to be mostly about OGM. Um…

00:30:00.000 --> 00:30:05.000
for whatever reason. You know, and maybe this is a good…

00:30:05.000 --> 00:30:13.000
place to interject. A thing that I always wanted with the plaques, and I felt like I was marginally successful, and mostly I felt like I failed,

00:30:13.000 --> 00:30:15.000
was kind of exactly…

00:30:15.000 --> 00:30:25.000
something that we're talking about here, who's doing what where? How can I find out who's doing more? Or, you know, when I know a little bit, can I find out more about something?

00:30:25.000 --> 00:30:29.000
Um, it… it turned out to be devilishly difficult, I found.

00:30:29.000 --> 00:30:33.000
Um, to get that kind of information from people, and to…

00:30:33.000 --> 00:30:35.000
to get that kind of information from people.

00:30:35.000 --> 00:30:39.000
And it's not because people are closed-lipped, it's because

00:30:39.000 --> 00:30:43.000
If you ask me, hey, Pete, where do you hang out? It's like…

00:30:43.000 --> 00:30:52.000
Today, I'm hanging out with, uh… I was gonna hang out with Jesse today, you know? Does that matter to you? Do you care? Do you, like… is that the… and I won't tell you…

00:30:52.000 --> 00:30:57.000
you know, the 3 or 4 other things that are coming up this month that aren't currently in my head, right?

00:30:57.000 --> 00:31:06.000
Um, it's… it's really difficult. Um, I… another good example of somebody who's doing a lot of amazingly cool stuff, and…

00:31:06.000 --> 00:31:11.000
you know, it doesn't have the time to talk about it, Vincent Arena. He's doing a massively

00:31:11.000 --> 00:31:15.000
amazing project, and, you know, he's always

00:31:15.000 --> 00:31:18.000
thoughtful and helpful when you ask them a question.

00:31:18.000 --> 00:31:26.000
But he doesn't have a lot of time to, like, sit around and brainstorm with folks, you know, hey, this is the kind of thing that's going on, you should know this, you should know that.

00:31:26.000 --> 00:31:29.000
Uh, we're missing a…

00:31:29.000 --> 00:31:35.000
not OGM. We, the global we, um, everybody is missing a…

00:31:35.000 --> 00:31:38.000
matchmaking function, uh, a way of…

00:31:38.000 --> 00:31:40.000
finding out, you know,

00:31:40.000 --> 00:31:45.000
from your friends, and your friends of friends, and your friends of friends of friends.

00:31:45.000 --> 00:31:56.000
what are the things that you all know about that I would find interesting, right? We haven't cracked that nut. It's a really difficult thing to know who's saying what. So, to come back to your

00:31:56.000 --> 00:32:00.000
your kind of questioning and your thought there, Stacy.

00:32:00.000 --> 00:32:10.000
my heuristic for the plaques was, like, I'm gonna publish whatever I want to in the plaques. I didn't really know, I didn't have a good understanding of what to publish.

00:32:10.000 --> 00:32:12.000
who found…

00:32:12.000 --> 00:32:21.000
Uh, who found Charles' little videos interesting, or who found them, you know, distracting, uh, who cared about, uh, this interview or that interview? I don't…

00:32:21.000 --> 00:32:23.000
I don't know. I didn't look at readership.

00:32:23.000 --> 00:32:26.000
I… and I didn't really care.

00:32:26.000 --> 00:32:30.000
Because I think…

00:32:30.000 --> 00:32:33.000
It's a little bit hard to describe, but…

00:32:33.000 --> 00:32:45.000
I know you're not interested in, like, oh, I need more advertising views, and I want to be able to resell, package, and resell eyeballs. I know you're not talking about that, but it's kind of… I felt like it's kind of a slippery slope.

00:32:45.000 --> 00:32:48.000
Um, and…

00:32:48.000 --> 00:32:53.000
I don't know. I… the… a thing…

00:32:53.000 --> 00:32:57.000
in plaques, I felt this…

00:32:57.000 --> 00:33:05.000
concern or thinking, or something like that, I wanted to give people agency and…

00:33:05.000 --> 00:33:07.000
And let them…

00:33:07.000 --> 00:33:10.000
permit me to do things, rather than…

00:33:10.000 --> 00:33:18.000
Saying, well, I'm gonna do this because you've joined this collective, right? I'm going to count you, I'm going to, you know, understand

00:33:18.000 --> 00:33:22.000
Whether or not I should post something about knitting, or whatever, right?

00:33:22.000 --> 00:33:25.000
Um… uh…

00:33:25.000 --> 00:33:27.000
I think it's…

00:33:27.000 --> 00:33:29.000
I think we…

00:33:29.000 --> 00:33:33.000
Too often, we assume that

00:33:33.000 --> 00:33:37.000
people can be collected into…

00:33:37.000 --> 00:33:39.000
you know, into categories.

00:33:39.000 --> 00:33:46.000
Even in benign categories, uh, benignly collected, when… I don't… I don't… I don't feel that way. You know, I think…

00:33:46.000 --> 00:33:55.000
Um, and so then we end up in this weird conundrum, right? I could have helped Plex a lot more, probably, if I knew what Plex was interested in.

00:33:55.000 --> 00:34:01.000
And if I said, hey, here's an edge where we're almost interested in this as a group,

00:34:01.000 --> 00:34:09.000
But we're not talking about it. Let me push this edge a little bit. Let me start doing that, right? And see who catches on, who enjoys that.

00:34:09.000 --> 00:34:14.000
That would make it more of a collective brain, more of a collective thinking process, right?

00:34:14.000 --> 00:34:17.000
Um, I didn't have the…

00:34:17.000 --> 00:34:24.000
I didn't have, and I didn't want to, create the opt-in for that, um, because opt-ins are…

00:34:24.000 --> 00:34:29.000
are kind of a pain. Um, so it's weird. It's a weird problem of…

00:34:29.000 --> 00:34:37.000
Like, how… how do we know… how do we find out about people? How do we ask people if it's okay to find out about them?

00:34:37.000 --> 00:34:41.000
all that kind of stuff. It's… it's hard.

00:34:41.000 --> 00:34:46.000
Uh, there's a bunch of stuff I want to put into the conversation that's kind of OGM history, but first you go, Stacy.

00:34:46.000 --> 00:34:54.000
Yeah, real quick, could we have had, like, a like or a comment function? Because to me, that would have been the perfect platform right there.

00:34:54.000 --> 00:35:01.000
Um, yes. Yes. There should have been likes and comments, there should have been, um…

00:35:01.000 --> 00:35:04.000
There should have been individual article addressing.

00:35:04.000 --> 00:35:06.000
All of that stuff is work.

00:35:06.000 --> 00:35:10.000
Um, and, you know, and…

00:35:10.000 --> 00:35:13.000
Even something like likes.

00:35:13.000 --> 00:35:15.000
it's…

00:35:15.000 --> 00:35:22.000
we… we got trained by Facebook and Amazon, where they have really good rating systems.

00:35:22.000 --> 00:35:29.000
Facebook… well, actually, both of those are good and bad, right? They're evil in a way.

00:35:29.000 --> 00:35:32.000
Um, but they have enough velocity and throughput

00:35:32.000 --> 00:35:37.000
to be able to do statistically interesting and useful stuff, right?

00:35:37.000 --> 00:35:47.000
something like plaques is so small that adding a function that Amazon has, like reviews, or something that Facebook has, like likes or whatever they do nowadays,

00:35:47.000 --> 00:35:59.000
Um, it's… it's nearly meaningless. You know, one like here, one like there is not enough for me to have done all the work to make sure that the like, um, the like, uh…

00:35:59.000 --> 00:36:02.000
infrastructure is there, right?

00:36:02.000 --> 00:36:08.000
Another… another weird problem. Um, uh, in… in small group dynamics.

00:36:08.000 --> 00:36:20.000
You don't get the same… even… and maybe a way to illustrate this, and sorry to go on kind of on a detail here, but it's another important illustration of a problem.

00:36:20.000 --> 00:36:30.000
Um, if I go to Substack, oh my gosh, Substack has got amazing throughput of, like, people reading stuff, and they're pushing viewers all over the place, and…

00:36:30.000 --> 00:36:33.000
When somebody posts an amazing article,

00:36:33.000 --> 00:36:41.000
I want to go and say, you know, is this article more amazing than other articles? What are other articles that are amazing like this one, right?

00:36:41.000 --> 00:36:45.000
I see one or two likes, you know, and…

00:36:45.000 --> 00:36:59.000
it's… it's interesting and almost… it's not that useful. It's… it's, you know, Medium is finally kind of getting to the point with their clap thing that it's kind of… I can kind of tell what's interesting and kind of not.

00:36:59.000 --> 00:37:02.000
But not in the way that…

00:37:02.000 --> 00:37:06.000
that, God forbid, X is, you know?

00:37:06.000 --> 00:37:08.000
Um, on X, you can kind of tell…

00:37:08.000 --> 00:37:12.000
tell what's going on from the traffic and volumes.

00:37:12.000 --> 00:37:14.000
And another aside…

00:37:14.000 --> 00:37:19.000
Sorry, I need to get even more technical. Um, the big… the big

00:37:19.000 --> 00:37:21.000
platforms like Twitter or…

00:37:21.000 --> 00:37:24.000
X or, uh, Instagram or something like that.

00:37:24.000 --> 00:37:36.000
you start to see weird dynamics of the likes, you know, like, um, just because there's a lot of likes doesn't mean it's actually popular. It means that a bunch of bots have decided to boost that one, right?

00:37:36.000 --> 00:37:43.000
And so you get these weird non-social dynamics that go on that don't mean what you… what they are meant to mean.

00:37:43.000 --> 00:37:56.000
So anyway, um, social software is really hard. Social dynamics is really hard. Getting us more signal and less noise is really hard. Really, really, really hard.

00:37:56.000 --> 00:38:01.000
This is the perfect segue for me to do a little bit of history and talk about context.

00:38:01.000 --> 00:38:12.000
I love the conversation we're having, and I think we should go deeper into what tools would we like to use? What affordances do we really want to value over others, et cetera, et cetera. And that's right next to the conversation.

00:38:12.000 --> 00:38:17.000
About, do we want to grow? Whatever else, but let me go back. First thing I want to say is,

00:38:17.000 --> 00:38:24.000
We should do the same kind of composting indexing with the OGM wiki, Pete says in the chat, and I'm like,

00:38:24.000 --> 00:38:26.000
Because…

00:38:26.000 --> 00:38:31.000
When Pete put up the Mattermost server, I just automatically started pouring

00:38:31.000 --> 00:38:39.000
all the files. I basically take the… I download the video from Zoom, I upload it to YouTube, I take that link,

00:38:39.000 --> 00:38:44.000
I put it in my brain. I put it in the matter most, and then I attach to that… to that matter most entry

00:38:44.000 --> 00:38:49.000
the chat, the transcript, and the AI summary. And I've been doing that rhythmically, methodically,

00:38:49.000 --> 00:38:54.000
for… since… not since June 2020, which was our first call,

00:38:54.000 --> 00:39:00.000
But since the Mattermost server came out and all that, and that's where all the files are, and Mattermost is a terrible place to do that.

00:39:00.000 --> 00:39:06.000
matter most is not a database, it doesn't make it easy to fetch those things out, it doesn't do anything like that.

00:39:06.000 --> 00:39:13.000
avid user of MassiveWiki since Pete came out with MassiveWiki. I'm writing like a fiend in Obsidian in the OGM wiki,

00:39:13.000 --> 00:39:16.000
It has not occurred to me once

00:39:16.000 --> 00:39:21.000
to go create… to go into the folder and, you know, some… to create, basically,

00:39:21.000 --> 00:39:24.000
A list of all the calls in OGM Wiki.

00:39:24.000 --> 00:39:29.000
Which may or may not be the right kind of structure to put it in. I'm not exactly sure that it's

00:39:29.000 --> 00:39:40.000
that the wiki as it stands is a great database for looking things up or doing analyses or whatever else on it. That's an interesting side conversation. I just want to say, it hadn't occurred to me

00:39:40.000 --> 00:39:49.000
to go do it there, and at this point, because Mattermost is being deprecated, I just created a Google Drive where I'm putting all the files, and that's not very useful, and nobody knows it exists.

00:39:49.000 --> 00:39:56.000
So, I'm up for some brainstorming about, hey, every time I, you know, I download these files, where should I put them and what should I do?

00:39:56.000 --> 00:40:01.000
Um, where it's much more useful, and I think OGM Wiki is a nice place to do it.

00:40:01.000 --> 00:40:05.000
Because, another thing I wrote down is wikis versus newsletters.

00:40:05.000 --> 00:40:13.000
Pete and I are both big fans of wikis. Pete used to actually, uh, he co-founded and was in a wiki company for years called SocialText.

00:40:13.000 --> 00:40:17.000
I… he and I and many others thought

00:40:17.000 --> 00:40:24.000
Many years ago, that we would all be collaborating through wikis, and that there would be some semi-structured wikis, there's one called Wagon that came and went,

00:40:24.000 --> 00:40:27.000
That was about slightly more structured data,

00:40:27.000 --> 00:40:33.000
There were a bunch of kind of variants, but we thought we would be collaborating to co-write

00:40:33.000 --> 00:40:36.000
a series of connected nodes of text and other stuff.

00:40:36.000 --> 00:40:42.000
that existed out in a rhizomal mycelial network of nodes. And I love this vision.

00:40:42.000 --> 00:40:50.000
MassiveWiki isn't quite a wiki yet, and may not… I don't know that it's on Pete's roadmap anymore to turn it into a full-fledged wiki.

00:40:50.000 --> 00:40:58.000
Because you can't click a… you can't edit the page that you're looking at, which is, I think, a really important feature for wikis to have.

00:40:58.000 --> 00:41:02.000
So we don't have wiki-like conversation yet in

00:41:02.000 --> 00:41:06.000
Ironically, OGM Wiki. But the topography

00:41:06.000 --> 00:41:12.000
of a wiki is… or a mailing list, and a newsletter are all different. And Stacey, what I mean by topography is

00:41:12.000 --> 00:41:21.000
When you have a newsletter, it's broadcast to a bunch of people who sign up, and the owner of the list might be able to see the list of people who've signed up, but it's not a public resource.

00:41:21.000 --> 00:41:30.000
On the OGM list, you can go… you may not have done this yet, but you can go to Google Groups and you can see all the members of the OGM list. You can see

00:41:30.000 --> 00:41:33.000
when you put any… and when you drop any email to

00:41:33.000 --> 00:41:35.000
OpenGlobalmind.google Groups,

00:41:35.000 --> 00:41:43.000
You can see who it went to. You cannot tell if any of them forwarded it to a friend or anything like that. You can't tell the second-order reach.

00:41:43.000 --> 00:41:47.000
So the first order we reach is right there for you to see, and it's easy, right?

00:41:47.000 --> 00:41:53.000
And then on a wiki, you can kind of see who made changes. You can't usually see who read the page, it doesn't…

00:41:53.000 --> 00:41:55.000
track visitors who are reading.

00:41:55.000 --> 00:42:03.000
Unless you have a larger site like Wikipedia, but there's a community of people who are co-editing, and it's a very different feeling around

00:42:03.000 --> 00:42:11.000
the shared asset online. And those things are distinct and culturally different and interesting in ways that we should talk about at greater length.

00:42:11.000 --> 00:42:19.000
Now, for a little bit of history. Way early in OGM, Vincent Dorena showed up, and one of the questions was, hey, who's doing what with whom?

00:42:19.000 --> 00:42:26.000
And that turned out to be a big question that was big enough that Vincent came straight out of, uh, out of college.

00:42:26.000 --> 00:42:31.000
Where he had done some of this for his college, and he started a project to create a list of groups.

00:42:31.000 --> 00:42:36.000
And members of groups and all of that, which he's still doing, and I haven't… I haven't seen Vincent, he hasn't been, uh…

00:42:36.000 --> 00:42:39.000
in OGM for quite a while. He's apparently quite busy.

00:42:39.000 --> 00:42:45.000
Um, we also had a little period where we were, um, and I think Pete sort of started… gave us the metaphor,

00:42:45.000 --> 00:42:50.000
of, hey, since there are lots of little overlapping raindrop-y organizations,

00:42:50.000 --> 00:42:57.000
swimming in the big flotilla that was also a side project called Flotilla for a while that Pete was running,

00:42:57.000 --> 00:43:00.000
What is the view from the mast of any one organization?

00:43:00.000 --> 00:43:08.000
Like, if I were to go to the top of the OGM mast and look out, there are some orgs that are closer to us and others that are sort of out on the horizon that we've heard of,

00:43:08.000 --> 00:43:15.000
But there's some who have regular overlapping members, because they're members of those communities who are regulars.

00:43:15.000 --> 00:43:20.000
here, right? And so, um, this view from the mass thing was really interesting, and then

00:43:20.000 --> 00:43:25.000
Later, I was looking for, how do I get a multi-plane camera view?

00:43:25.000 --> 00:43:32.000
And now, sorry, I'm gonna explain a different thing. Uh, Disney invented the multi-plane camera to make cartoons.

00:43:32.000 --> 00:43:40.000
They basically created a frame where you could put cells, P-E-L-S, which are individual frames of animations,

00:43:40.000 --> 00:43:49.000
You would put cells in each of these layers, and the background would be, like, the landscape, and then here would be a couple trees, and here would be a Donald Duck.

00:43:49.000 --> 00:44:00.000
And you could move them at different rates of speed to give the illusion of depth and speed in a comic pretty easily. You would then replace one of them, but just shift the other ones, etc.

00:44:00.000 --> 00:44:03.000
what I was looking for was this view from the mast,

00:44:03.000 --> 00:44:13.000
Could it be one layer in a multi-plane camera? Another view is the people, another view is the projects that each of these things are going into, and then between the different layers, you could see, oh,

00:44:13.000 --> 00:44:23.000
Stacy is a member of OGM, and she's part of this group doing a Neobooks project, or not, or whatever else, and you could kind of go up and down and see and collect, but you could turn this multi-plane thing around

00:44:23.000 --> 00:44:25.000
And you could pull any one of them out,

00:44:25.000 --> 00:44:40.000
And look at them in 2D, because just the view from the mast is its own interesting story, or just the overlapping projects is an interesting story. But then you can see the relationship between them, and that was more code than any of us was interested in trying to create,

00:44:40.000 --> 00:44:45.000
or anything like that. So that's the multi-plane camera view thing that I put in the chat.

00:44:45.000 --> 00:44:48.000
we're sort of at this interesting moment where

00:44:48.000 --> 00:44:52.000
Ironically, when somebody says, hey, I've got a new community, what tools should I use?

00:44:52.000 --> 00:44:55.000
There's no good answer.

00:44:55.000 --> 00:45:01.000
Like, if you ask Pete and me and other people who have a lot of experience in this field, we'll be like,

00:45:01.000 --> 00:45:04.000
Oh, God, not this question again. That's under our breath.

00:45:04.000 --> 00:45:10.000
And then we're like, well, you could try Discord, or you could try a Google group, or you could try this, or you could try that, and they all have

00:45:10.000 --> 00:45:15.000
There are pluses and minuses, and the ones that have eaten the space, Facebook, LinkedIn, and others,

00:45:15.000 --> 00:45:20.000
Now, Facebook has, as its business model, addicting you, so not that cool.

00:45:20.000 --> 00:45:30.000
LinkedIn, much less so, but is very business-y, very, very whatever, whatever. I'm trying to do a little something with some private LinkedIn groups, but they don't have a lot of life.

00:45:30.000 --> 00:45:35.000
Right? So the question still is, where the hell do we go?

00:45:35.000 --> 00:45:40.000
I'm a little angry at the software world for not having fixed this and solved it at this point. I think that

00:45:40.000 --> 00:45:43.000
We're kind of, um, we're kind of…

00:45:43.000 --> 00:45:47.000
We know enough about all these things to figure out

00:45:47.000 --> 00:45:59.000
what to do, right? But we don't… we haven't sort of figured that out, and it would be nice to… I'd love to hear people's opinions, whatever else, but that's… that's just a little bit of background history, a bunch of different things we tried.

00:45:59.000 --> 00:46:08.000
Um, none of which, frankly, stuck, and a few people like Vincent went off and were entrepreneurial and built up the thing that they were working on.

00:46:08.000 --> 00:46:11.000
went off. There are other communities

00:46:11.000 --> 00:46:17.000
Um, I'm trying to remember, uh, Brad DeGraff has one, but another… Ben Roberts has a community where he's got a Kumu map.

00:46:17.000 --> 00:46:26.000
Of all the people in overlapping communities, that's really quite interesting. I'll find the link and post it in the chat when I'm done monologuing here.

00:46:26.000 --> 00:46:31.000
But some of the flotilla of neighboring communities have

00:46:31.000 --> 00:46:37.000
managed to get things done and share them out into the world, and they're really quite interesting resources.

00:46:37.000 --> 00:46:40.000
And with that, let's, uh, do…

00:46:40.000 --> 00:47:10.000
a few seconds of silence, and then I'll go to you, Klaus. Thanks for your patience.

00:47:29.000 --> 00:47:35.000
Thanks, everybody.

00:47:35.000 --> 00:47:44.000
Yeah, I was saying, they used to have a calendar. I was recently looking for it, and it seems to either have disappeared, or I couldn't find it.

00:47:44.000 --> 00:47:51.000
But there used to be a calendar where people would group would advertise themselves.

00:47:51.000 --> 00:48:02.000
And, um, they would be open or closed groups, you know, there would be some groups you can just drop in, there would be other groups, you know, please see, please check in if this is the right thing for you.

00:48:02.000 --> 00:48:09.000
But it really made it super easy to… to share, you know, what's happening.

00:48:09.000 --> 00:48:14.000
And one reason why I was thinking about it is because I've been this summer wanting to.

00:48:14.000 --> 00:48:23.000
See what's going on in my own community, and when you go to your meetup schedule, I mean, the meetup… meetup app.

00:48:23.000 --> 00:48:34.000
Every coop here is advertising itself, and they also, you know, let you know if this is open or drop-in, or… contact me, and so on.

00:48:34.000 --> 00:48:40.000
And it's super incredible how many groups are meeting, you know, even in a small town like Bend.

00:48:40.000 --> 00:48:48.000
I mean, any topic you can think of, if you want to go to Sen Meditation, or an AI group, or you name it.

00:48:48.000 --> 00:48:59.000
Um, you know, climate change issues, you know, electrification. Uh, the national organization, like Citizen Climate Lobby, and.

00:48:59.000 --> 00:49:04.000
Now, the Sierra Club, I mean, they all have local representations.

00:49:04.000 --> 00:49:14.000
Um, so there's just so much happening. Um, it makes it… makes it really easy and interesting, so why don't we have… why don't we look at.

00:49:14.000 --> 00:49:18.000
We coping this schedule, right? And if someone wants to form a group.

00:49:18.000 --> 00:49:23.000
You can't just make yourself known on their schedule, put a little background on it, and off you go.

00:49:23.000 --> 00:49:31.000
I'd be very happy to post about us on other groups' schedules or calendars, so that more people can find us. That sounds awesome, I just…

00:49:31.000 --> 00:49:35.000
I haven't looked around, so I don't know which calendars to look at. Anybody who…

00:49:35.000 --> 00:49:38.000
wants to do that, please do that on her behalf as well.

00:49:38.000 --> 00:49:43.000
Brief side note, I meant in my long rant to do something unrelated, which was

00:49:43.000 --> 00:49:48.000
to point out how spectacular Pete's recent project about social cyclic theories is.

00:49:48.000 --> 00:49:53.000
Uh, just go… go browse around the wiki. Uh, it's an astonishing resource of

00:49:53.000 --> 00:50:00.000
You've heard of Kondratiev waves and the Great Turning and all that. This is a beautifully organized

00:50:00.000 --> 00:50:03.000
very deep compendium of that stuff.

00:50:03.000 --> 00:50:07.000
Totally worth looking at. Now we return to our…

00:50:07.000 --> 00:50:09.000
which is already in progress. Alex.

00:50:09.000 --> 00:50:14.000
But if I may, the one that you just posted, actually, I found this one.

00:50:14.000 --> 00:50:17.000
But there, for example, it hasn't been updated. You know, new books on Mondays, we used to…

00:50:17.000 --> 00:50:22.000
That's the page… earlier, when I was saying that we had sort of deprecated the different

00:50:22.000 --> 00:50:26.000
pop out, uh, the different pop-out calls, and I needed to update the web.

00:50:26.000 --> 00:50:31.000
That's the page I need to fix.

00:50:31.000 --> 00:50:32.000
I remember that too, and I don't know where. I don't have it.

00:50:32.000 --> 00:50:35.000
But there was an actual schedule, like a spreadsheet.

00:50:35.000 --> 00:50:36.000
P.

00:50:36.000 --> 00:50:38.000
I think that's mine, the old Plex calendar.

00:50:38.000 --> 00:50:39.000
There we go. Good.

00:50:39.000 --> 00:50:40.000
Well, that… and this is something that I made.

00:50:40.000 --> 00:50:42.000
How good people would find it.

00:50:42.000 --> 00:50:44.000
Um, it's a lot of work to do this.

00:50:44.000 --> 00:50:45.000
Yeah.

00:50:45.000 --> 00:50:53.000
And uh… the community didn't support it well enough.

00:50:53.000 --> 00:50:57.000
Alex.

00:50:57.000 --> 00:51:04.000
Okay, checking on Pete's comment just then. I'm gonna go the other way. So, um…

00:51:04.000 --> 00:51:13.000
So, I agree with you. Gerry, about… okay, just my personal experience. I have an issue reading long blocks of text.

00:51:13.000 --> 00:51:19.000
So I want everything in little bits and titles, headings, summarizations, whatever.

00:51:19.000 --> 00:51:26.000
So, obviously, if you go to Discord, it is like a… impossibility for me to follow anything.

00:51:26.000 --> 00:51:34.000
Literally, it's just… I've got to think… it's like having long chains of emails, and having to look back to see what someone said. Again.

00:51:34.000 --> 00:51:42.000
So, it's impossible. So Discord result, similarly, all the other, kind of, IT-centric, you know, computer-centric, techy people.

00:51:42.000 --> 00:51:48.000
Centered things around. Email is just sent OGM, even the email is a challenge for me.

00:51:48.000 --> 00:51:58.000
Um, and the point I'm trying to make is. I would love to… create our own one, or, you know, create a product about this.

00:51:58.000 --> 00:52:08.000
Caters with all these… all these issues we've just mentioned. Based on what you said, Jerry, is I don't understand why nobody's done it yet.

00:52:08.000 --> 00:52:12.000
I don't know if you remember a tool that was out there for a short while.

00:52:12.000 --> 00:52:16.000
Until Google, as it does so often, canned it. Was it called? Wave or something?

00:52:16.000 --> 00:52:18.000
Yep, Wave. Wave was great.

00:52:18.000 --> 00:52:19.000
so was… so was Google+, by the way.

00:52:19.000 --> 00:52:21.000
That was… that was the closest that I came.

00:52:21.000 --> 00:52:29.000
Wave and Google Plus were two gigantic projects that Google launched and then deprecated really quickly. They were both super interesting.

00:52:29.000 --> 00:52:44.000
Yeah, absolutely, and I understood Wave. I liked Wave. But obviously, I couldn't find anybody else on my wavelength, so… but that was the kind of thing. So if anybody's interested in working on this with me or whatever.

00:52:44.000 --> 00:52:51.000
I'm happy to work with people on this. But I just think there must be a product out there that does it. It's not beyond the…

00:52:51.000 --> 00:52:55.000
The imagination. I don't understand why there isn't one.

00:52:55.000 --> 00:52:58.000
Um, totally agree with you. Totally agree with you.

00:52:58.000 --> 00:53:09.000
Um, Kalia, thanks for being there. I'd love it if you also gave us a little taste of what Sharif's meditation session was like, if you're willing to do that.

00:53:09.000 --> 00:53:16.000
Um, how about I rain check on Sharif's meditation, because I'm working on getting a one-page.

00:53:16.000 --> 00:53:19.000
Website up for it, and when it is ready, I will invite you all.

00:53:19.000 --> 00:53:21.000
That sounds great.

00:53:21.000 --> 00:53:26.000
It's great. Um…

00:53:26.000 --> 00:53:34.000
So, I think that… I'm… I'm… raise my hand because I have to go at the top of the hour, and I said.

00:53:34.000 --> 00:53:42.000
I've linked just a couple things in chat. I think… that we are…

00:53:42.000 --> 00:53:46.000
We. I don't know what we means anymore.

00:53:46.000 --> 00:53:54.000
People are approaching the problem that we have incorrectly. I don't believe we live in a social graph.

00:53:54.000 --> 00:54:02.000
That is a product of our… tool, a mental model, and the social reality of.

00:54:02.000 --> 00:54:12.000
Archetypical social reality of young, young masculine energy that runs around and says, look at me, connect to me, I'm really important.

00:54:12.000 --> 00:54:22.000
It's fine. It's a noble way to be in the world, it's just not the only way. And the anchor of… are… which… and that energy built the social web.

00:54:22.000 --> 00:54:27.000
Because that's who has given money to build it. If you had given money.

00:54:27.000 --> 00:54:37.000
To… women who are oriented around groups and communities, we would have built a vastly different social web.

00:54:37.000 --> 00:54:51.000
And social tooling. And I think we have to… go back and, like, go wait… What did we just build? We did not build infrastructure for groups and communities to be coherent, to govern themselves, to take action together in the world.

00:54:51.000 --> 00:54:58.000
In part because I believe they don't want us to have this tooling. I mean, when you… why… why after this long isn't it?

00:54:58.000 --> 00:55:06.000
Resource. But, um, I'm working with Grace Rajmani on articulating group.

00:55:06.000 --> 00:55:15.000
Credentialing and formation. Another reason the software world is broken is you can form a group, but you can't port a group, and you can't move it between places.

00:55:15.000 --> 00:55:25.000
Until we have that, we're locked into our tooling, so we need… infrastructure that's separate from the tooling about group belonging and membership. This is a.

00:55:25.000 --> 00:55:32.000
You know, the identity tech I've worked on for 20 years is finally here, and we could finally do that if we built it.

00:55:32.000 --> 00:55:39.000
We need to use the identity tech for things other than government-issued ID, which is getting all the money and attention and resourcing.

00:55:39.000 --> 00:55:52.000
It's fine, I'm neutral on it. There are open protocols, anybody can build anything, but we have to build group tooling for our own groups, so we have identity outside of status systems.

00:55:52.000 --> 00:56:03.000
And we also need group accountability and group… dispute resolution, and Grace also has thought a lot about how to do this, um, potentially at scale.

00:56:03.000 --> 00:56:12.000
In creative ways. So, I just would invite…

00:56:12.000 --> 00:56:25.000
Yeah, considering what I said, and sort of thinking about it slightly differently than… you know, the bird's-eye view of all the people. This is instrumentalist thinking.

00:56:25.000 --> 00:56:34.000
There's Chapter 15 and 16 of Surveillance Capitalism are about this, and about Sandy Pentland's lab, and specifically.

00:56:34.000 --> 00:56:43.000
And… people are… Yeah, I could go on. But, um…

00:56:43.000 --> 00:56:51.000
I've said enough, I have to go, I'm sorry, but it's about the groups and tooling for groups.

00:56:51.000 --> 00:56:56.000
And… and oh, I'll just finish and say. We need to also think about this.

00:56:56.000 --> 00:57:06.000
Community infrastructure as digital public infrastructure, not just. Status infrastructure as digital public infrastructure.

00:57:06.000 --> 00:57:11.000
Can we ask thank you. I'm sorry you have to bounce in a minute or two.

00:57:11.000 --> 00:57:17.000
That's a really good reorienting for us. Uh, I was thinking that

00:57:17.000 --> 00:57:23.000
VCs… I wrote, VCs are happy to fund addiction, but they're not going to fund community or civic life.

00:57:23.000 --> 00:57:29.000
Um, but you're also… I think you're also saying, I'm gonna… I'm gonna exaggerate a little bit what you said, but

00:57:29.000 --> 00:57:37.000
Boys will create boy tools, and women will actually create social tools that care about

00:57:37.000 --> 00:57:39.000
structure, reconciliation,

00:57:39.000 --> 00:57:41.000
relationships, all that kind of stuff.

00:57:41.000 --> 00:57:47.000
And we have not created any paths to the sea for that kind of software, and we're not

00:57:47.000 --> 00:57:51.000
backing it, we're not funding it, we're not anything yet.

00:57:51.000 --> 00:57:53.000
might be a really interesting remedy there.

00:57:53.000 --> 00:57:57.000
Grace was a regular in OGM for a while.

00:57:57.000 --> 00:58:01.000
And kind of… we chased her off, or she dropped out, or she got really busy with…

00:58:01.000 --> 00:58:04.000
with this, but…

00:58:04.000 --> 00:58:05.000
Tell me.

00:58:05.000 --> 00:58:09.000
You want to know why she doesn't come? And I… because all you do is talk.

00:58:09.000 --> 00:58:16.000
That's what she said. It's just to talk fast, and it's… and also your demographics, although… you know, every time I come, I change the demographics.

00:58:16.000 --> 00:58:17.000
That's true.

00:58:17.000 --> 00:58:32.000
But how does this group… go beyond, like… If we are… not we… if one is serious about making a difference in the world, how is that difference actually manifest?

00:58:32.000 --> 00:58:41.000
Like, I'm going because it's, like… I, you know, at one point I came more regularly. It sort of…

00:58:41.000 --> 00:58:51.000
Good to connect, and I like you all, but I still, like… It's more, like, intellectually, like, massaging, not, like, doing.

00:58:51.000 --> 00:58:52.000
Well, um…

00:58:52.000 --> 00:58:53.000
It's fun!

00:58:53.000 --> 00:58:58.000
I… I… I… I was gonna say I agree, but I sort of agree.

00:58:58.000 --> 00:59:02.000
Um, it feels like OGM has become

00:59:02.000 --> 00:59:10.000
The title pool at the intersection of multiple people's activities. And, you know, Klaus is out trying to change the world toward regenerative

00:59:10.000 --> 00:59:17.000
agriculture, clean soil, clean… I mean, healthy soil, clean water, etc. And I love hearing what he does.

00:59:17.000 --> 00:59:20.000
in those spheres, and he is really, really active.

00:59:20.000 --> 00:59:31.000
Doug is trying to pacify the world in other ways, and he is very active in other spheres, and I love when he checks in. And Sean is busy, like, coding till his, like,

00:59:31.000 --> 00:59:39.000
Your eyes fall out, like, late at night, trying to build a platform to do all this kind of stuff, and I hope is hearing what you're saying, because I think

00:59:39.000 --> 00:59:46.000
what you just said is, like, really interesting for, um, what Sean is trying to do.

00:59:46.000 --> 00:59:55.000
et cetera, et cetera. Scott has put together… and it's funny, I just… I just look around my little gallery view, and everybody's busy

00:59:55.000 --> 00:59:57.000
doing stuff, but we don't…

00:59:57.000 --> 01:00:01.000
We don't succeed when we try to do stuff together much at all.

01:00:01.000 --> 01:00:08.000
And, uh, granted, but it feels to me like the sharing of those bits of activity from each of us

01:00:08.000 --> 01:00:11.000
is somehow worth it for us to show up here and go.

01:00:11.000 --> 01:00:14.000
Um, Kalia, thank you. I know you have to… you have to bounce.

01:00:14.000 --> 01:00:19.000
Um…

01:00:19.000 --> 01:00:26.000
So it may also be, like. You know, I… And it's okay, not everybody has to be in every group.

01:00:26.000 --> 01:00:27.000
Well, before you go, Kalia,

01:00:27.000 --> 01:00:28.000
That's true.

01:00:28.000 --> 01:00:29.000
Before you go, um, uh, I'm…

01:00:29.000 --> 01:00:32.000
Yeah.

01:00:32.000 --> 01:00:44.000
I'm doing things at two layers. One level is the MMM level, and what that is is the merged mental model. What it is, is a distributed

01:00:44.000 --> 01:00:47.000
data store that is…

01:00:47.000 --> 01:00:56.000
It's semantic, it's structured, but it also has textual components, so in effect, it's structured so that it can hold both

01:00:56.000 --> 01:00:58.000
The hyper-object of…

01:00:58.000 --> 01:01:00.000
The Great Conversation.

01:01:00.000 --> 01:01:03.000
Which is natural language.

01:01:03.000 --> 01:01:06.000
been flung back and forth around the world, that… that…

01:01:06.000 --> 01:01:09.000
the hyper-object of the great conversation is,

01:01:09.000 --> 01:01:12.000
all of our discourse through history,

01:01:12.000 --> 01:01:14.000
it could hold that.

01:01:14.000 --> 01:01:19.000
And it can also hold the merged mental model

01:01:19.000 --> 01:01:26.000
Which is our… the superposition of our collected understandings. And the way that's…

01:01:26.000 --> 01:01:29.000
And this is just a data layer.

01:01:29.000 --> 01:01:37.000
Okay? So it's a distributed database that… it's kind of like Bitcoin, but for ideas.

01:01:37.000 --> 01:01:39.000
Okay? For those two…

01:01:39.000 --> 01:01:41.000
aspects of… of…

01:01:41.000 --> 01:01:47.000
the problem space, okay? And so, so yeah, and so one of the things that it has…

01:01:47.000 --> 01:01:49.000
is a bunch of

01:01:49.000 --> 01:02:01.000
of, um, uh, privilege levels and control circuits, uh, so that… so that groups can define themselves

01:02:01.000 --> 01:02:07.000
And Disquares spaces.

01:02:07.000 --> 01:02:08.000
So…

01:02:08.000 --> 01:02:11.000
Great, then come and collaborate with us, and don't reinvent new things, like… We have the infrastructure. I mean, that's what we talked about last time we talked, so hopefully we'll figure it out.

01:02:11.000 --> 01:02:12.000
Yeah.

01:02:12.000 --> 01:02:18.000
Exactly. So, so I… I embrace your use cases, and I have an offer.

01:02:18.000 --> 01:02:19.000
Kalia has to back… yeah.

01:02:19.000 --> 01:02:21.000
that's a platform for all you say.

01:02:21.000 --> 01:02:27.000
I would say pitch it into groups that Kaliyah might direct you toward.

01:02:27.000 --> 01:02:31.000
Um, good. And she's… she's headed off to her… her call.

01:02:31.000 --> 01:02:35.000
Thanks, Sean.

01:02:35.000 --> 01:02:47.000
I think our topic for next Thursday is sort of like this. I think we pick up this conversation and keep going. I think we're in a good place, and I think we've only…

01:02:47.000 --> 01:02:54.000
past the hour, but we've only now started to turn into some interesting issues that matter that might actually be

01:02:54.000 --> 01:03:06.000
long-term, how we… how we shift or do something. I'm not… I'm not feeling that articulate about it right now, but I feel like… I feel like I'm seeing differently than I was at the top of the hour, which I… at the start of the hour, which I really appreciate.

01:03:06.000 --> 01:03:13.000
Speak, please.

01:03:13.000 --> 01:03:19.000
As always, there's about 4 things I want to reply to. I don't know if I'll hit all of them, and…

01:03:19.000 --> 01:03:25.000
Probably shouldn't anyway. Um…

01:03:25.000 --> 01:03:33.000
One of the things I wanted to say, I… I… I… I said really hard, really, really, really hard a couple times.

01:03:33.000 --> 01:03:37.000
And also…

01:03:37.000 --> 01:03:44.000
um, you know, didn't have the resources to do that. Community didn't support this, whatever, right?

01:03:44.000 --> 01:03:48.000
the bright lights. Um…

01:03:48.000 --> 01:03:58.000
One of the bright lights nowadays is AI assistance. Uh, so the Plex Archive is actually an amazingly well-put-together thing.

01:03:58.000 --> 01:04:00.000
Um, I…

01:04:00.000 --> 01:04:05.000
didn't… I didn't really do that. I had, uh, AI

01:04:05.000 --> 01:04:07.000
write code that did that.

01:04:07.000 --> 01:04:09.000
Um, so…

01:04:09.000 --> 01:04:22.000
Uh, when I say something like AI is… is really important here, I'm not meaning that we should seed things over to AI and say, hey, AI, can you help me? I'm lost and confused.

01:04:22.000 --> 01:04:27.000
But there is definitely a place for…

01:04:27.000 --> 01:04:33.000
AI to follow the lead of a human who knows that they need to organize things.

01:04:33.000 --> 01:04:38.000
And an AI is great at grunt lifting code, or…

01:04:38.000 --> 01:04:42.000
massive reorganization of stuff that used to

01:04:42.000 --> 01:04:50.000
used to… we used to wish for, and now we can just do it, kind of, you know, with a bot's help, super fast.

01:04:50.000 --> 01:04:54.000
So, I'm actually…

01:04:54.000 --> 01:04:58.000
I'm actually super energized knowing that we have

01:04:58.000 --> 01:05:06.000
tools that can make code super fast, and tools… agentic tools, that can organize information very fast.

01:05:06.000 --> 01:05:13.000
And that people like the folks here can direct those tools. So, I'm actually really excited about the future.

01:05:13.000 --> 01:05:22.000
Um, organizing and… organizing and distributing communication and information amongst humans. It's gonna be

01:05:22.000 --> 01:05:25.000
a lot easier than it has been.

01:05:25.000 --> 01:05:27.000
Um…

01:05:27.000 --> 01:05:35.000
Uh, I wanted to pick up on what Kalia said about groups. Very smart, very thoughtful, and especially contrasting with the social graph.

01:05:35.000 --> 01:05:39.000
Um, I'm gonna hit return on a thing that I started to write in chat.

01:05:39.000 --> 01:05:43.000
Um, I happen to know… I happen to be… have been…

01:05:43.000 --> 01:05:50.000
in the bleachers, watching some of this world start to happen, the social graph,

01:05:50.000 --> 01:05:51.000
Supremacy of the social graph.

01:05:51.000 --> 01:06:07.000
Um, back in the day, back in the mid-90s, uh, there was a company called Six Degrees that was one of the early… you could think of it kind of as LinkedIn or something like that. There were a few others, uh, Rise, there was a thing called Rise, R-Y-Z-E, it might still be around.

01:06:07.000 --> 01:06:09.000
That was one of the very earliest.

01:06:09.000 --> 01:06:17.000
Um, 6 degrees went out of business, the IP that got bought, the idea of a social graph, um, got…

01:06:17.000 --> 01:06:22.000
Um, protectively acquired by Reed Hoffman, uh, later of LinkedIn,

01:06:22.000 --> 01:06:28.000
Uh, and Mark Pincus, later of things like Zynga and Tribe. Um, Reed and…

01:06:28.000 --> 01:06:33.000
And Mark wanted to make sure that it didn't fall into the wrong hands, um, which

01:06:33.000 --> 01:06:36.000
may have been the Friendster guy.

01:06:36.000 --> 01:06:40.000
Um, uh, but…

01:06:40.000 --> 01:06:46.000
It was… it was perceived to be the 6 Degrees patent, it's called, um,

01:06:46.000 --> 01:06:49.000
Uh, was perceived to be a key part of…

01:06:49.000 --> 01:06:52.000
a key asset that then

01:06:52.000 --> 01:06:59.000
got developed into things like LinkedIn. So, the supremacy of

01:06:59.000 --> 01:07:02.000
of the social graph is…

01:07:02.000 --> 01:07:06.000
a path-dependent outcome of, kind of,

01:07:06.000 --> 01:07:15.000
Silicon Valley latching onto the idea of social graph early on, and deciding that that was going to be a moneymaker, and it was.

01:07:15.000 --> 01:07:18.000
But in some alternate history, um,

01:07:18.000 --> 01:07:24.000
to Khalia's point, it could have been a set of women that came up with the

01:07:24.000 --> 01:07:28.000
the ideas and the architecture is to…

01:07:28.000 --> 01:07:34.000
help people hook together, and we would have… we might have ended up in a completely different place.

01:07:34.000 --> 01:07:38.000
I've personally met and chatted with Mark

01:07:38.000 --> 01:07:44.000
Mark Pincus and Reid Hoff, and they are both amazing people, the best… some of the best people I know in the world.

01:07:44.000 --> 01:07:49.000
Um, so I… I don't mean to impugn their…

01:07:49.000 --> 01:07:55.000
you know, their character, or… or say anything bad about them. They're awesome people.

01:07:55.000 --> 01:08:09.000
Um, but they did also get swept up in, you know, the supremacy of the social graph, which was a good thing for a while, and maybe now it's not such a good thing to Claire's point. I think that's really smart of her to say.

01:08:09.000 --> 01:08:13.000
Um…

01:08:13.000 --> 01:08:15.000
uh… I… I think…

01:08:15.000 --> 01:08:23.000
Lastly, um, it… I hope it stung a little bit when Clea… Clea said… Grace said,

01:08:23.000 --> 01:08:28.000
y'all just talk, so I'm sorry I don't have time for that. Um…

01:08:28.000 --> 01:08:31.000
I think that's okay. Uh…

01:08:31.000 --> 01:08:37.000
Jerry and I talked, you know, Jerry and I had some talks over the years. What is OGM?

01:08:37.000 --> 01:08:44.000
One of the things OGM seems to be is this nexus of place… a place where people can come together and learn about other people.

01:08:44.000 --> 01:08:46.000
And then they go off and do things.

01:08:46.000 --> 01:08:49.000
And in a way,

01:08:49.000 --> 01:08:59.000
that's not a bad thing, and maybe that's a best thing. Um, OGM, uh, as a star nursery, a place for stellar formation,

01:08:59.000 --> 01:09:03.000
Um, is… is a wonderful kind of thing.

01:09:03.000 --> 01:09:10.000
Um, I wish that… so, if I had my druthers, or if I could wish for something for OGM,

01:09:10.000 --> 01:09:13.000
I don't wish that we got more done.

01:09:13.000 --> 01:09:20.000
Um, I don't even wish that we onboarded people better. Um, I wish that more people

01:09:20.000 --> 01:09:26.000
pass by, and some of them stuck. I wish that we could tell what this group

01:09:26.000 --> 01:09:30.000
is doing, um, in multiplex.

01:09:30.000 --> 01:09:35.000
everywhere. Each of us has probably got, you know, 3, 4, 5,

01:09:35.000 --> 01:09:44.000
10 projects that they know of are interrelated with that would be really interesting to some but not all of the rest of us, right?

01:09:44.000 --> 01:09:54.000
Um, this is kind of the problem that Vincent Flotilla, and especially Vincent, was chasing. You know, wouldn't it be great if there was a database where everybody knew everything about everything?

01:09:54.000 --> 01:10:00.000
And… and if it was magically relevant in a way that you could come and…

01:10:00.000 --> 01:10:03.000
You know, I think of the world this way, or I think of the world that way, and I need

01:10:03.000 --> 01:10:07.000
I'm interested in these kinds of things, can you tell me what other kinds of things there are?

01:10:07.000 --> 01:10:18.000
Catalyst does that. And it's still not enough. Um, I've always thought that we needed human matchmakers around a power tool like Catalyst to help

01:10:18.000 --> 01:10:22.000
people make sense of things. I don't know if that's the right architecture.

01:10:22.000 --> 01:10:30.000
Um… uh… but if I had a wish, I'll say it again, if I had a wish, it's not that OJM

01:10:30.000 --> 01:10:34.000
was necessarily bigger or better at doing stuff.

01:10:34.000 --> 01:10:36.000
It's that we had…

01:10:36.000 --> 01:10:41.000
better distribution of interesting information about what we're all doing.

01:10:41.000 --> 01:10:44.000
Um, and what…

01:10:44.000 --> 01:10:49.000
the people we know and can trust, and we know they're thoughtful.

01:10:49.000 --> 01:10:54.000
what they're doing, and how we might plug into that. So, somehow…

01:10:54.000 --> 01:11:00.000
That used to be, you know, that's kind of the idea of the plaques, was kind of that.

01:11:00.000 --> 01:11:03.000
Um, and it didn't work out. Um…

01:11:03.000 --> 01:11:09.000
I think. I mean, it worked out a little bit, but not… not nearly as much as it should have. Um, so I wish OGM would do more of that.

01:11:09.000 --> 01:11:14.000
I'm still brainstorming tools and ways to do more of that, too.

01:11:14.000 --> 01:11:19.000
Um, Pete, thank you for all of that, and I just want to…

01:11:19.000 --> 01:11:24.000
the things that happened for a short while and then go away aren't failures.

01:11:24.000 --> 01:11:33.000
their progress. They're, they're, like, we tried something, we did something, it… and pieces of it will live on in other ways.

01:11:33.000 --> 01:11:43.000
I'm cool. And some things have a lifetime, and unfortunately, um, some projects, groups, and things keep going, even though they should have stopped. So, I think

01:11:43.000 --> 01:11:45.000
Stomping is an okay thing.

01:11:45.000 --> 01:11:49.000
Um, but thank you for all the added context.

01:11:49.000 --> 01:11:53.000
Um, as well. And, uh, Scott, thanks for what you said in the chat.

01:11:53.000 --> 01:11:57.000
That's good. We're agreeing with you.

01:11:57.000 --> 01:12:00.000
Pause, please.

01:12:00.000 --> 01:12:09.000
Yeah, to… to echo a little bit, but… what Pete was just saying, I mean, I would have… not known anything about AI or what to do with AI.

01:12:09.000 --> 01:12:18.000
If it wasn't for Pete to open the doors and… And get us into it, and then I spent some time, Ms. Pete, trying to.

01:12:18.000 --> 01:12:22.000
See how we could hook up with what he's working on.

01:12:22.000 --> 01:12:32.000
And what really… what really happened, uh, in… started an evolution in how I was working with AI.

01:12:32.000 --> 01:12:44.000
I just got invited to a panel discussion. For a conference hosted by Kansas State University on the integration of AI with agriculture, with food and agriculture.

01:12:44.000 --> 01:12:54.000
Um, and that made me… think about, um… more deeply, right? What am I actually doing with this?

01:12:54.000 --> 01:13:01.000
And the way I'm transitioning, and I find when I talk with potential clients.

01:13:01.000 --> 01:13:07.000
Uh, there is… there is this confusion about, am I an AI software developer?

01:13:07.000 --> 01:13:13.000
Or am I an industry expert who is using AI to do what he's doing?

01:13:13.000 --> 01:13:21.000
Right? And so I have come now to… this. I'm an industry expert, you know, I have a very unique background, and…

01:13:21.000 --> 01:13:25.000
Of course, God kept us, you know, to also miss my daughter and I, too.

01:13:25.000 --> 01:13:30.000
Think this through a little bit more, but I'm really articulating this now, because.

01:13:30.000 --> 01:13:42.000
I'm realizing that in order to land clients. I have to be very specific about… I know what I'm doing in this industry and in this business, and I'm using AI to do it better.

01:13:42.000 --> 01:13:50.000
Kind of thing, you know? And so, I might create it, uh… us to, uh, OpenAI team.

01:13:50.000 --> 01:14:04.000
Because I can still program this myself. You know, I can still develop the agents and, uh… and train them, and have conversations with these agents without having to.

01:14:04.000 --> 01:14:10.000
Know how to code a program. We're currently… we're going to move into a different place really soon.

01:14:10.000 --> 01:14:20.000
You know, I was invited by George Paul. Who is a senior fellow at the Schumera Institute and Cherry, I know you are in the same group right now.

01:14:20.000 --> 01:14:27.000
Um, and George is doing a really high-level, uh, you know, boil the oceans kind of, uh.

01:14:27.000 --> 01:14:34.000
Thing to, to, uh. To bring people.

01:14:34.000 --> 01:14:41.000
Connect people, and he actually connected me. With an international coup, uh, that's headquartered in the UK.

01:14:41.000 --> 01:14:52.000
On building food hubs, community-based food systems. So, we are now in conversation with this group where George is…

01:14:52.000 --> 01:14:59.000
Is going to waste money for us, or is assisting us in raising money.

01:14:59.000 --> 01:15:06.000
So we can create a project that integrates AI. With this group, but at the same time.

01:15:06.000 --> 01:15:13.000
Uh, no, I'm having to explain, we're not… it's not so much about integrating AI as it is about.

01:15:13.000 --> 01:15:19.000
Figuring out how you enter wholesale markets. And use AI to do it better, you know?

01:15:19.000 --> 01:15:27.000
And to end the carbon markets, where you can get paid for ecosystem services.

01:15:27.000 --> 01:15:39.000
Um, and we're using AI to manage that process. So… So I may come back really fast, Pete, because, uh…

01:15:39.000 --> 01:15:49.000
To integrate data banks, you know, with AI in order to have the AI do the diagnostics, but create databanks that actually can do this.

01:15:49.000 --> 01:15:53.000
Now, this is not, uh, this is like, uh, walking my boat.

01:15:53.000 --> 01:16:03.000
I know it needs to be done, but how to do it is a whole different trip, but… to… the challenge really is.

01:16:03.000 --> 01:16:12.000
You know, in… I've been working with, you know, I still am with NGOs, the Sarah Club, and Citizen Climate Lobby, and all.

01:16:12.000 --> 01:16:18.000
It's really difficult to do anything there that actually has an impact, you know.

01:16:18.000 --> 01:16:26.000
You need to get… you need to get into the industry, you need to get Pepsi and… Nestle and Kellogg engaged here.

01:16:26.000 --> 01:16:31.000
Um, and we need to figure out how to connect smaller and medium-sized farmers.

01:16:31.000 --> 01:16:41.000
So they can competently participate in a market. That they have been shut out of at this point. So that is… that is my mission, you know, is to…

01:16:41.000 --> 01:16:47.000
Create the aggregation systems, the logistics. Contract farming, uh, ideas.

01:16:47.000 --> 01:16:55.000
So that you can have multiple smaller farmers. Partner in co-op style and engage.

01:16:55.000 --> 01:17:02.000
That's my dream, right? Um… And it's… it's murder to…

01:17:02.000 --> 01:17:08.000
Explain those, particularly to non-profit corps who are so idealistic about so many things, but.

01:17:08.000 --> 01:17:17.000
Really, really, uh, have a hard time. Crapping the mechanics of what you really need to do here.

01:17:17.000 --> 01:17:29.000
And sort of, you know, hardcore working this. So here, here's the, uh… the, uh, conference that I'm… that I'm, uh, attending, it's on the 14th of October, so it's…

01:17:29.000 --> 01:17:37.000
Actually a super interesting, uh. Approach here, because what Kansas State is doing there is really.

01:17:37.000 --> 01:17:43.000
Nuggling down to what is AI, actually, and what are we going to do with this thing, you know?

01:17:43.000 --> 01:17:46.000
And bring practitioners into the field.

01:17:46.000 --> 01:17:53.000
Plus, thank you very much. I don't know if it's helpful to you, but there's a thought in my brain, the hidden war on small farms.

01:17:53.000 --> 01:17:55.000
Uh, which lists things… when I read…

01:17:55.000 --> 01:18:00.000
Um, God, what book was it? About, uh, seed cleaners?

01:18:00.000 --> 01:18:15.000
Basically, there's a bunch of guys who… with… with trailers that clean seeds, and they troop around the country, and when you've… when you've pulled your crop in, when you've harvested, you want to save some of your crop and clean the seeds so that you can store them. If they still have their husks on them, they rot.

01:18:15.000 --> 01:18:23.000
seed cleaners, exactly. And Monsanto has sued the seed cleaners, trying to get them out of existence, so that everybody will buy

01:18:23.000 --> 01:18:32.000
new seed every year from Monsanto slash Bayer slash whoever. The Monopoly, basically, or not quite monopoly, on

01:18:32.000 --> 01:18:39.000
on agricultural products, and that's just one… and then, if you're a small farmer and you turn over to the futures markets and the investors,

01:18:39.000 --> 01:18:43.000
that are busy trying to, like, slice and dice all the profit out of

01:18:43.000 --> 01:18:46.000
you know, your ability to sell your crop.

01:18:46.000 --> 01:18:48.000
And the weather, and it's like…

01:18:48.000 --> 01:18:53.000
Oh my god, the weather's, like, not an active participant, it's just mean, but…

01:18:53.000 --> 01:19:03.000
It's really, really, really hard to be a small farmer and cause anything you can do to build scaffolding systems and things like that to help them thrive,

01:19:03.000 --> 01:19:08.000
or raw to you, because, um, it's just… it's super hard.

01:19:08.000 --> 01:19:09.000
I wonder why people don't want to, you know, inherit the family farm.

01:19:09.000 --> 01:19:16.000
Yeah. Yeah, this… this seat cleaner thing went all the way to the Supreme Court.

01:19:16.000 --> 01:19:21.000
You know, there was one farmer, and everybody rallied around this one farmer.

01:19:21.000 --> 01:19:26.000
Who got sued by Monsanto because his neighbor used GMO crops.

01:19:26.000 --> 01:19:33.000
And his siege drifted into… onto his farm, and planted into his seeds.

01:19:33.000 --> 01:19:42.000
Um, and… and Monsanto Sothev, they systematically sent out lawyers. Throughout the country, to sue farmers.

01:19:42.000 --> 01:19:48.000
Uh, because they may have had traces of their GMO content in their seeds.

01:19:48.000 --> 01:19:56.000
And knocked them out of business. It's… We're really not nice people, you know what I mean?

01:19:56.000 --> 01:19:58.000
There's some… there's some nasty stuff happening out there.

01:19:58.000 --> 01:19:59.000
Um, Stacy, please.

01:19:59.000 --> 01:20:06.000
Yeah.

01:20:06.000 --> 01:20:07.000
Uh, it's hard. Yeah.

01:20:07.000 --> 01:20:13.000
We're really not nice people, that just… I don't know. That feels so… It feels terrible. Um, but because Grace isn't here.

01:20:13.000 --> 01:20:16.000
And because they have first-hand knowledge, I just want to add that.

01:20:16.000 --> 01:20:23.000
It wasn't just the alt talk. It was how some of the talk was. So when Grace left here.

01:20:23.000 --> 01:20:29.000
She left here informed an all-women group. And she made it very clear.

01:20:29.000 --> 01:20:33.000
That the pushback. That she got from a dissenting voice.

01:20:33.000 --> 01:20:38.000
And Alex, you may appreciate this, was nothing like the pushback that you.

01:20:38.000 --> 01:20:42.000
Seem to experience. It was totally different.

01:20:42.000 --> 01:20:49.000
So, in her perspective, and I viewed it, so I kind of… I understand where she's coming from.

01:20:49.000 --> 01:20:54.000
It felt a lot more like she had to defend her dissenting views.

01:20:54.000 --> 01:21:03.000
Then it may have, if she looked more like you. So, it's not necessarily the same… the same we.

01:21:03.000 --> 01:21:09.000
That's in this space at the moment. But the we that was here at the time that she was here.

01:21:09.000 --> 01:21:15.000
Was a little bit different, and it… I can understand why she felt it wasn't worth it.

01:21:15.000 --> 01:21:22.000
To keep pushing back. So I wanted to add that, because it shouldn't go… unnoticed.

01:21:22.000 --> 01:21:28.000
Yeah, thank you. Um…

01:21:28.000 --> 01:21:38.000
I was puzzled because she seemed to leave right after something I said, and I just want to relate what it was from my perspective, because it was a form of pushback, but not… I don't think it was, and I might be wrong.

01:21:38.000 --> 01:21:44.000
Um, I had caught COVID on a trip to Spain and came back,

01:21:44.000 --> 01:21:49.000
And I had been vaccinated, and I told everybody, yeah, I just came down with COVID. And Grace said, oh,

01:21:49.000 --> 01:21:59.000
didn't catching COVID destroy your mental model about the vaccine? Or… I'm paraphrasing her, but didn't it shatter your worldview about the vaccine?

01:21:59.000 --> 01:22:01.000
And I said, no, not remotely.

01:22:01.000 --> 01:22:09.000
taking the vaccine, I did not think that taking the vaccine gave me an invulnerability shield from catching COVID. I knew it was very contagious.

01:22:09.000 --> 01:22:12.000
I knew it would greatly lessen my likelihood of dying.

01:22:12.000 --> 01:22:17.000
or getting long COVID, or something terrible. And I was perfectly comfortable with that.

01:22:17.000 --> 01:22:22.000
And that's the last I heard of her.

01:22:22.000 --> 01:22:26.000
I would just… I mean, I… I would just say it wasn't one comment and one time.

01:22:26.000 --> 01:22:28.000
Okay. But that kind of worried me. I was like… I was like… I was really interested in that conversation, because

01:22:28.000 --> 01:22:33.000
So, yeah.

01:22:33.000 --> 01:22:43.000
Her mental model and mine were obviously different on vaccines and COVID, and I was like, oh, let's dive, and that didn't happen. So thank you for

01:22:43.000 --> 01:22:45.000
I'm telling us what, um,

01:22:45.000 --> 01:22:49.000
One time.

01:22:49.000 --> 01:22:57.000
Um, we are out. I just looked up, and we're, like, at the end of our… at the end of our call time at Alex, thoughts?

01:22:57.000 --> 01:23:03.000
Um, sorry, I was gonna relate a story to do with Monsanto-type big pharma.

01:23:03.000 --> 01:23:06.000
But I don't have to, we can keep it for another time.

01:23:06.000 --> 01:23:10.000
There are so many of them.

01:23:10.000 --> 01:23:11.000
Yeah, yeah. There's actually a…

01:23:11.000 --> 01:23:13.000
You mentioned the vaccines, and that triggered me, so…

01:23:13.000 --> 01:23:21.000
thought in my brain, I got so angry about this that there's a thought in my brain, which I will put a link to right now,

01:23:21.000 --> 01:23:28.000
Titled, Monsanto Has Eviscerated Farming Worldwide may be destroying agriculture.

01:23:28.000 --> 01:23:31.000
And I think the people who go to work there think they're, like,

01:23:31.000 --> 01:23:33.000
making farming better.

01:23:33.000 --> 01:23:36.000
And I'm like, I don't understand how you can think that.

01:23:36.000 --> 01:23:39.000
the policies, the things they've done, the people they've sued,

01:23:39.000 --> 01:23:43.000
the effects they've had on the world, I don't get it.

01:23:43.000 --> 01:23:48.000
I don't… I don't know enough to be, you know, like, sure about this, but uh…

01:23:48.000 --> 01:23:54.000
They just make me angry. And then Bayer bought them, and I'm like, Bayer, what are you doing?

01:23:54.000 --> 01:23:57.000
I don't like Bayer.

01:23:57.000 --> 01:24:02.000
Because they had the poor judgment to do that. I should probably have a nice conversation with somebody from one of those companies.

01:24:02.000 --> 01:24:05.000
Sunday. Uh, anyway, any, any, um…

01:24:05.000 --> 01:24:10.000
Concluding thought… Doug, did you wanna…

01:24:10.000 --> 01:24:11.000
Oh, you're muted. You put your hand down, but you didn't unmute.

01:24:11.000 --> 01:24:15.000
You muted.

01:24:15.000 --> 01:24:19.000
I just wanted to stir in, around the time that Grace left.

01:24:19.000 --> 01:24:23.000
This question had arisen, and I actually reached out to her.

01:24:23.000 --> 01:24:27.000
And I reached out to a couple of other women at that time that had been.

01:24:27.000 --> 01:24:32.000
In and out of here. And, um…

01:24:32.000 --> 01:24:37.000
One piece of it was sort of, you know. Getting exhausted by.

01:24:37.000 --> 01:24:42.000
The patriarchal metaphoric… jousting.

01:24:42.000 --> 01:24:49.000
Of whose is bigger, whose is better. Um, and… but another dimension of it was that.

01:24:49.000 --> 01:24:58.000
In that jousting, it gets boring. Like, their… the share, the cons… the collective share was.

01:24:58.000 --> 01:25:08.000
It just sort of loses interest after a while. Um, and, you know, they were looking for something that had more vitality and momentum, and…

01:25:08.000 --> 01:25:16.000
And, you know, sort of substantive, energetic leveling up. Um…

01:25:16.000 --> 01:25:27.000
And I think, you know. There's… there's… you know, the… the dominance of the masculine, the dominance of…

01:25:27.000 --> 01:25:38.000
Of the fire and air stuff, the intellect and the… passion versus the Divine Feminine stuff, which is nurturance and holding.

01:25:38.000 --> 01:25:43.000
And receiving, and… and growing stuff.

01:25:43.000 --> 01:25:52.000
And, um… And they all sort of basically said, I want to go someplace where I feel like I'm growing something.

01:25:52.000 --> 01:25:57.000
So, I share that just… for data input purposes.

01:25:57.000 --> 01:26:02.000
Doug, thank you, thank you for sharing that a lot.

01:26:02.000 --> 01:26:06.000
That also seems like a really good place to wrap this call.

01:26:06.000 --> 01:26:09.000
I'm hoping Ken has a poem for us, but um…

01:26:09.000 --> 01:26:16.000
Doug, thank you.

01:26:16.000 --> 01:26:19.000
I do indeed have a poem.

01:26:19.000 --> 01:26:22.000
Taking a beat.

01:26:22.000 --> 01:26:24.000
I've been part of the OGM

01:26:24.000 --> 01:26:28.000
communities since the Yitan years. It's a community where I've felt well met.

01:26:28.000 --> 01:26:30.000
Appreciate it. Stimulated.

01:26:30.000 --> 01:26:33.000
Respected, and cared for.

01:26:33.000 --> 01:26:36.000
My hope is that I've contributed something of value to y'all.

01:26:36.000 --> 01:26:43.000
Perhaps my Plex posts, my stories, and my presence on the calls have provoked some deep thinking for some of you.

01:26:43.000 --> 01:26:46.000
Hopefully, I have not offended too many.

01:26:46.000 --> 01:26:53.000
Too much or too often. I so appreciate being able to read poetry to y'all. That means the world for me. Thanks so much.

01:26:53.000 --> 01:27:00.000
Now, we think supplies is in order. It's time for me to take a break and unplug from OGM's deluge of information.

01:27:00.000 --> 01:27:07.000
In addition to downsizing and packing up my household goods, which is as big an elephant as I've ever had to eat,

01:27:07.000 --> 01:27:10.000
I feel that I need to be quiet for a while.

01:27:10.000 --> 01:27:13.000
To sit with some really big and really tough questions.

01:27:13.000 --> 01:27:20.000
Questions that resonate across time and through multiple domains and dimensions, questions that require serious stillness.

01:27:20.000 --> 01:27:24.000
Serious listening and serious pondering.

01:27:24.000 --> 01:27:29.000
Questions that, if I can answer them, help me to decide what to do next.

01:27:29.000 --> 01:27:32.000
where to place my time, my energy, and my attention.

01:27:32.000 --> 01:27:35.000
to be effective with the rest of my life.

01:27:35.000 --> 01:27:39.000
The Times are calling for something different than what I've been doing.

01:27:39.000 --> 01:27:42.000
I do not know if I have that something within me or not.

01:27:42.000 --> 01:27:47.000
But I do know the only way to find out was to still myself for a while.

01:27:47.000 --> 01:27:54.000
I need to tune out of the constant distractions. I need to move away from the need to keep up with the latest news and trends.

01:27:54.000 --> 01:27:57.000
I need to tune into the rhythms of my cells.

01:27:57.000 --> 01:28:01.000
To listen to how they're responding to the calls of the greater-than-human world.

01:28:01.000 --> 01:28:04.000
I need to listen to the voices of my ancestors.

01:28:04.000 --> 01:28:14.000
Both those who came before and those who will come after, because I know they have things to say that I need to be aware of and to consider before making any further moves.

01:28:14.000 --> 01:28:16.000
beyond what is already in progress.

01:28:16.000 --> 01:28:22.000
I need unfettered access to the slow rhythms of biological analog reality.

01:28:22.000 --> 01:28:32.000
I need, in the words of Pablo Enruda, a huge silence that might interrupt the sadness of never understanding ourselves and threatening each other with death.

01:28:32.000 --> 01:28:35.000
So, I hope you'll pardon me while I go quiet for a bit.

01:28:35.000 --> 01:28:39.000
And until we meet again, I'll leave you with Narut's brilliant poem.

01:28:39.000 --> 01:28:41.000
Keeping quiet.

01:28:41.000 --> 01:28:46.000
Now we will count to 12. We will all keep still for once on the face of the earth.

01:28:46.000 --> 01:28:49.000
Let us not speak in any language.

01:28:49.000 --> 01:28:51.000
What a stop for a second.

01:28:51.000 --> 01:28:53.000
And not move our arms so much.

01:28:53.000 --> 01:28:56.000
It would be an exotic moment. Without rush.

01:28:56.000 --> 01:29:01.000
Without energies, we would all be together in a sudden strangeness.

01:29:01.000 --> 01:29:05.000
Fishermen in the cold sea would not harm whales.

01:29:05.000 --> 01:29:11.000
And the man gathering salt would not look at his hurt hands. Those who prepare green wars

01:29:11.000 --> 01:29:14.000
Or as with gas. Or as with fire.

01:29:14.000 --> 01:29:17.000
Victories with no survivors.

01:29:17.000 --> 01:29:21.000
would put on clean clothes and walk about with their brothers in the shade.

01:29:21.000 --> 01:29:26.000
Doing nothing. What I want should not be confused with total inactivity.

01:29:26.000 --> 01:29:32.000
Life is what it's about. If we were not so single-minded about keeping our lives moving,

01:29:32.000 --> 01:29:34.000
And for once could do nothing.

01:29:34.000 --> 01:29:39.000
Perhaps a huge silence might interrupt this sadness of never understanding ourselves.

01:29:39.000 --> 01:29:42.000
And threatening ourselves with death.

01:29:42.000 --> 01:29:44.000
Perhaps the Earth can teach us.

01:29:44.000 --> 01:29:48.000
As when everything seems dead, and later proves to be alive.

01:29:48.000 --> 01:29:51.000
Now, I will count up to 12.

01:29:51.000 --> 01:30:11.000
And you keep quiet, and I will go.

01:30:11.000 --> 01:30:14.000
Thank you all.

01:30:14.000 --> 01:30:17.000
Thank you all. I think.

01:30:17.000 --> 01:30:19.000
I don't know how, but can…

01:30:19.000 --> 01:30:23.000
Just encapsulated so much.

01:30:23.000 --> 01:30:31.000
So beautifully.

01:30:31.000 --> 01:30:35.000
I'll just say, I think he just said what I wanted to say to him.

01:30:35.000 --> 01:30:44.000
Um, you know, just picking up on the energy, kind of progressively of what I was seeing from him, I feel like…

01:30:44.000 --> 01:30:49.000
What he just said is, like, put into words better than I could have what… what I…

01:30:49.000 --> 01:30:52.000
what I actually wanted to say to him, so…

01:30:52.000 --> 01:30:53.000
Oh, that's wonderful.

01:30:53.000 --> 01:30:56.000
I see it… see it as a very positive thing.

01:30:56.000 --> 01:30:58.000
Love that, love that.

01:30:58.000 --> 01:31:03.000
Hey, thank you all. I think we kind of have our work cut out for us next Thursday, should you care to…

01:31:03.000 --> 01:31:07.000
Dare to be here. Um, I'll be here.

01:31:07.000 --> 01:31:11.000
And, um, let's be careful out there.

01:31:11.000 --> 01:31:12.000
Thanks, everybody.

01:31:12.000 --> 01:31:18.000
Thanks, bye.

